{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KITTI dataset parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pykitti\n",
    "from source import parseTrackletXML as xmlParser\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(date, drive, calibrated=False, frame_range=None):\n",
    "    \"\"\"\n",
    "    Loads the dataset with `date` and `drive`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    date        : Dataset creation date.\n",
    "    drive       : Dataset drive.\n",
    "    calibrated  : Flag indicating if we need to parse calibration data. Defaults to `False`.\n",
    "    frame_range : Range of frames. Defaults to `None`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Loaded dataset of type `raw`.\n",
    "    \"\"\"\n",
    "    dataset = pykitti.raw(basedir, date, drive)\n",
    "\n",
    "    # Load the data\n",
    "    if calibrated:\n",
    "        dataset.load_calib()  # Calibration data are accessible as named tuples\n",
    "\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    print('\\nDrive: ' + str(dataset.drive))\n",
    "    print('\\nFrame range: ' + str(dataset.frames))\n",
    "\n",
    "    if calibrated:\n",
    "        print('\\nIMU-to-Velodyne transformation:\\n' + str(dataset.calib.T_velo_imu))\n",
    "        print('\\nGray stereo pair baseline [m]: ' + str(dataset.calib.b_gray))\n",
    "        print('\\nRGB stereo pair baseline [m]: ' + str(dataset.calib.b_rgb))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "def kitti_tracklets_extraction(basedir, date, drive, calibrated=False, frame_range=None):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        dataset path\n",
    "            basedir, date, drive\n",
    "        \n",
    "    output:\n",
    "        tracklets: list of tracklet\n",
    "        tracklet['pc']\n",
    "        tracklet['rect']\n",
    "        tracklet['trans']\n",
    "        tracklet['rot]\n",
    "    \n",
    "    \"\"\"\n",
    "    dataset = load_dataset(date, drive, calibrated=False, frame_range=None)\n",
    "    dataset_velo = list(dataset.velo)\n",
    "    tracklets = xmlParser.parseXML('../dataset/{}/{}_drive_{}_sync/tracklet_labels.xml'.format(date, date, drive) )\n",
    "    \n",
    "    # loop over tracklets\n",
    "    parse_tracklets = []\n",
    "    \n",
    "    for i, tracklet in enumerate(tracklets):\n",
    "        \n",
    "        \n",
    "        parse_tracklet = {}\n",
    "        \n",
    "        parse_tracklet['pc'] = []\n",
    "        parse_tracklet['rect'] = []\n",
    "        parse_tracklet['trans'] = []\n",
    "        parse_tracklet['rot'] = []\n",
    "        parse_tracklet['type'] = []\n",
    "\n",
    "        # this part is inspired by kitti object development kit matlab code: computeBox3D\n",
    "        h, w, l = tracklet.size\n",
    "        # in velodyne coordinates around zero point and without orientation yet\n",
    "        trackletBox = np.array([\n",
    "            [-l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2],\n",
    "            [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2],\n",
    "            [0.0, 0.0, 0.0, 0.0, h, h, h, h]\n",
    "        ])\n",
    "        # loop over all data in tracklet\n",
    "        for translation, rotation, state, occlusion, truncation, amtOcclusion, amtBorders, absoluteFrameNumber in tracklet:\n",
    "            \n",
    "            # determine if object is in the image; otherwise continue\n",
    "            if truncation not in (xmlParser.TRUNC_IN_IMAGE, xmlParser.TRUNC_TRUNCATED):\n",
    "                continue\n",
    "            \n",
    "            # re-create 3D bounding box in velodyne coordinate system\n",
    "            yaw = rotation[2]  # other rotations are supposedly 0\n",
    "            assert np.abs(rotation[:2]).sum() == 0, 'object rotations other than yaw given!'\n",
    "            rotMat = np.array([\n",
    "                [np.cos(yaw), -np.sin(yaw), 0.0],\n",
    "                [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "                [0.0, 0.0, 1.0]\n",
    "            ])\n",
    "            cornerPosInVelo = np.dot(rotMat, trackletBox) + np.tile(translation, (8, 1)).T\n",
    "            \n",
    "            # extract point cloud\n",
    "            velo_pc = dataset_velo[absoluteFrameNumber].copy()\n",
    "            min_val = np.min(cornerPosInVelo, axis = 1)\n",
    "            max_val = np.max(cornerPosInVelo, axis = 1)\n",
    "            \n",
    "            for j in range(3):\n",
    "                velo_pc = velo_pc[ np.logical_and( velo_pc[:,j] < max_val[j], velo_pc[:,j] > min_val[j] )]    \n",
    "            \n",
    "            parse_tracklet['type'].append(tracklet.objectType)\n",
    "            parse_tracklet['rect'].append(cornerPosInVelo)\n",
    "            parse_tracklet['trans'].append(translation)\n",
    "            parse_tracklet['rot'].append(rotation)\n",
    "            parse_tracklet['pc'].append(velo_pc)\n",
    "\n",
    "        parse_tracklets.append(parse_tracklet)          \n",
    "  \n",
    "    return parse_tracklets\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Drive: 2011_09_26_drive_0001_sync\n",
      "\n",
      "Frame range: None\n",
      "Parsing tracklet file ../dataset/2011_09_26/2011_09_26_drive_0001_sync/tracklet_labels.xml\n",
      "File contains 15 tracklets\n",
      "Loaded 15 tracklets.\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "basedir = os.path.abspath('../dataset')\n",
    "date = '2011_09_26'\n",
    "drive = '0001'\n",
    "\n",
    "parse_tracklets = kitti_tracklets_extraction(basedir, date, drive)\n",
    "\n",
    "print ( type(parse_tracklets) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from visualization import *\n",
    "\n",
    "\n",
    "%matplotlib qt5\n",
    "\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "\n",
    "pc_all = []\n",
    "\n",
    "for i in range( len( parse_tracklets ) ):\n",
    "    \n",
    "    parse_tracklet = parse_tracklets[i]\n",
    "    \n",
    "    for j in range( len( parse_tracklet['pc'] ) ):\n",
    "                   \n",
    "        pc = parse_tracklet['pc'][j]\n",
    "        pc = resample_point_cloud(pc, 0.1)\n",
    "        display_point_cloud_ax_color(ax, pc, color = plt.cm.RdYlBu(i / len( parse_tracklets ) ))\n",
    "        \n",
    "        pc_all.append(np.min(pc, axis = 0) )\n",
    "        pc_all.append(np.max(pc, axis = 0) )\n",
    "\n",
    "# make axis equal\n",
    "points = np.array(pc_all)\n",
    "p_min = np.min(points, axis=0)\n",
    "p_max = np.max(points, axis=0)\n",
    "max_range = np.array([p_max[0]-p_min[0], p_max[1]-p_min[1], p_max[2]-p_min[2]]).max() / 2.0\n",
    "\n",
    "mid_x = (p_max[0]+p_min[0]) * 0.5\n",
    "mid_y = (p_max[1]+p_min[1]) * 0.5\n",
    "mid_z = (p_max[2]+p_min[2]) * 0.5\n",
    "ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parsing all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found:  2011_09_26_drive_0011\n",
      "Match found:  2011_09_26_drive_0001\n",
      "Match found:  2011_09_26_drive_0002\n",
      "Match found:  2011_09_26_drive_0005\n",
      "Match found:  2011_09_26_drive_0009\n",
      "Match found:  2011_09_26_drive_0013\n",
      "Match found:  2011_09_26_drive_0014\n",
      "Match found:  2011_09_26_drive_0017\n",
      "\n",
      "Drive: 2011_09_26_drive_0011_sync\n",
      "\n",
      "Frame range: None\n",
      "Parsing tracklet file ../dataset/2011_09_26/2011_09_26_drive_0011_sync/tracklet_labels.xml\n",
      "File contains 20 tracklets\n",
      "Loaded 20 tracklets.\n",
      "\n",
      "Drive: 2011_09_26_drive_0001_sync\n",
      "\n",
      "Frame range: None\n",
      "Parsing tracklet file ../dataset/2011_09_26/2011_09_26_drive_0001_sync/tracklet_labels.xml\n",
      "File contains 15 tracklets\n",
      "Loaded 15 tracklets.\n",
      "\n",
      "Drive: 2011_09_26_drive_0002_sync\n",
      "\n",
      "Frame range: None\n",
      "Parsing tracklet file ../dataset/2011_09_26/2011_09_26_drive_0002_sync/tracklet_labels.xml\n",
      "File contains 3 tracklets\n",
      "Loaded 3 tracklets.\n",
      "\n",
      "Drive: 2011_09_26_drive_0005_sync\n",
      "\n",
      "Frame range: None\n",
      "Parsing tracklet file ../dataset/2011_09_26/2011_09_26_drive_0005_sync/tracklet_labels.xml\n",
      "File contains 15 tracklets\n",
      "Loaded 15 tracklets.\n",
      "\n",
      "Drive: 2011_09_26_drive_0009_sync\n",
      "\n",
      "Frame range: None\n",
      "Parsing tracklet file ../dataset/2011_09_26/2011_09_26_drive_0009_sync/tracklet_labels.xml\n",
      "File contains 98 tracklets\n",
      "Loaded 98 tracklets.\n",
      "\n",
      "Drive: 2011_09_26_drive_0013_sync\n",
      "\n",
      "Frame range: None\n",
      "Parsing tracklet file ../dataset/2011_09_26/2011_09_26_drive_0013_sync/tracklet_labels.xml\n",
      "File contains 9 tracklets\n",
      "Loaded 9 tracklets.\n",
      "\n",
      "Drive: 2011_09_26_drive_0014_sync\n",
      "\n",
      "Frame range: None\n",
      "Parsing tracklet file ../dataset/2011_09_26/2011_09_26_drive_0014_sync/tracklet_labels.xml\n",
      "File contains 41 tracklets\n",
      "Loaded 41 tracklets.\n",
      "\n",
      "Drive: 2011_09_26_drive_0017_sync\n",
      "\n",
      "Frame range: None\n",
      "Parsing tracklet file ../dataset/2011_09_26/2011_09_26_drive_0017_sync/tracklet_labels.xml\n",
      "File contains 4 tracklets\n",
      "Loaded 4 tracklets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "KITTI dataset\n",
    "configuration\n",
    "\"\"\"\n",
    "\n",
    "basedir = os.path.abspath('../dataset')\n",
    "date = '2011_09_26'\n",
    "\n",
    "## parse drives\n",
    "import re\n",
    "\n",
    "p = re.compile(date + '_drive_\\d{4}')\n",
    "\n",
    "drives = []\n",
    "\n",
    "for root,d_names,f_names in os.walk(root_path):\n",
    "    for d in d_names:\n",
    "        m = p.match(d)\n",
    "        if m:\n",
    "            print('Match found: ', m.group())\n",
    "            drives.append(m.group().split('_')[-1])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Parsing\n",
    "\"\"\"\n",
    "\n",
    "parsed_data = {}\n",
    "parsed_data[date] = {}\n",
    "\n",
    "for d in drives:\n",
    "    parsed_data[date][d] = parse_tracklets = kitti_tracklets_extraction(basedir, date, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Saved new dataset, protocol=2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "## Save pickle\n",
    "with open('parsed_kitti_data.pickle', 'wb') as f:\n",
    "    pickle.dump(parsed_data, f, protocol=2)\n",
    "    \n",
    "print(\"\\n\\nSaved new dataset, protocol=2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
