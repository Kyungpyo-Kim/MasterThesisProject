{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Log 20181129\n",
    "\n",
    "## Results\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "## Trained model\n",
    "* [Download link]()\n",
    "\n",
    "## Evaluation\n",
    "* Incorrect sample\n",
    "![results]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time , datetime\n",
    "\n",
    "sys.path.append( os.path.abspath('../../../Dataset/scripts'))\n",
    "from utils import *\n",
    "\n",
    "sys.path.append( os.path.abspath('../../model') )\n",
    "from train import *\n",
    "import model_opt5 as MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Path \"\"\"\n",
    "data_train_path = os.path.abspath('../../../Dataset_ver2/dataset/db_v8_aug_20181129_ndb_v2_20181020/train.h5')\n",
    "data_vali_path = os.path.abspath('../../../Dataset_ver2/dataset/db_v8_aug_20181129_ndb_v2_20181020/vali.h5')\n",
    "\n",
    "log_path = os.path.abspath('./train_log_20181129.txt')\n",
    "\n",
    "model_save_path = os.path.abspath('./model')\n",
    "if not os.path.isdir(model_save_path) : os.mkdir(model_save_path)\n",
    "\n",
    "\"\"\" Parameters \"\"\"\n",
    "GPU_INDEX = 0\n",
    "NUM_POINT = 1024\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "BN_INIT_DECAY = 0.5\n",
    "BN_DECAY_DECAY_RATE = 0.5\n",
    "BN_DECAY_DECAY_STEP = float(200000)\n",
    "BN_DECAY_CLIP = 0.99\n",
    "DECAY_STEP = BN_DECAY_DECAY_STEP\n",
    "DECAY_RATE = BN_DECAY_DECAY_RATE\n",
    "\n",
    "BATCH_SIZE = 250\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "BASE_LEARNING_RATE = 0.001\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "MAX_EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Load dataset\"\"\"\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "\n",
    "data_train, label_train = load_h5(data_train_path)\n",
    "data_vali, label_vali = load_h5(data_vali_path)\n",
    "\n",
    "data.append(data_train)\n",
    "data.append(data_vali)\n",
    "label.append(label_train)\n",
    "label.append(label_vali)\n",
    "\n",
    "\"\"\" Data statistics \"\"\"\n",
    "\n",
    "label_list = [0,1,2,3,4]\n",
    "\n",
    "y_val = []\n",
    "for i in range( len ( data) ):\n",
    "    for j in range ( len ( label_list ) ):\n",
    "        y_val.append(np.sum(label[i] == label_list[j]))\n",
    "\n",
    "x_name=('unknown-train', 'cars-train', 'trucks-train', 'pedestrian-train', 'bike-train',\n",
    "        'unknown-vali', 'cars-vali', 'trucks-vali', 'pedestrian-vali', 'bike-vali')\n",
    "\n",
    "index = range( len(x_name) )\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(index, y_val, tick_label=x_name, align='center')\n",
    "plt.ylabel('Number of dataset')\n",
    "plt.title('Label distribution')\n",
    "plt.xlim( -1, len(x_name))\n",
    "plt.ylim( 0, np.max(y_val) * 1.1 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_2:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "INFO:tensorflow:Summary name classify loss is illegal; using classify_loss instead.\n",
      "INFO:tensorflow:Summary name mat loss is illegal; using mat_loss instead.\n",
      "2018-11-29 23:50:44.887371   Train one epoch   1 /  10\n",
      "2018-11-29 23:50:45.387344   Evaluation one (validation set) epoch   1 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [01:34<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 23:52:20.332106  [Epoch 0] vali mean loss: 0.000000\n",
      "2018-11-29 23:52:20.332549  [Epoch 0] vali accuracy: 49.333333\n",
      "2018-11-29 23:52:20.332913  [Epoch 0] vali avg class acc: 0.200000\n",
      "2018-11-29 23:52:20.333077  [Epoch 0] vali indivisual [0] class recall: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2bb43eb4b04d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi_cls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mlog_string\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;34m'[Epoch %d] vali indivisual [%d] class recall: %f'\u001b[0m \u001b[0;34m%\u001b[0m                        \u001b[0;34m(\u001b[0m  \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_correct_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_cls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_cls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mlog_string\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;34m'[Epoch %d] vali indivisual [%d] class precision: %f'\u001b[0m \u001b[0;34m%\u001b[0m                        \u001b[0;34m(\u001b[0m  \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_correct_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_cls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_detect_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_cls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "\"\"\" log file \"\"\"\n",
    "LOG_FOUT = open(log_path, 'w')\n",
    "\n",
    "def log_string(out_str):\n",
    "    out_str = str( datetime.datetime.fromtimestamp( time.time() ) ) + \"  \" + out_str\n",
    "    LOG_FOUT.write(out_str+'\\n')\n",
    "    LOG_FOUT.flush()\n",
    "    print(out_str)\n",
    "    \n",
    "    \n",
    "def get_learning_rate(batch):\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "                        BASE_LEARNING_RATE,  # Base learning rate.\n",
    "                        batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                        DECAY_STEP,          # Decay step.\n",
    "                        DECAY_RATE,          # Decay rate.\n",
    "                        staircase=True)\n",
    "    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n",
    "    return learning_rate        \n",
    "\n",
    "def get_bn_decay(batch):\n",
    "    bn_momentum = tf.train.exponential_decay(\n",
    "                      BN_INIT_DECAY,\n",
    "                      batch * BATCH_SIZE,\n",
    "                      BN_DECAY_DECAY_STEP,\n",
    "                      BN_DECAY_DECAY_RATE,\n",
    "                      staircase=True)\n",
    "    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "    return bn_decay\n",
    "\n",
    "\"\"\" load traing model \"\"\"\n",
    "with tf.Graph().as_default():\n",
    "    with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "        pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "        is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "        print(is_training_pl)\n",
    "\n",
    "        # Note the global_step=batch parameter to minimize. \n",
    "        # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "        batch = tf.Variable(0)\n",
    "        bn_decay = get_bn_decay(batch)\n",
    "        tf.summary.scalar('bn_decay', bn_decay)\n",
    "\n",
    "        # Get model and loss \n",
    "        pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n",
    "        loss = MODEL.get_loss(pred, labels_pl, end_points)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "        # Get training operator\n",
    "        learning_rate = get_learning_rate(batch)\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        if OPTIMIZER == 'momentum':\n",
    "            optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n",
    "        elif OPTIMIZER == 'adam':\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        train_op = optimizer.minimize(loss, global_step=batch)\n",
    "\n",
    "        # Add ops to save and restore all the variables.\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    # Create a session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.allow_soft_placement = True\n",
    "    config.log_device_placement = False\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    # Add summary writers\n",
    "    #merged = tf.merge_all_summaries()\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    train_writer_path = os.path.abspath('./train')\n",
    "    if os.path.isdir(train_writer_path): os.system('rm -r {}'.format(train_writer_path))\n",
    "    os.mkdir(train_writer_path)\n",
    "        \n",
    "    test_writer_path = os.path.abspath('./test')\n",
    "    if os.path.isdir(test_writer_path): os.system('rm -r {}'.format(test_writer_path))\n",
    "    os.mkdir(test_writer_path)\n",
    "    \n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(train_writer_path, sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(test_writer_path)\n",
    "    \n",
    "    \n",
    "    # Init variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    # To fix the bug introduced in TF 0.12.1 as in\n",
    "    # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n",
    "    #sess.run(init)\n",
    "    sess.run(init, {is_training_pl: True})\n",
    "\n",
    "    ops = {'pointclouds_pl': pointclouds_pl,\n",
    "           'labels_pl': labels_pl,\n",
    "           'is_training_pl': is_training_pl,\n",
    "           'pred': pred,\n",
    "           'loss': loss,\n",
    "           'train_op': train_op,\n",
    "           'merged': merged,\n",
    "           'step': batch}\n",
    "    \n",
    "            \n",
    "    for epoch in range(MAX_EPOCH):\n",
    "        \n",
    "        ## Training\n",
    "        log_string ( \" Train one epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        is_training = True\n",
    "        \n",
    "        # Shuffle train files\n",
    "        train_file_idxs = np.arange(0, data_train.shape[0])\n",
    "        np.random.shuffle(train_file_idxs)\n",
    "        \n",
    "        current_data = data_train[train_file_idxs] \n",
    "        current_label = label_train[train_file_idxs]\n",
    "        current_label.reshape((data_train.shape[0],))\n",
    "              \n",
    "        ## Evaluation metric\n",
    "        total_correct = 0\n",
    "        total_seen = 0\n",
    "        loss_sum = 0\n",
    "        \n",
    "        total_class = [0 for _ in range(NUM_CLASSES)]\n",
    "        total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "        total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            \n",
    "        num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "               \n",
    "        for batch_idx in trange(num_batches):\n",
    "            \n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = (batch_idx+1) * BATCH_SIZE           \n",
    "\n",
    "            # Augment batched point clouds by rotation and jittering\n",
    "            rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])\n",
    "            jittered_data = provider.jitter_point_cloud(rotated_data)\n",
    "            \n",
    "            feed_dict = {ops['pointclouds_pl']: jittered_data,\n",
    "                         ops['labels_pl']: current_label[start_idx:end_idx].reshape((BATCH_SIZE,)),\n",
    "                         ops['is_training_pl']: is_training,}\n",
    "            \n",
    "            summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                ops['train_op'], ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "            \n",
    "            train_writer.add_summary(summary, step)\n",
    "            \n",
    "            pred_val = np.argmax(pred_val, 1)\n",
    "            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n",
    "            total_correct += correct\n",
    "            total_seen += BATCH_SIZE\n",
    "            loss_sum += loss_val\n",
    "            \n",
    "            for i in range(NUM_CLASSES):\n",
    "                total_class[i] = np.sum( np.ones(BATCH_SIZE) * i == current_label[start_idx:end_idx] )\n",
    "                total_detect_class[i] = np.sum( np.ones(BATCH_SIZE) * i == pred_val )\n",
    "                total_correct_class[i] = np.sum( (np.ones(BATCH_SIZE) * i == current_label[start_idx:end_idx]) * \\\n",
    "                                                    (np.ones(BATCH_SIZE) * i == pred_val) )\n",
    "                                \n",
    "        log_string(  '[Epoch %d] mean loss: %f' % \\\n",
    "                   (  epoch, loss_sum / float(total_seen)  )   )\n",
    "        log_string(  '[Epoch %d] accuracy: %f'% \\\n",
    "                   (  epoch, total_correct / float(total_seen)  )   )\n",
    "        log_string(  '[Epoch %d] avg class acc: %f' % \\\n",
    "                   (  epoch, np.mean( np.array(total_correct_class)/np.array(total_class,dtype=np.float) )  )   )\n",
    "        \n",
    "        for i_cls in range(NUM_CLASSES):\n",
    "            if not float(total_class[i_cls]) == 0:\n",
    "                log_string(  '[Epoch %d] indivisual [%d] class recall: %f' % \\\n",
    "                       (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "            if not float(total_detect_class[i_cls]) == 0:\n",
    "                log_string(  '[Epoch %d] indivisual [%d] class precision: %f' % \\\n",
    "                       (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "\n",
    "\n",
    "        ## Evaluation using validation set    \n",
    "        log_string ( \" Evaluation one (validation set) epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        is_training = False\n",
    "        total_correct = 0\n",
    "        total_seen = 0\n",
    "        total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "        total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "        total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "        total_detect_true_class = [0 for _ in range(NUM_CLASSES)]\n",
    "        \n",
    "        # Shuffle validation files\n",
    "        file_idxs = np.arange(0, data_vali.shape[0])\n",
    "        np.random.shuffle(file_idxs)\n",
    "        \n",
    "        current_data = data_vali[file_idxs]\n",
    "        current_label = label_vali[file_idxs]\n",
    "        \n",
    "        num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "               \n",
    "        for batch_idx in trange(num_batches):\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "\n",
    "            feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                         ops['labels_pl']: current_label[start_idx:end_idx].reshape( (BATCH_SIZE,) ),\n",
    "                         ops['is_training_pl']: is_training}\n",
    "            summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "            \n",
    "            # test_writer.add_summary(summary, step)\n",
    "            \n",
    "            pred_val = np.argmax(pred_val, 1)\n",
    "            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n",
    "            total_correct += correct\n",
    "            total_seen += BATCH_SIZE\n",
    "            \n",
    "            for i in range(NUM_CLASSES):\n",
    "                total_class[i] = np.sum( np.ones(BATCH_SIZE) * i == current_label[start_idx:end_idx] )\n",
    "                total_detect_class[i] = np.sum( np.ones(BATCH_SIZE) * i == pred_val )\n",
    "                total_correct_class[i] = np.sum( (np.ones(BATCH_SIZE) * i == current_label[start_idx:end_idx]) * \\\n",
    "                                                    (np.ones(BATCH_SIZE) * i == pred_val) )\n",
    "                                \n",
    "        log_string(  '[Epoch %d] vali mean loss: %f' % \\\n",
    "                   (  epoch, loss_sum / float(total_seen)  )   )\n",
    "        log_string(  '[Epoch %d] vali accuracy: %f'% \\\n",
    "                   (  epoch, total_correct / float(total_seen)  )   )\n",
    "        log_string(  '[Epoch %d] vali avg class acc: %f' % \\\n",
    "                   (  epoch, np.mean( np.array(total_correct_class) / np.array(total_class) )  )   )\n",
    "        \n",
    "        for i_cls in range(NUM_CLASSES):\n",
    "            log_string(  '[Epoch %d] vali indivisual [%d] class recall: %f' % \\\n",
    "                       (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "            log_string(  '[Epoch %d] vali indivisual [%d] class precision: %f' % \\\n",
    "                       (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "             \n",
    " \n",
    "        # Save the variables to disk.\n",
    "        if ( epoch + 1 ) % 10 == 0:\n",
    "            save_path = saver.save(sess, os.path.join(model_save_path, \"model.ckpt\"))\n",
    "            log_string(\"Model saved in file: %s\" % save_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
