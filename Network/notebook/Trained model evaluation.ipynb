{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained model evaluation\n",
    "\n",
    "## Evaluation metric\n",
    "* Precision and recall\n",
    "    ![pr](../image/recall_precision.png)\n",
    "\n",
    "\n",
    "## Results\n",
    "* Voxel size 가 0.05, 0.1, 0.2, 0.5 일때 test set classification 성능\n",
    "    ```\n",
    "    Evaluation results - train\n",
    "    Correct / incorrect : 14603 / 7 - 99.9520876112% \n",
    "\n",
    "    Evaluation results - v050\n",
    "    Correct / incorrect : 14606 / 4 - 99.9726214921% \n",
    "\n",
    "    Evaluation results - v100\n",
    "    Correct / incorrect : 14604 / 6 - 99.9589322382% \n",
    "\n",
    "    Evaluation results - v200\n",
    "    Correct / incorrect : 14414 / 196 - 98.6584531143% \n",
    "\n",
    "    Evaluation results - v500\n",
    "    Correct / incorrect : 9374 / 5236 - 64.1615331964% \n",
    "    ```\n",
    "\n",
    "* Voxel size 가 0.1, 0.2, 0.3, 0.4, 0.5 일때 test set classification 성능\n",
    "    ```\n",
    "    Evaluation results - train\n",
    "    Correct / incorrect : 14493 / 7 - 99.9517241379% \n",
    "\n",
    "    Evaluation results - v100\n",
    "    Correct / incorrect : 14492 / 8 - 99.9448275862% \n",
    "\n",
    "    Evaluation results - v200\n",
    "    Correct / incorrect : 14277 / 223 - 98.4620689655% \n",
    "\n",
    "    Evaluation results - v300\n",
    "    Correct / incorrect : 13243 / 1257 - 91.3310344828% \n",
    "\n",
    "    Evaluation results - v400\n",
    "    Correct / incorrect : 11491 / 3009 - 79.2482758621% \n",
    "\n",
    "    Evaluation results - v500\n",
    "    Correct / incorrect : 9365 / 5135 - 64.5862068966% \n",
    "    ```\n",
    "    \n",
    "#### Visualization\n",
    "![analysis](../image/analysis_voxel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append( os.path.abspath('../../Dataset/scripts'))\n",
    "from utils import *\n",
    "\n",
    "sys.path.append( os.path.abspath('../model') )\n",
    "from train import *\n",
    "import model as MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parameters \"\"\"\n",
    "# model_path = os.path.abspath('../notebook/train_log_20181020/model/backup/model.ckpt')\n",
    "# model_path = os.path.abspath('../notebook/train_log_20181020/model/model.ckpt')\n",
    "model_path = os.path.abspath('../notebook/train_log_20181025/model/model.ckpt')\n",
    "\n",
    "data_test_path = []\n",
    "\n",
    "dtp = os.path.join( \\\n",
    "          os.path.abspath('../../Dataset/dataset/db_aug_v2_20181019_ndb_aug_v2_20181020'), 'test.h5' \\\n",
    "                  )\n",
    "data_test_path.append(dtp)\n",
    "\n",
    "dtp = os.path.join( \\\n",
    "          os.path.abspath('../../Dataset/dataset/db_aug_v2_v_100_20181022_ndb_aug_v2_20181020'), 'test.h5' \\\n",
    "                  )\n",
    "data_test_path.append(dtp)\n",
    "\n",
    "dtp = os.path.join( \\\n",
    "          os.path.abspath('../../Dataset/dataset/db_aug_v2_v_200_20181022_ndb_aug_v2_20181020'), 'test.h5' \\\n",
    "                  )\n",
    "data_test_path.append(dtp)\n",
    "\n",
    "dtp = os.path.join( \\\n",
    "          os.path.abspath('../../Dataset/dataset/db_aug_v2_v_300_20181022_ndb_aug_v2_20181020'), 'test.h5' \\\n",
    "                  )\n",
    "data_test_path.append(dtp)\n",
    "\n",
    "dtp = os.path.join( \\\n",
    "          os.path.abspath('../../Dataset/dataset/db_aug_v2_v_400_20181022_ndb_aug_v2_20181020'), 'test.h5' \\\n",
    "                  )\n",
    "data_test_path.append(dtp)\n",
    "\n",
    "dtp = os.path.join( \\\n",
    "          os.path.abspath('../../Dataset/dataset/db_aug_v2_v_500_20181022_ndb_aug_v2_20181020'), 'test.h5' \\\n",
    "                  )\n",
    "data_test_path.append(dtp)\n",
    "\n",
    "data_name_list = ['train', 'v100', 'v200', 'v300', 'v400', 'v500']\n",
    "\n",
    "\n",
    "\"\"\" Parameters \"\"\"\n",
    "GPU_INDEX = 0\n",
    "NUM_POINT = 256\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data: /home/gozilla/kyungpyo/git/MasterThesisProject/Dataset/dataset/db_aug_v2_20181019_ndb_aug_v2_20181020/test.h5\n",
      "Load data: /home/gozilla/kyungpyo/git/MasterThesisProject/Dataset/dataset/db_aug_v2_v_100_20181022_ndb_aug_v2_20181020/test.h5\n",
      "Load data: /home/gozilla/kyungpyo/git/MasterThesisProject/Dataset/dataset/db_aug_v2_v_200_20181022_ndb_aug_v2_20181020/test.h5\n",
      "Load data: /home/gozilla/kyungpyo/git/MasterThesisProject/Dataset/dataset/db_aug_v2_v_300_20181022_ndb_aug_v2_20181020/test.h5\n",
      "Load data: /home/gozilla/kyungpyo/git/MasterThesisProject/Dataset/dataset/db_aug_v2_v_400_20181022_ndb_aug_v2_20181020/test.h5\n",
      "Load data: /home/gozilla/kyungpyo/git/MasterThesisProject/Dataset/dataset/db_aug_v2_v_500_20181022_ndb_aug_v2_20181020/test.h5\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load dataset \"\"\"\n",
    "data = []\n",
    "label = []\n",
    "\n",
    "for dtp in data_test_path:\n",
    "    d, l = load_h5(dtp)\n",
    "    \n",
    "    data.append(d)\n",
    "    label.append(l)\n",
    "    \n",
    "    print \"Load data: {}\".format(dtp)\n",
    "    \n",
    "\n",
    "\"\"\" Data statistics\"\"\"\n",
    "label_list = [0,1,2]\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure( figsize=(12,9) )\n",
    "fig.subplots_adjust(left=0.02,top= 0.98,bottom=0.02,right=0.98,wspace=0.1,hspace=0.5)\n",
    "\n",
    "\n",
    "for i in range( len(data) ):\n",
    "    y_val = []\n",
    "    x_name = []\n",
    "\n",
    "    for j in range ( len ( label_list ) ):\n",
    "        y_val.append(np.sum(label[i] == label_list[j]))\n",
    "\n",
    "    x_name.append(\"{}-unknown\".format(data_name_list[i]))\n",
    "    x_name.append(\"{}-cars\".format(data_name_list[i]))\n",
    "    x_name.append(\"{}-trucks\".format(data_name_list[i]))\n",
    "\n",
    "    index = range( len(x_name) )\n",
    "    \n",
    "    ax=fig.add_subplot(len(data),1,i+1)\n",
    "\n",
    "    ax.bar(index, y_val, tick_label=x_name, align='center')\n",
    "    ax.set_ylabel('Number of dataset')\n",
    "    ax.set_title('Label distribution - {}'.format(data_name_list[i]))\n",
    "    ax.set_xlim( -1, len(x_name))\n",
    "    ax.set_ylim( 0, np.max(y_val) * 1.1 )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name classify loss is illegal; using classify_loss instead.\n",
      "INFO:tensorflow:Summary name mat loss is illegal; using mat_loss instead.\n",
      "INFO:tensorflow:Restoring parameters from /home/gozilla/kyungpyo/git/MasterThesisProject/Network/notebook/train_log_20181025/model/model.ckpt\n",
      "Model restored\n",
      "Dataset 1 / 6 \n",
      "Number of total dataset / evaluated dataset: 14616 / 14500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:12<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2 / 6 \n",
      "Number of total dataset / evaluated dataset: 14616 / 14500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 29/29 [00:12<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 3 / 6 \n",
      "Number of total dataset / evaluated dataset: 14616 / 14500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 29/29 [00:11<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 4 / 6 \n",
      "Number of total dataset / evaluated dataset: 14616 / 14500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 29/29 [00:11<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 5 / 6 \n",
      "Number of total dataset / evaluated dataset: 14616 / 14500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 29/29 [00:12<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 6 / 6 \n",
      "Number of total dataset / evaluated dataset: 14616 / 14500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 29/29 [00:11<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "is_training = False\n",
    "\n",
    "# reset graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "    pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "    is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "    # simple model\n",
    "    pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl)\n",
    "    loss = MODEL.get_loss(pred, labels_pl, end_points)\n",
    "\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "# Create a session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "config.log_device_placement = True\n",
    "\n",
    "ops = {'pointclouds_pl': pointclouds_pl,\n",
    "       'labels_pl': labels_pl,\n",
    "       'is_training_pl': is_training_pl,\n",
    "       'pred': pred,\n",
    "       'loss': loss}\n",
    "\n",
    "# ops.reset_default_graph() \n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# Restore variables from disk.\n",
    "saver.restore(sess, model_path)\n",
    "\n",
    "print \"Model restored\"\n",
    "sys.stdout.flush()\n",
    "\n",
    "results_list = []\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    print \"Dataset {} / {} \".format(i+1, len(data))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    ## Evaluation using test set    \n",
    "    is_training = False\n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    total_detect_true_class = [0 for _ in range(NUM_CLASSES)]\n",
    "\n",
    "    current_data = data[i]\n",
    "    current_label = label[i]\n",
    "\n",
    "    num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "    \n",
    "    print \"Number of total dataset / evaluated dataset: {} / {}\".format(current_data.shape[0], num_batches * BATCH_SIZE)\n",
    "    sys.stdout.flush()\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for batch_idx in trange(num_batches):\n",
    "        start_idx = batch_idx * BATCH_SIZE\n",
    "        end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "\n",
    "        feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx],\n",
    "                     ops['labels_pl']: current_label[start_idx:end_idx],\n",
    "                     ops['is_training_pl']: is_training}\n",
    "        loss_val, pred_val = sess.run([ops['loss'], ops['pred']],\n",
    "                                  feed_dict=feed_dict)\n",
    "\n",
    "        pred_val = np.argmax(pred_val, 1)\n",
    "        results.extend(pred_val)\n",
    "    \n",
    "    results_list.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results - train\n",
      "Correct / incorrect : 14384 / 116 - 99.2% \n",
      "\n",
      "Evaluation results - v100\n",
      "Correct / incorrect : 14460 / 40 - 99.724137931% \n",
      "\n",
      "Evaluation results - v200\n",
      "Correct / incorrect : 14476 / 24 - 99.8344827586% \n",
      "\n",
      "Evaluation results - v300\n",
      "Correct / incorrect : 14155 / 345 - 97.6206896552% \n",
      "\n",
      "Evaluation results - v400\n",
      "Correct / incorrect : 13710 / 790 - 94.5517241379% \n",
      "\n",
      "Evaluation results - v500\n",
      "Correct / incorrect : 12260 / 2240 - 84.5517241379% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "incorrect_idx_list = []\n",
    "all_accuracy_list = []\n",
    "cls_recall_list = []\n",
    "cls_precision_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "for i, results in enumerate(results_list):\n",
    "\n",
    "    print \"Evaluation results - {}\".format(data_name_list[i])\n",
    "    \n",
    "    prediction = np.array(results)\n",
    "    ground_truth = np.array(label[i][:prediction.shape[0]])\n",
    "    correct = np.sum( prediction == ground_truth )\n",
    "\n",
    "    ## calculate accuracy\n",
    "    all_accuracy = float( correct ) / float( prediction.shape[0] )\n",
    "    cls_recall = []\n",
    "    cls_precision = []\n",
    "    \n",
    "    for j in range(NUM_CLASSES):\n",
    "        tp = np.sum(  ( prediction == ground_truth ) * ( prediction == j * np.ones(prediction.shape) )  )\n",
    "        tn = np.sum(  ( prediction == ground_truth ) * ( prediction != j * np.ones(prediction.shape) )  )\n",
    "        fp = np.sum(  ( prediction != ground_truth ) * ( prediction == j * np.ones(prediction.shape) )  )\n",
    "        fn = np.sum(  ( prediction != ground_truth ) * ( prediction != j * np.ones(prediction.shape) )  )\n",
    "        \n",
    "        p = float(tp) / float( tp + fp )\n",
    "        r = float(tp) / float( tp + fn )\n",
    "        \n",
    "        cls_precision.append(p)\n",
    "        cls_recall.append(r)\n",
    "    \n",
    "    all_accuracy_list.append(all_accuracy)\n",
    "    cls_recall_list.append(cls_recall)\n",
    "    cls_precision_list.append(cls_precision)\n",
    "\n",
    "    ## find incorrect idx\n",
    "    \n",
    "    incorrect_idx = []\n",
    "    \n",
    "    for j, gt in enumerate(ground_truth):\n",
    "\n",
    "        pred = prediction[j]\n",
    "        if not gt == pred: incorrect_idx.append(j)\n",
    "                          \n",
    "            #print \"gt: {}, pred: {}\".format(gt, pred)\n",
    "\n",
    "    print \"Correct / incorrect : {} / {} - {}% \\n\".format( \n",
    "        ground_truth.shape[0] - len(incorrect_idx) , \n",
    "        len(incorrect_idx),\n",
    "        all_accuracy * 100. )\n",
    "    \n",
    "    incorrect_idx_list.append(incorrect_idx)\n",
    "    \n",
    "\"\"\" Visualization \"\"\"\n",
    "plt.close('all')\n",
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x = range( len(data_name_list) - 1 )\n",
    "ac = ax.plot(x, np.array(all_accuracy_list[1:]), marker = 'o', label = 'accuracy')#, color = 1, marker = 'o', label = data_name_list[0])\n",
    "\n",
    "for i in range( len(data_name_list) - 1 ):\n",
    "    ax.annotate(\"{:.2f}%\".format(np.array(all_accuracy_list[i+1])*100.), \n",
    "                (x[i] + 0.05 , all_accuracy_list[i+1]) ,  fontsize=10, fontweight='bold')\n",
    "\"\"\"color = ac[0].get_color(),\"\"\"\n",
    "\n",
    "label_dict = {0: 'unkwnown', 1: 'cars', 2: 'trucks'}\n",
    "cr = []\n",
    "for i in range(1,NUM_CLASSES):\n",
    "    cr = ax.plot(x, np.array(cls_recall_list)[1:, i], linestyle = '--', label = 'recall-{}'.format(label_dict[i]), marker = '^')\n",
    "    cp = ax.plot(x, np.array(cls_precision_list)[1:, i], linestyle = '--', label = 'precision-{}'.format(label_dict[i]), marker = 's')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "xticlabels = ['0.1', '0.2', '0.3', '0.4', '0.5']\n",
    "ax.set_xticklabels(xticlabels)\n",
    "\n",
    "ax.set_xlabel('Dataset(voxel size [m])')\n",
    "ax.set_ylabel('Accuracy (recall, precision)')\n",
    "\n",
    "ax.set_title('Analysis on voxel size')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cls_recall_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( prediction == ground_truth ) * ( prediction == j * np.ones(prediction.shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Display \"\"\"\n",
    "data_sel = 0\n",
    "num_of_fig = 7\n",
    "\n",
    "%matplotlib qt\n",
    "label_list = [0,1,2]\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure( figsize=(12,9) )\n",
    "fig.subplots_adjust(left=0.02,top= 0.98,bottom=0.02,right=0.98,wspace=0.1,hspace=0.5)\n",
    "\n",
    "\n",
    "incorrect_idx = incorrect_idx_list[data_sel]\n",
    "\n",
    "if len(incorrect_idx) < num_of_fig: num_of_fig = len(incorrect_idx)\n",
    "    \n",
    "# display point cloud\n",
    "crn = int( np.sqrt(num_of_fig) ) + 1\n",
    "\n",
    "idx_offset = 0\n",
    "\n",
    "for i in range(num_of_fig):\n",
    "    \n",
    "    idx = idx_offset + incorrect_idx[i]\n",
    "\n",
    "    prediction = np.array(results_list[data_sel])\n",
    "    ground_truth = np.array(label[data_sel][:prediction.shape[0]])\n",
    "\n",
    "    ax = fig.add_subplot(crn, crn, i+1, projection='3d')\n",
    "    ax = display_point_cloud_box_ax(ax, data[data_sel][idx])\n",
    "    ax.set_title(\"idx: {}, gt: {}, pred: {}\".format(idx, ground_truth[idx], prediction[idx]))\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()    \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
