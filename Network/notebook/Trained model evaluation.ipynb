{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append( os.path.abspath('../../Dataset/scripts'))\n",
    "from utils import *\n",
    "\n",
    "sys.path.append( os.path.abspath('../model') )\n",
    "from train import *\n",
    "import model as MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parameters \"\"\"\n",
    "# model_path = os.path.abspath('../notebook/train_log_20181020/model/backup/model.ckpt')\n",
    "model_path = os.path.abspath('../notebook/train_log_20181020/model/model.ckpt')\n",
    "\n",
    "data_test_path = os.path.join( \\\n",
    "                      os.path.abspath('../../Dataset/dataset/db_aug_v2_20181019_ndb_aug_v2_20181020'), 'test.h5' \\\n",
    "                             )\n",
    "\n",
    "\"\"\" Parameters \"\"\"\n",
    "GPU_INDEX = 0\n",
    "NUM_POINT = 256\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "BN_INIT_DECAY = 0.5\n",
    "BN_DECAY_DECAY_RATE = 0.5\n",
    "BN_DECAY_DECAY_STEP = float(200000)\n",
    "BN_DECAY_CLIP = 0.99\n",
    "DECAY_STEP = BN_DECAY_DECAY_STEP\n",
    "DECAY_RATE = BN_DECAY_DECAY_RATE\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "BASE_LEARNING_RATE = 0.001\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "MAX_EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load dataset \"\"\"\n",
    "data, label = load_h5(data_test_path)\n",
    "\n",
    "\n",
    "\"\"\" Data statistics\"\"\"\n",
    "label_list = [0,1,2]\n",
    "\n",
    "y_val = []\n",
    "for j in range ( len ( label_list ) ):\n",
    "    y_val.append(np.sum(label == label_list[j]))\n",
    "\n",
    "x_name=('unknown-test', 'cars-test', 'trucks-test')\n",
    "\n",
    "index = range( len(x_name) )\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(index, y_val, tick_label=x_name, align='center')\n",
    "plt.ylabel('Number of dataset')\n",
    "plt.title('Label distribution')\n",
    "plt.xlim( -1, len(x_name))\n",
    "plt.ylim( 0, np.max(y_val) * 1.1 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name classify loss is illegal; using classify_loss instead.\n",
      "INFO:tensorflow:Summary name mat loss is illegal; using mat_loss instead.\n",
      "INFO:tensorflow:Restoring parameters from /home/gozilla/kyungpyo/git/MasterThesisProject/Network/notebook/train_log_20181020/model/model.ckpt\n",
      "Model restored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1461/1461 [00:23<00:00, 62.92it/s]\n"
     ]
    }
   ],
   "source": [
    "is_training = False\n",
    "\n",
    "# reset graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "    pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "    is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "    # simple model\n",
    "    pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl)\n",
    "    loss = MODEL.get_loss(pred, labels_pl, end_points)\n",
    "\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "# Create a session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "config.log_device_placement = True\n",
    "\n",
    "ops = {'pointclouds_pl': pointclouds_pl,\n",
    "       'labels_pl': labels_pl,\n",
    "       'is_training_pl': is_training_pl,\n",
    "       'pred': pred,\n",
    "       'loss': loss}\n",
    "\n",
    "# ops.reset_default_graph() \n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# Restore variables from disk.\n",
    "saver.restore(sess, model_path)\n",
    "\n",
    "print \"Model restored\"\n",
    "sys.stdout.flush()\n",
    "\n",
    "## Evaluation using test set    \n",
    "is_training = False\n",
    "total_correct = 0\n",
    "total_seen = 0\n",
    "total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "total_detect_true_class = [0 for _ in range(NUM_CLASSES)]\n",
    "\n",
    "current_data = data\n",
    "current_label = label\n",
    "\n",
    "num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "\n",
    "results = []\n",
    "\n",
    "for batch_idx in trange(num_batches):\n",
    "    start_idx = batch_idx * BATCH_SIZE\n",
    "    end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "\n",
    "    feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx],\n",
    "                 ops['labels_pl']: current_label[start_idx:end_idx],\n",
    "                 ops['is_training_pl']: is_training}\n",
    "    loss_val, pred_val = sess.run([ops['loss'], ops['pred']],\n",
    "                              feed_dict=feed_dict)\n",
    "    \n",
    "    pred_val = np.argmax(pred_val, 1)\n",
    "    results.extend(pred_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: 0, pred: 2\n",
      "gt: 0, pred: 2\n",
      "gt: 0, pred: 2\n",
      "gt: 0, pred: 2\n",
      "gt: 2, pred: 0\n",
      "gt: 2, pred: 0\n",
      "gt: 2, pred: 0\n",
      "Correct / incorrect : 14603 / 7 \n"
     ]
    }
   ],
   "source": [
    "prediction = np.array(results)\n",
    "ground_truth = np.array(current_label[:prediction.shape[0]])\n",
    "correct = np.sum( prediction == ground_truth )\n",
    "\n",
    "incorrect_idx = []\n",
    "\n",
    "for i, gt in enumerate(ground_truth):\n",
    "    \n",
    "    pred = prediction[i]\n",
    "    \n",
    "    if not gt == pred:\n",
    "        \n",
    "        incorrect_idx.append(i)\n",
    "        \n",
    "        print \"gt: {}, pred: {}\".format(gt, pred)\n",
    "\n",
    "print \"Correct / incorrect : {} / {} \".format( ground_truth.shape[0] - len(incorrect_idx) , len(incorrect_idx) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Display \"\"\"\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "    \n",
    "# display point cloud\n",
    "for i, idx in enumerate(incorrect_idx):\n",
    "\n",
    "    ax = fig.add_subplot(331 + i, projection='3d')\n",
    "    ax = display_point_cloud_box_ax(ax, data[idx])\n",
    "    ax.set_title(\"idx: {}, gt: {}, pred: {}\".format(idx, ground_truth[idx], prediction[idx]))\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
