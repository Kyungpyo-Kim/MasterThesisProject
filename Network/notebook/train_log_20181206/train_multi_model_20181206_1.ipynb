{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Log 20181206\n",
    "\n",
    "* Add multi-model training structure\n",
    "\n",
    "## Results\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "## Trained model\n",
    "* [Download link]()\n",
    "\n",
    "## Evaluation\n",
    "* Incorrect sample\n",
    "![results]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time , datetime\n",
    "\n",
    "# sys.path.append( os.path.abspath('../../../Dataset/scripts'))\n",
    "# from utils import *\n",
    "\n",
    "sys.path.append( os.path.abspath('../../model') )\n",
    "from train import *\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Path \"\"\"\n",
    "data_train_path = os.path.abspath('../../../new_dataset/dataset/dataset_20181203_01/train.h5')\n",
    "data_vali_path = os.path.abspath('../../../new_dataset/dataset/dataset_20181203_01/vali.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Load dataset\"\"\"\n",
    "\n",
    "data = []\n",
    "class_label = []\n",
    "heading_label = []\n",
    "\n",
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    class_label = f['class'][:]\n",
    "    heading_label = f['heading'][:]\n",
    "    return (data, class_label, heading_label)\n",
    "\n",
    "data_train, class_label_train, heading_label_train = load_h5(data_train_path)\n",
    "data_vali, class_label_vali, heading_label_vali = load_h5(data_vali_path)\n",
    "\n",
    "data.append(data_train)\n",
    "data.append(data_vali)\n",
    "class_label.append(class_label_train)\n",
    "class_label.append(class_label_vali)\n",
    "heading_label.append(heading_label_train)\n",
    "heading_label.append(heading_label_vali)\n",
    "\n",
    "\"\"\" Data statistics \"\"\"\n",
    "\n",
    "label_list = [0,1,2]\n",
    "\n",
    "y_val = []\n",
    "for i in range( len ( data) ):\n",
    "    for j in range ( len ( label_list ) ):\n",
    "        y_val.append(np.sum(class_label[i] == label_list[j]))\n",
    "\n",
    "x_name=('unknown-train', 'cars-train','pedestrian-train',\n",
    "        'unknown-vali', 'cars-vali', 'pedestrian-vali')\n",
    "\n",
    "index = range( len(x_name) )\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(index, y_val, tick_label=x_name, align='center')\n",
    "plt.ylabel('Number of dataset')\n",
    "plt.title('Label distribution')\n",
    "plt.xlim( -1, len(x_name))\n",
    "plt.ylim( 0, np.max(y_val) * 1.1 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "\n",
      "\n",
      " Train one epoch   1 /   2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1615/1615 [09:45<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 0.430615007877\n",
      "- cls loss: 0.419095903635\n",
      "- mat loss: 2.12083029747\n",
      "- heading loss: 0.0939829200506\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    unknown       0.73      0.66      0.70     35515\n",
      "        car       0.73      0.79      0.76     36235\n",
      "      pedes       0.83      0.87      0.85      9000\n",
      "\n",
      "avg / total       0.74      0.74      0.74     80750\n",
      "\n",
      "- Root mean_squared_errors [deg]: 11.5010654926\n",
      " Evaluation one (validation set) epoch   1 /   2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 0.391478121281\n",
      "- cls loss: 0.381946831942\n",
      "- mat loss: 2.26346325874\n",
      "- heading loss: 0.0726783648133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    unknown       0.75      0.91      0.82     11805\n",
      "        car       0.97      0.73      0.83     12102\n",
      "      pedes       0.77      0.92      0.84      2993\n",
      "\n",
      "avg / total       0.85      0.83      0.83     26900\n",
      "\n",
      "- Root mean_squared_errors [deg]: 2.64644645154\n",
      "\n",
      "\n",
      " Train one epoch   2 /   2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1615/1615 [09:44<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 0.534535527229\n",
      "- cls loss: 0.521973490715\n",
      "- mat loss: 2.83400273323\n",
      "- heading loss: 0.097280010581\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    unknown       0.85      0.82      0.83     35517\n",
      "        car       0.86      0.87      0.87     36233\n",
      "      pedes       0.87      0.92      0.89      9000\n",
      "\n",
      "avg / total       0.85      0.85      0.85     80750\n",
      "\n",
      "- Root mean_squared_errors [deg]: 2.66691606492\n",
      " Evaluation one (validation set) epoch   2 /   2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 0.414387494326\n",
      "- cls loss: 0.4032368958\n",
      "- mat loss: 3.01515316963\n",
      "- heading loss: 0.0813543200493\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    unknown       0.89      0.96      0.92     11803\n",
      "        car       0.99      0.90      0.94     12101\n",
      "      pedes       0.89      0.91      0.90      2996\n",
      "\n",
      "avg / total       0.93      0.93      0.93     26900\n",
      "\n",
      "- Root mean_squared_errors [deg]: 2.53443807364\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\"\"\"\n",
    "Import model \n",
    "\"\"\"\n",
    "sys.path.append( os.path.abspath('../../model') )\n",
    "\n",
    "from train import *\n",
    "import model_out_5_heading_3 as MODEL\n",
    "\n",
    "\n",
    "\n",
    "def run_training(out_path):\n",
    "    \n",
    "    \"\"\" Path \"\"\"\n",
    "    model_save_path = os.path.abspath(out_path)\n",
    "    if not os.path.isdir(model_save_path) : os.mkdir(model_save_path)\n",
    "        \n",
    "    \"\"\" Parameters \"\"\"\n",
    "    GPU_INDEX = 0\n",
    "    NUM_POINT = 1024\n",
    "    NUM_CLASSES = 3\n",
    "\n",
    "    BN_INIT_DECAY = 0.5\n",
    "    BN_DECAY_DECAY_RATE = 0.5\n",
    "    BN_DECAY_DECAY_STEP = float(200000)\n",
    "    BN_DECAY_CLIP = 0.99\n",
    "    DECAY_STEP = BN_DECAY_DECAY_STEP\n",
    "    DECAY_RATE = BN_DECAY_DECAY_RATE\n",
    "\n",
    "    BATCH_SIZE = 50\n",
    "\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    BASE_LEARNING_RATE = 0.001\n",
    "\n",
    "    OPTIMIZER = 'adam'\n",
    "\n",
    "    MAX_EPOCH = 2\n",
    "    \n",
    "    HEADING_LOSS_WEIGHT = 0.1\n",
    "\n",
    "\n",
    "    \n",
    "    def get_learning_rate(batch):\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "                            BASE_LEARNING_RATE,  # Base learning rate.\n",
    "                            batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                            DECAY_STEP,          # Decay step.\n",
    "                            DECAY_RATE,          # Decay rate.\n",
    "                            staircase=True)\n",
    "        learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n",
    "        return learning_rate        \n",
    "\n",
    "    def get_bn_decay(batch):\n",
    "        bn_momentum = tf.train.exponential_decay(\n",
    "                          BN_INIT_DECAY,\n",
    "                          batch * BATCH_SIZE,\n",
    "                          BN_DECAY_DECAY_STEP,\n",
    "                          BN_DECAY_DECAY_RATE,\n",
    "                          staircase=True)\n",
    "        bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "        return bn_decay\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    load traing model\n",
    "    \"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Placeholder\n",
    "            \"\"\"\n",
    "            pointclouds_pl, class_labels_pl, heading_labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "            is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "            print(is_training_pl)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            decay\n",
    "            \"\"\"\n",
    "            # Note the global_step=batch parameter to minimize. \n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.summary.scalar('bn_decay', bn_decay)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Get model and loss \n",
    "            \"\"\"\n",
    "            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n",
    "            loss = MODEL.get_loss(pred, class_labels_pl, heading_labels_pl, end_points, h_reg_weight=HEADING_LOSS_WEIGHT)\n",
    "            tf.summary.scalar('loss', loss)\n",
    "            \n",
    "            classify_loss = MODEL.get_classify_loss(pred, class_labels_pl)\n",
    "            mat_diff_loss = MODEL.get_mat_diff_loss(end_points)\n",
    "            heading_loss = MODEL.get_heading_loss(pred, heading_labels_pl)\n",
    "            \n",
    "            tf.summary.scalar('classify_loss', classify_loss)\n",
    "            tf.summary.scalar('mat_diff_loss', mat_diff_loss)\n",
    "            tf.summary.scalar('heading_loss', heading_loss)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Get accuracy \n",
    "            \"\"\"\n",
    "            correct = tf.equal(tf.argmax(tf.slice(pred, [0,0], [BATCH_SIZE,3]), 1), tf.to_int64(class_labels_pl))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Get training operator\n",
    "            \"\"\"\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            if OPTIMIZER == 'momentum':\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n",
    "            elif OPTIMIZER == 'adam':\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss, global_step=batch)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Add ops to save and restore all the variables.\n",
    "            \"\"\"\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        Create a session\n",
    "        \"\"\"\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = False\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Add summary writers\n",
    "        merged = tf.merge_all_summaries()\n",
    "        \"\"\"\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        train_writer_path = os.path.abspath( os.path.join(model_save_path, 'train') )\n",
    "        if os.path.isdir(train_writer_path): os.system('rm -r {}'.format(train_writer_path))\n",
    "        os.mkdir(train_writer_path)\n",
    "\n",
    "        test_writer_path = os.path.abspath( os.path.join(model_save_path, 'test') )\n",
    "        if os.path.isdir(test_writer_path): os.system('rm -r {}'.format(test_writer_path))\n",
    "        os.mkdir(test_writer_path)\n",
    "\n",
    "\n",
    "        train_writer = tf.summary.FileWriter(train_writer_path, sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(test_writer_path)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Init variables\n",
    "        \"\"\"\n",
    "        init = tf.global_variables_initializer()\n",
    "        # To fix the bug introduced in TF 0.12.1 as in\n",
    "        # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n",
    "        #sess.run(init)\n",
    "        sess.run(init, {is_training_pl: True})\n",
    "\n",
    "        ops = {'pointclouds_pl': pointclouds_pl,\n",
    "               'class_labels_pl': class_labels_pl,\n",
    "               'heading_labels_pl': heading_labels_pl,\n",
    "               'is_training_pl': is_training_pl,\n",
    "               'pred': pred,\n",
    "               'loss': loss,\n",
    "               'classify_loss': classify_loss,\n",
    "               'mat_diff_loss': mat_diff_loss,\n",
    "               'heading_loss': heading_loss,\n",
    "               'train_op': train_op,\n",
    "               'merged': merged,\n",
    "               'step': batch}\n",
    "\n",
    "\n",
    "        for epoch in range(MAX_EPOCH):\n",
    "\n",
    "            ## Training\n",
    "            print \"\\n\\n Train one epoch %3d / %3d\" % (epoch+1, MAX_EPOCH)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = True\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle train files\n",
    "            \"\"\"\n",
    "            train_file_idxs = np.arange(0, data_train.shape[0])\n",
    "            np.random.shuffle(train_file_idxs)\n",
    "\n",
    "            current_data = data_train[train_file_idxs] \n",
    "            current_class_label = class_label_train[train_file_idxs]\n",
    "            current_heading_label = heading_label_train[train_file_idxs]\n",
    "            \n",
    "            current_class_label.reshape((data_train.shape[0],))\n",
    "            current_heading_label.reshape((data_train.shape[0],))\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            class_results = []\n",
    "            heading_results = []\n",
    "            \n",
    "\n",
    "            \"\"\"\n",
    "            Run batch training\n",
    "            \"\"\"\n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE           \n",
    "\n",
    "                # Augment batched point clouds by rotation and jittering\n",
    "                rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])\n",
    "                jittered_data = provider.jitter_point_cloud(rotated_data)\n",
    "\n",
    "                # Reashape\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                feed_dict = {ops['pointclouds_pl']: jittered_data,\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training,}\n",
    "\n",
    "                summary, step, _, loss_val,loss_cls,loss_mat,loss_hea, pred_val = sess.run([ops['merged'], \n",
    "                                                                 ops['step'],\n",
    "                                                                 ops['train_op'], \n",
    "                                                                 ops['loss'], \n",
    "                                                                 ops['classify_loss'],\n",
    "                                                                 ops['mat_diff_loss'],\n",
    "                                                                 ops['heading_loss'],\n",
    "                                                                 ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                train_writer.add_summary(summary, step)\n",
    "                \n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                # heading\n",
    "                heading_results.extend(pred_val[:,3])\n",
    "                # class\n",
    "                pred_val_class = np.argmax(pred_val[:,:3], 1)\n",
    "                class_results.extend(pred_val_class)\n",
    "            \n",
    "            \"\"\"\n",
    "            Results\n",
    "            \"\"\"\n",
    "            ## Loss\n",
    "            print \"Total loss: {}\".format(np.mean(loss_val))\n",
    "            print \"- cls loss: {}\".format(np.mean(loss_cls))\n",
    "            print \"- mat loss: {}\".format(np.mean(loss_mat))\n",
    "            print \"- heading loss: {}\".format(np.mean(loss_hea))\n",
    "            \n",
    "            \n",
    "            \n",
    "            ## Classification\n",
    "            prediction = np.array(class_results)\n",
    "            ground_truth = np.array(current_class_label[:num_batches*BATCH_SIZE])\n",
    "            cm = confusion_matrix(ground_truth, prediction)\n",
    "            label_list = ['unknown', 'car', 'pedes']\n",
    "            print(classification_report(ground_truth, prediction, target_names=label_list))\n",
    "            \n",
    "            ## Heading\n",
    "            y_pred = np.asarray(heading_results)\n",
    "            y_true = np.asarray(current_heading_label[:num_batches*BATCH_SIZE])\n",
    "            y_pred = y_pred.reshape(y_true.shape)\n",
    "\n",
    "            error = np.abs(y_true - y_pred)\n",
    "            rmse = np.square( np.mean (error**2) )\n",
    "        #     print('- Explained_variance_score: {}'.format(explained_variance_score(y_true, y_pred)))\n",
    "        #     print('- R2_score: {}'.format(r2_score(y_true, y_pred)))\n",
    "            print('- Root mean_squared_errors [deg]: {}'.format(rmse * 360.))\n",
    "                \n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation using validation set    \n",
    "            \"\"\"\n",
    "            \n",
    "            print \" Evaluation one (validation set) epoch %3d / %3d\" % (epoch+1, MAX_EPOCH)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = False\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            class_results = []\n",
    "            heading_results = []\n",
    "                       \n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle validation files\n",
    "            \"\"\"\n",
    "            file_idxs = np.arange(0, data_vali.shape[0])\n",
    "            np.random.shuffle(file_idxs)\n",
    "\n",
    "            current_data = data_vali[file_idxs]\n",
    "            current_class_label = class_label_vali[file_idxs]\n",
    "            current_heading_label = heading_label_vali[file_idxs]\n",
    "\n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Run batch validation\n",
    "            \"\"\"\n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Reashape\n",
    "                \"\"\"\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Feed dict\n",
    "                \"\"\"\n",
    "                feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training}\n",
    "                \n",
    "                \"\"\"\n",
    "                Summary\n",
    "                \"\"\"\n",
    "                summary, step, loss_val, loss_cls, loss_mat, loss_hea, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                                                              ops['loss'], \n",
    "                                                              ops['classify_loss'], \n",
    "                                                              ops['mat_diff_loss'], \n",
    "                                                              ops['heading_loss'], \n",
    "                                                              ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                # heading\n",
    "                heading_results.extend(pred_val[:,3])\n",
    "\n",
    "                pred_val_class = np.argmax(pred_val[:,:3], 1)\n",
    "                class_results.extend(pred_val_class)\n",
    "            \n",
    "            ## Loss\n",
    "            print \"Total loss: {}\".format(np.mean(loss_val))\n",
    "            print \"- cls loss: {}\".format(np.mean(loss_cls))\n",
    "            print \"- mat loss: {}\".format(np.mean(loss_mat))\n",
    "            print \"- heading loss: {}\".format(np.mean(loss_hea))\n",
    "            \n",
    "            \n",
    "            ## Classification\n",
    "            prediction = np.array(class_results)\n",
    "            ground_truth = np.array(current_class_label[:num_batches*BATCH_SIZE])\n",
    "            cm = confusion_matrix(ground_truth, prediction)\n",
    "            label_list = ['unknown', 'car', 'pedes']\n",
    "            print(classification_report(ground_truth, prediction, target_names=label_list))\n",
    "            \n",
    "            ## Heading\n",
    "            y_pred = np.asarray(heading_results)\n",
    "            y_true = np.asarray(current_heading_label[:num_batches*BATCH_SIZE])\n",
    "            y_pred = y_pred.reshape(y_true.shape)\n",
    "\n",
    "            error = np.abs(y_true - y_pred)\n",
    "            rmse = np.square( np.mean (error**2) )\n",
    "        #     print('- Explained_variance_score: {}'.format(explained_variance_score(y_true, y_pred)))\n",
    "        #     print('- R2_score: {}'.format(r2_score(y_true, y_pred)))\n",
    "            print('- Root mean_squared_errors [deg]: {}'.format(rmse * 360.))\n",
    "            \n",
    "                \n",
    "            \"\"\"\n",
    "            Save the variables to disk.\n",
    "            \"\"\"\n",
    "#             if ( epoch + 1 ) % 10 == 0:\n",
    "            save_path = saver.save(sess, os.path.join(model_save_path, \"model.ckpt\"))\n",
    "            print \"Model saved in file: %s\" % save_path\n",
    "\n",
    "                \n",
    "# option 1: execute code with extra process\n",
    "p = multiprocessing.Process(target=run_training, args = ('./model_out5_4',))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
