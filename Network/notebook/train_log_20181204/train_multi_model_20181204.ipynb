{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Log 20181201\n",
    "\n",
    "* Add multi-model training structure\n",
    "\n",
    "## Results\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "## Trained model\n",
    "* [Download link]()\n",
    "\n",
    "## Evaluation\n",
    "* Incorrect sample\n",
    "![results]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time , datetime\n",
    "\n",
    "# sys.path.append( os.path.abspath('../../../Dataset/scripts'))\n",
    "# from utils import *\n",
    "\n",
    "sys.path.append( os.path.abspath('../../model') )\n",
    "from train import *\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Path \"\"\"\n",
    "data_train_path = os.path.abspath('../../../new_dataset/dataset/dataset_20181203_01/train.h5')\n",
    "data_vali_path = os.path.abspath('../../../new_dataset/dataset/dataset_20181203_01/vali.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAE/CAYAAADv11YpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xu4JVV55/Hvz25UvGCDtAzSQBPF5AFNUFtAYwziCA1E0QQVo4KEBJ2A0UQd0VxACBPUUUfUaFA7gFERQaWDrUiMeOfSKHdk6CAMIALKXRQB3/ljryObU+ey+7LP7nP6+3meenbVW2vVWrUvdc67q2rtVBWSJEmSJPV72Kg7IEmSJEla/5gsSpIkSZI6TBYlSZIkSR0mi5IkSZKkDpNFSZIkSVKHyaIkSZIkqcNkUZI0ZyU5O8mfD7tukt2SXN+3fFmS3dak3Qm2/aokX+1briRPXhfbbtu7O8lvravtSZLmDpNFSdJ6L8k1Sf77qPsxqKrasarOnqpMksUt8Zs/zbY+VVV7rIt+TZQAV9VjqurqdbF9SdLcYrIoSdJ6arpEUpKkYTJZlCTNWkk2TXJGkluS3NbmF40r9qQk5yW5M8npSTbrq79rku8muT3JRYNeOppk4yQntDYvB541bv1vzoQm2TnJytb+TUne14p9sz3e3i4FfXaS1yb5TpL3J/kZcGSLfXtcF/ZOcnWSnyZ5T5KHtbaOTPJvff34zdnLJMcAfwB8qLX3oVbmN5e1JnlckpPa83ltkr/r2/Zrk3w7yf9u+/2jJHsN8nxJkmYnk0VJ0mz2MOBfgW2BbYBfAB8aV+YA4M+ALYH7geMAkmwFfAn4R2Az4C3AaUkWDtDuEcCT2rQncOAUZT8AfKCqNmnlT2nx57XHBe1S0O+15V2Aq4EtgGMm2eZLgSXAM4B92/5Nqar+FvgWcFhr77AJin0QeBzwW8Af0nvuDupbvwtwJbA58G7gE0kyXduSpNnJZFGSNGtV1c+q6rSquqeq7qKXXP3huGKfrKpLq+rnwN8DL08yD3g1sKKqVlTVr6vqLGAlsPcATb8cOKaqbq2q62gJ6CTuA56cZPOquruqzplm2z+uqg9W1f1V9YtJyryrtf3/gP8DvHKAPk+pPSf7A2+vqruq6hrgvcBr+opdW1Ufq6oHgBPpJeBbrG3bkqT1k8miJGnWSvKoJP/SLpm8k96lnQta4jPmur75a4GN6J0Z2xZ4WbsE9fYktwPPpZcATeeJE2x3MgcDTwF+mOT8JH80zbavm2b9+DLXtv6src3pPTf9+3ItsFXf8k/GZqrqnjb7mHXQtiRpPWSyKEmazd4M/DawS7vMc+zSzv5LI7fum9+G3pm+n9JLuD5ZVQv6pkdX1bEDtHvjBNudUFVdVVWvBJ4AvAs4NcmjgZqsygDtj2/7x23+58Cj+tb9t9XY9k/pPTfbjtv2DQP0R5I0B5ksSpJmi42SPLJvmg88lt59ire3gWuOmKDeq5PskORRwFHAqe0yyn8DXpRkzyTz2jZ3m2CAnImcAry9DbCzCHjDZAWTvDrJwqr6NXB7C/8auKU9rslvHL61tb018Ebgsy1+IfC8JNskeRzw9nH1bpqsvfacnAIck+SxSbYF/obe8yRJ2gCZLEqSZosV9BLDselIevfrbUzvrNg5wFcmqPdJ4AR6l1A+EvgrgHav4b7AO+glbtcBb2Wwv43vpHeJ5o+Ar7Y2JrMUuCzJ3fQGu9m/qn7RLuM8BvhOuwx21wHaHXM6cAG95PBLwCfaPp1FL3G8uK0/Y1y9DwD7tdFMJ7rP8g30zk5eDXwb+DSwbDX6JUmaQ1I1yNUukiRJkqQNiWcWJUmSJEkdJouSJEmSpA6TRUmSJElSh8miJEmSJKnDZFGSJEmS1DF/1B2YaZtvvnktXrx41N2QJEmSpJG44IILflpVC6crt8Eli4sXL2blypWj7oYkSZIkjUSSawcp52WokiRJkqQOk0VJkiRJUofJoiRJkiSpw2RRkiRJktRhsihJkiRJ6jBZlCRJkiR1mCxKkiRJkjpMFiVJkiRJHSaLkiRJkqQOk0VJkiRJUofJoiRJkiSpw2RRkiRJktRhsihJkiRJ6jBZlCRJkiR1mCxKkiRJkjpMFiVJkiRJHSaLkiRJkqQOk0VJkiRJUofJoiRJkiSpw2RRkiRJktRhsihJkiRJ6jBZlCRJkiR1mCxKkiRJkjrmj7oDkmbG4sO/NOoubNCuOXafUXdBkiRptXhmUZIkSZLUYbIoSZIkSeowWZQkSZIkdQwtWUzyyCTnJbkoyWVJ3tniJyT5UZIL27RTiyfJcUlWJbk4yTP6tnVgkqvadGBf/JlJLml1jkuSYe2PJEmSJG1IhjnAzb3A7lV1d5KNgG8n+XJb99aqOnVc+b2A7du0C/ARYJckmwFHAEuAAi5Isryqbmtl/gI4F1gBLAW+jNaIA6CMlgOgSJIkaX0ytDOL1XN3W9yoTTVFlX2Bk1q9c4AFSbYE9gTOqqpbW4J4FrC0rdukqs6pqgJOAl4yrP2RJEmSpA3JUO9ZTDIvyYXAzfQSvnPbqmPapabvT/KIFtsKuK6v+vUtNlX8+gnikiRJkqS1NNRksaoeqKqdgEXAzkmeCrwd+B3gWcBmwNuG2QeAJIckWZlk5S233DLs5iRJkiRp1puR0VCr6nbg68DSqrqxXWp6L/CvwM6t2A3A1n3VFrXYVPFFE8Qnav/4qlpSVUsWLly4LnZJkiRJkua0YY6GujDJgja/MfBC4IftXkPayKUvAS5tVZYDB7RRUXcF7qiqG4EzgT2SbJpkU2AP4My27s4ku7ZtHQCcPqz9kSRJkqQNyTBHQ90SODHJPHpJ6SlVdUaS/0yyEAhwIfD6Vn4FsDewCrgHOAigqm5NcjRwfit3VFXd2ub/EjgB2JjeKKiOhCpJkiRJ68DQksWquhh4+gTx3ScpX8Chk6xbBiybIL4SeOra9VSSJEmSNN6M3LMoSZIkSZpdTBYlSZIkSR0mi5IkSZKkDpNFSZIkSVKHyaIkSZIkqcNkUZIkSZLUYbIoSZIkSeowWZQkSZIkdZgsSpIkSZI6TBYlSZIkSR0mi5IkSZKkDpNFSZIkSVKHyaIkSZIkqcNkUZIkSZLUYbIoSZIkSeowWZQkSZIkdZgsSpIkSZI6TBYlSZIkSR0mi5IkSZKkDpNFSZIkSVKHyaIkSZIkqcNkUZIkSZLUYbIoSZIkSeowWZQkSZIkdZgsSpIkSZI6hpYsJnlkkvOSXJTksiTvbPHtkpybZFWSzyZ5eIs/oi2vausX923r7S1+ZZI9++JLW2xVksOHtS+SJEmStKEZ5pnFe4Hdq+r3gJ2ApUl2Bd4FvL+qngzcBhzcyh8M3Nbi72/lSLIDsD+wI7AU+Ock85LMAz4M7AXsALyylZUkSZIkraWhJYvVc3db3KhNBewOnNriJwIvafP7tmXa+hckSYufXFX3VtWPgFXAzm1aVVVXV9WvgJNbWUmSJEnSWhrqPYvtDOCFwM3AWcB/AbdX1f2tyPXAVm1+K+A6gLb+DuDx/fFxdSaLS5IkSZLW0lCTxap6oKp2AhbROxP4O8NsbzJJDkmyMsnKW265ZRRdkCRJkqRZZUZGQ62q24GvA88GFiSZ31YtAm5o8zcAWwO09Y8DftYfH1dnsvhE7R9fVUuqasnChQvXyT5JkiRJ0lw2zNFQFyZZ0OY3Bl4IXEEvadyvFTsQOL3NL2/LtPX/WVXV4vu30VK3A7YHzgPOB7Zvo6s+nN4gOMuHtT+SJEmStCGZP32RNbYlcGIbtfRhwClVdUaSy4GTk/wj8APgE638J4BPJlkF3Eov+aOqLktyCnA5cD9waFU9AJDkMOBMYB6wrKouG+L+SJIkSdIGY2jJYlVdDDx9gvjV9O5fHB//JfCySbZ1DHDMBPEVwIq17qwkSZIk6SFm5J5FSZIkSdLsYrIoSZIkSeowWZQkSZIkdZgsSpIkSZI6TBYlSZIkSR0mi5IkSZKkDpNFSZIkSVKHyaIkSZIkqcNkUZIkSZLUYbIoSZIkSeowWZQkSZIkdZgsSpIkSZI6TBYlSZIkSR0mi5IkSZKkDpNFSZIkSVKHyaIkSZIkqcNkUZIkSZLUYbIoSZIkSeqYNllM8rJBYpIkSZKkuWOQM4tvHzAmSZIkSZoj5k+2IslewN7AVkmO61u1CXD/sDsmSZIkSRqdSZNF4MfASuDFwAV98buAvx5mpyRJkiRJozVpslhVFwEXJfl0K7dNVV05Yz2TJEmSJI3MIPcsLgUuBL4CkGSnJMuH2itJkiRJ0kgNkiweCewM3A5QVRcC2w2xT5IkSZKkERskWbyvqu4YF6thdEaSJEmStH4YJFm8LMmfAvOSbJ/kg8B3p6uUZOskX09yeZLLkryxxY9MckOSC9u0d1+dtydZleTKJHv2xZe22Kokh/fFt0tybot/NsnDV2vvJUmSJEkTGiRZfAOwI3Av8BngTuBNA9S7H3hzVe0A7AocmmSHtu79VbVTm1YAtHX7t7aWAv+cZF6SecCHgb2AHYBX9m3nXW1bTwZuAw4eoF+SJEmSpGlMmyxW1T1V9bdV9SxgF+BdVfXLAerdWFXfb/N3AVcAW01RZV/g5Kq6t6p+BKyid6/kzsCqqrq6qn4FnAzsmyTA7sCprf6JwEum65ckSZIkaXrTJotJPp1kkySPBi4BLk/y1tVpJMli4OnAuS10WJKLkyxLsmmLbQVc11ft+habLP544Paqun9cfKL2D0myMsnKW265ZXW6LkmSJEkbpEEuQ92hqu6kd9buy/RGQn3NoA0keQxwGvCmtp2PAE8CdgJuBN67up1eXVV1fFUtqaolCxcuHHZzkiRJkjTrDZIsbpRkI3rJ4vKquo8BR0Nt9U4DPlVVnweoqpuq6oGq+jXwMXqXmQLcAGzdV31Ri00W/xmwIMn8cXFJkiRJ0loaJFn8F+Aa4NHAN5NsS2+Qmym1ewo/AVxRVe/ri2/ZV+ylwKVtfjmwf5JHJNkO2B44Dzgf2L6NfPpweoPgLK+qAr4O7NfqHwicPsD+SJIkSZKmMX+6AlV1HHBcX+jaJM8fYNu/T+9y1UuSXNhi76A3mulO9M5OXgO8rrVzWZJTgMvpjaR6aFU9AJDkMOBMYB6wrKoua9t7G3Bykn8EfkAvOZUkSZIkraVpk0WAJPvQ+0mLR/aFj5qqTlV9G8gEq1ZMUecY4JgJ4ismqldVV/PgZaySJEmSpHVkkNFQPwq8gt7vLQZ4GbDtkPslSZIkSRqhQe5ZfE5VHQDcVlXvBJ4NPGW43ZIkSZIkjdIgyeIv2uM9SZ4I3AdsOUV5SZIkSdIsN8g9i2ckWQC8B/g+vYFpPj7UXkmSJEmSRmqQZPHdVXUvcFqSM+gNcvPL4XZLkiRJkjRKg1yG+r2xmaq6t6ru6I9JkiRJkuaeSc8sJvlvwFbAxkmezoM/g7EJ8KgZ6JskSZIkaUSmugx1T+C1wCLgfX3xu4B3DLFPkiRJkqQRmzRZrKoTgROT/ElVnTaDfZIkSZIkjdi0A9xU1WlJ9gF2pDe4zVj8qGF2TJIkSZI0OtMOcJPko8ArgDfQu2/xZcC2Q+6XJEmSJGmEBhkN9TlVdQBwW1W9E3g28JThdkuSJEmSNEqDJIu/aI/3JHkicB+w5fC6JEmSJEkatWnvWQTOSLIAeA/wfaCAjw+1V5IkSZKkkRpkgJuj2+xpSc4AHllVdwy3W5IkSZKkUZo0WUzyx1Oso6o+P5wuSZIkSZJGbaoziy9qj08AngP8Z1t+PvBdwGRRkiRJkuaoSZPFqjoIIMlXgR2q6sa2vCVwwoz0TpIkSZI0EoOMhrr1WKLY3ARsM6T+SJIkSZLWA4OMhvq1JGcCn2nLrwD+Y3hdkiRJkiSN2iCjoR6W5KXA81ro+Kr6wnC7JUmSJEkapUHOLNKSQxNESZIkSdpADHLPoiRJkiRpA2OyKEmSJEnqmDRZTPK19viumeuOJEmSJGl9MNWZxS2TPAd4cZKnJ3lG/zTdhpNsneTrSS5PclmSN7b4ZknOSnJVe9y0xZPkuCSrklzc30aSA1v5q5Ic2Bd/ZpJLWp3jkmTNnwpJkiRJ0pipBrj5B+DvgUXA+8atK2D3abZ9P/Dmqvp+kscCFyQ5C3gt8LWqOjbJ4cDhwNuAvYDt27QL8BFglySbAUcAS1q7FyRZXlW3tTJ/AZwLrACWAl8eZMclSZIkSZObNFmsqlOBU5P8fVUdvbobrqobgRvb/F1JrgC2AvYFdmvFTgTOppcs7gucVFUFnJNkQZItW9mzqupWgJZwLk1yNrBJVZ3T4icBL8FkUZIkSZLW2iC/s3h0khfz4O8snl1VZ6xOI0kWA0+ndwZwi5ZIAvwE2KLNbwVc11ft+habKn79BPGJ2j8EOARgm222WZ2uS5IkSdIGadrRUJP8E/BG4PI2vTHJ/xq0gSSPAU4D3lRVd/ava2cRa7V6vAaq6viqWlJVSxYuXDjs5iRJkiRp1hvkpzP2AV5YVcuqahm9+wL/aJCNJ9mIXqL4qar6fAvf1C4vpT3e3OI3AFv3VV/UYlPFF00QlyRJkiStpUF/Z3FB3/zjBqnQRib9BHBFVfUPkLMcGBvR9EDg9L74AW1U1F2BO9rlqmcCeyTZtI2cugdwZlt3Z5JdW1sH9G1LkiRJkrQWpr1nEfgn4AdJvg6E3r2Lhw9Q7/eB1wCXJLmwxd4BHAuckuRg4Frg5W3dCmBvYBVwD3AQQFXdmuRo4PxW7qixwW6AvwROADamN7CNg9tIkiRJ0jowyAA3n2kjjz6rhd5WVT8ZoN636SWXE3nBBOULOHSSbS0Dlk0QXwk8dbq+SJIkSZJWzyBnFsd+BmP5kPsiSZIkSVpPDHrPoiRJkiRpA2KyKEmSJEnqmDJZTDIvyQ9nqjOSJEmSpPXDlMliVT0AXJlkmxnqjyRJkiRpPTDIADebApclOQ/4+Viwql48tF5JkiRJkkZqkGTx74feC0mSJEnSemWQ31n8RpJtge2r6j+SPAqYN/yuSZIkSZJGZdrRUJP8BXAq8C8ttBXwxWF2SpIkSZI0WoP8dMahwO8DdwJU1VXAE4bZKUmSJEnSaA2SLN5bVb8aW0gyH6jhdUmSJEmSNGqDJIvfSPIOYOMkLwQ+B/z7cLslSZIkSRqlQZLFw4FbgEuA1wErgL8bZqckSZIkSaM1yGiov05yInAuvctPr6wqL0OVJEmSpDls2mQxyT7AR4H/AgJsl+R1VfXlYXdOkiRJkjQa0yaLwHuB51fVKoAkTwK+BJgsSpIkSdIcNcg9i3eNJYrN1cBdQ+qPJEmSJGk9MOmZxSR/3GZXJlkBnELvnsWXAefPQN8kSZIkSSMy1WWoL+qbvwn4wzZ/C7Dx0HokSZIkSRq5SZPFqjpoJjsiSZIkSVp/DDIa6nbAG4DF/eWr6sXD65YkSZIkaZQGGQ31i8AngH8Hfj3c7kiSJEmS1geDJIu/rKrjht4TSZIkSdJ6Y5Bk8QNJjgC+Ctw7Fqyq7w+tV5IkSZKkkRokWXwa8Bpgdx68DLXasiRJkiRpDnrYAGVeBvxWVf1hVT2/TdMmikmWJbk5yaV9sSOT3JDkwjbt3bfu7UlWJbkyyZ598aUttirJ4X3x7ZKc2+KfTfLwwXdbkiRJkjSVQZLFS4EFa7DtE4ClE8TfX1U7tWkFQJIdgP2BHVudf04yL8k84MPAXsAOwCtbWYB3tW09GbgNOHgN+ihJkiRJmsAgl6EuAH6Y5Hwees/ilD+dUVXfTLJ4wH7sC5xcVfcCP0qyCti5rVtVVVcDJDkZ2DfJFfQug/3TVuZE4EjgIwO2J0mSJEmawiDJ4hHruM3DkhwArATeXFW3AVsB5/SVub7FAK4bF98FeDxwe1XdP0F5SZIkSdJamjZZrKpvrMP2PgIcTW+AnKOB9wJ/tg63P6EkhwCHAGyzzTbDbk6SJEmSZr1p71lMcleSO9v0yyQPJLlzTRqrqpuq6oGq+jXwMR681PQGYOu+ootabLL4z4AFSeaPi0/W7vFVtaSqlixcuHBNui5JkiRJG5Rpk8WqemxVbVJVmwAbA38C/POaNJZky77Fl9IbPAdgObB/kkck2Q7YHjgPOB/Yvo18+nB6g+Asr6oCvg7s1+ofCJy+Jn2SJEmSJHUNMhrqb1TPF4E9pyub5DPA94DfTnJ9koOBdye5JMnFwPOBv27bvQw4Bbgc+ApwaDsDeT9wGHAmcAVwSisL8Dbgb9pgOI8HPrE6+yJJkiRJmty09ywm+eO+xYcBS4BfTlevql45QXjShK6qjgGOmSC+AlgxQfxqHryMVZIkSZK0Dg0yGuqL+ubvB66h91MXkiRJkqQ5apDRUA+aiY5IkiRJktYfkyaLSf5hinpVVUcPoT+SJEmSpPXAVGcWfz5B7NHAwfQGlDFZlCRJkqQ5atJksareOzaf5LHAG4GDgJOB905WT5IkSZI0+015z2KSzYC/AV4FnAg8o6pum4mOSZIkSZJGZ6p7Ft8D/DFwPPC0qrp7xnolSZIkSRqph02x7s3AE4G/A36c5M423ZXkzpnpniRJkiRpFKa6Z3GqRFKSJEmSNIeZEEqSJEmSOkwWJUmSJEkdJouSJEmSpA6TRUmSJElSh8miJEmSJKlj0tFQJUmSNFyLD//SqLuwwbrm2H1G3QVpveeZRUmSJElSh2cWJUlaj3nmabQ8+yRpQ+aZRUmSJElSh8miJEmSJKnDZFGSJEmS1GGyKEmSJEnqMFmUJEmSJHWYLEqSJEmSOkwWJUmSJEkdJouSJEmSpI6hJYtJliW5OcmlfbHNkpyV5Kr2uGmLJ8lxSVYluTjJM/rqHNjKX5XkwL74M5Nc0uoclyTD2hdJkiRJ2tAM88ziCcDScbHDga9V1fbA19oywF7A9m06BPgI9JJL4AhgF2Bn4IixBLOV+Yu+euPbkiRJkiStoaEli1X1TeDWceF9gRPb/InAS/riJ1XPOcCCJFsCewJnVdWtVXUbcBawtK3bpKrOqaoCTurbliRJkiRpLc30PYtbVNWNbf4nwBZtfivgur5y17fYVPHrJ4hLkiRJktaBkQ1w084I1ky0leSQJCuTrLzllltmoklJkiRJmtVmOlm8qV1CSnu8ucVvALbuK7eoxaaKL5ogPqGqOr6qllTVkoULF671TkiSJEnSXDfTyeJyYGxE0wOB0/viB7RRUXcF7miXq54J7JFk0zawzR7AmW3dnUl2baOgHtC3LUmSJEnSWpo/rA0n+QywG7B5kuvpjWp6LHBKkoOBa4GXt+IrgL2BVcA9wEEAVXVrkqOB81u5o6pqbNCcv6Q34urGwJfbJEmSJElaB4aWLFbVKydZ9YIJyhZw6CTbWQYsmyC+Enjq2vRRkiRJkjSxkQ1wI0mSJElafw3tzKIkaeYsPvxLo+7CBuuaY/cZdRckSRoKzyxKkiRJkjpMFiVJkiRJHSaLkiRJkqQOk0VJkiRJUofJoiRJkiSpw2RRkiRJktRhsihJkiRJ6jBZlCRJkiR1mCxKkiRJkjpMFiVJkiRJHSaLkiRJkqQOk0VJkiRJUofJoiRJkiSpw2RRkiRJktRhsihJkiRJ6jBZlCRJkiR1mCxKkiRJkjpMFiVJkiRJHSaLkiRJkqQOk0VJkiRJUofJoiRJkiSpw2RRkiRJktRhsihJkiRJ6hhJspjkmiSXJLkwycoW2yzJWUmuao+btniSHJdkVZKLkzyjbzsHtvJXJTlwFPsiSZIkSXPRKM8sPr+qdqqqJW35cOBrVbU98LW2DLAXsH2bDgE+Ar3kEjgC2AXYGThiLMGUJEmSJK2d9eky1H2BE9v8icBL+uInVc85wIIkWwJ7AmdV1a1VdRtwFrB0pjstSZIkSXPRqJLFAr6a5IIkh7TYFlV1Y5v/CbBFm98KuK6v7vUtNllckiRJkrSW5o+o3edW1Q1JngCcleSH/SurqpLUumqsJaSHAGyzzTbrarOSJEmSNGeN5MxiVd3QHm8GvkDvnsOb2uWltMebW/EbgK37qi9qscniE7V3fFUtqaolCxcuXJe7IkmSJElz0owni0keneSxY/PAHsClwHJgbETTA4HT2/xy4IA2KuquwB3tctUzgT2SbNoGttmjxSRJkiRJa2kUl6FuAXwhyVj7n66qryQ5HzglycHAtcDLW/kVwN7AKuAe4CCAqro1ydHA+a3cUVV168zthiRJkiTNXTOeLFbV1cDvTRD/GfCCCeIFHDrJtpYBy9Z1HyVJkiRpQ7c+/XSGJEmSJGk9YbIoSZIkSeowWZQkSZIkdZgsSpIkSZI6TBYlSZIkSR0mi5IkSZKkDpNFSZIkSVKHyaIkSZIkqWP+qDsgSZIkzTWLD//SqLuwQbvm2H1G3YU5wTOLkiRJkqQOk0VJkiRJUofJoiRJkiSpw2RRkiRJktRhsihJkiRJ6jBZlCRJkiR1mCxKkiRJkjpMFiVJkiRJHSaLkiRJkqQOk0VJkiRJUofJoiRJkiSpw2RRkiRJktRhsihJkiRJ6jBZlCRJkiR1mCxKkiRJkjpMFiVJkiRJHbM+WUyyNMmVSVYlOXzU/ZEkSZKkuWBWJ4tJ5gEfBvYCdgBemWSH0fZKkiRJkma/WZ0sAjsDq6rq6qr6FXAysO+I+yRJkiRJs95sTxa3Aq7rW76+xSRJkiRJayFVNeo+rLEk+wFLq+rP2/JrgF2q6rBx5Q4BDmmLvw1cOaMd1UzZHPjpqDuhofH1nbt8bec2X9+5zdd37vK1ndu2raqF0xWaPxM9GaIbgK37lhe12ENU1fHA8TPVKY1GkpVVtWTU/dBw+PrOXb62c5uv79zm6zt3+doKZv9lqOcD2yfZLsnDgf2B5SPukyRJkiTNerP6zGJV3Z/kMOBMYB6wrKouG3G3JEmSJGnWm9XJIkBVrQBWjLofWi94qfHc5us7d/nazm2+vnObr+/c5Wur2T3AjSRJkiRpOGb7PYuSJEmSpCEwWdSMSvLaJB8adT/GJFmQ5C/XsO6KJAvWdZ80sSS7JXnOGtRbkuS4YfRpQ5FkcZJL17DuO6ZZv84+R9O1NUW9jyfZYV30YbZb347RayLJ3e3xiUlOHXV/NLn+91uS1yc5YNR9mq1my3FNsSAjAAAIsElEQVR6dSW5Jsnmbf67o+jDhs5kURu6BcCEyWKSKe/praq9q+r2ofRqAzLd89xnN2DCZHGqbVTVyqr6qzXomtaNCf8JSc/D1vHnaMq2JqtUVX9eVZevoz5oPVFVP66q/Ubdj7lgNY7Ta6yqPlpVJw27HU1oJo/Ta6yqVvsLY609k0WtlfHfZCV5S5Ijk5yd5F1Jzkvyf5P8wQR190nyvSSbJzkhyXFJvpvk6iT7tTJJ8p4klya5JMkrWvzDSV7c5r+QZFmb/7Mkx7R+XZHkY0kuS/LVJBtPsAvHAk9KcmFrZ7ck30qyHLi8bfOLSS5o2zmkr//XtL4P2tacl+SAJBcnuSjJJ5O8KMm5SX6Q5D+SbNHKHdnWfwf4ZJId23vlwlZ/+3HbXQy8HvjrVuYP2nvmo0nOBd6dZOf2fvpBex/9dqu7W5Iz+tpd1t6fVyfZYJLI9j79YZJPtffrqUkeleSZSb7R3uNnJtmylX9mex0vAg7t28689lk5v71Wr2vxLZN8s70+l7bX6Fhg4xb7VOvDlUlOAi4Fts5DvzWe7LN2d/tcX5TknLH30bj9G6StjyRZ2bb/zr66ZydZMmhbs0lm+TE6ybFJ+t9/R7Z9eEySryX5fmt33+n2XT0Z3nH6Ye3zvKAvdlWSLSZrY1z9I5O8ZehPwHosc/84/fok7+lb7j+zPOF2x9W/e108z1pNVeXktMYTsBi4tG/5LcCRwNnAe1tsb+A/2vxrgQ8BLwW+BWza4icAn6P3BcYOwKoW/xPgLHo/jbIF8P+ALen9puZ7WpnzgHPa/L8Ce7Z+3Q/s1OKnAK8eoP+7AT8HtuuLbdYeN6Z34Hx8W74G2HzQtub6BOwI/F9g87HnDdiUBwfS+vO+98SRwAXAxm35g8Cr2vzDx+Ljtn8k8Ja+5ROAM4B5bXkTYH6b/+/AaX2v6Rl92/gu8Ij22v0M2GjUz90MvT6LgQJ+vy0vA97ano+FLfYKej9BBHAx8Lw2/56xzwlwCPB3bf4RwEpgO+DNwN+2+DzgsW3+7nF9+DWwa1/smv73THsc/1kr4EVt/t1j7U+wj9O1tVlf/84Gfrctnw0sWZ22ZsvE7D9GPx34Rt/y5cDW9EZz36TFNgdW8eCx5u6J9t1pRo7THwAOavO79L2vJmvjtcCH+tp7y7ra19k4MceP08BC2rGjLX8ZeO402+1v++7Jnjun4U2z/qcztF77fHu8gN7BZ8zuwBJgj6q6sy/+xar6NXB53zdSzwU+U1UPADcl+QbwLHr/xLwpvfuMLgc2bd+0PRv4K+DxwI+q6sJJ+jCV86rqR33Lf5XkpW1+a2B7eklGvzVtay7ZHfhcVf0UoKpuTfI04LPttXk40P+8Lq+qX7T57wF/m2QR8PmqumrANj/X3hsAjwNObN92F7DRJHW+VFX3AvcmuZneP7jXD9jebHddVX2nzf8bvUuPngqclQR6/zzc2M4MLKiqb7aynwT2avN7AL87dmaJ3vO+PXA+sCzJRvQ+y2Ofh/GurapzJlk32WftV/S+GIDe5+uFA+7v+LZe3r6xnk8vodmB3j9b/da0rdlovT9GV9UPkjwhyRPp/aN5W1Vd195n/yvJ8+j9Y7sVvc/yT9b86dggDPs4/VngH+h9KbB/WwZYNEUbeqg5e5yuqlvSuzJhV+Aq4HeAsX0d5H8tjYCXoWpt3c9D30eP7Ju/tz0+wEN/0/O/gMcCTxm3rXv75jNVo1V1A737DZcC36T3j8nL6X3rdNcE23sAmJ9k63apxYVJXj/J5n/+m04ku9E7S/Xsqvo94Afj9nGivo/f3w3ZB+l9a/w04HU89Ln7zfNcVZ8GXgz8AliRZPckh/a9Vk+cZPs/75s/Gvh6VT0VeBETv06wYb9W438r6S7gsqraqU1Pq6o9ptlGgDf01dmuqr7a/mF5HnADcEImH6ji5xMFp/ms3VdVY30f+yzP63t/HDVdW0m2o3dW7QVV9bvAl5j4PdJpa5JtzxZz4Rj9OWA/emdUxpKPV9FLHp9ZVTsBNzH5Z15TW5fH6e8BT06yEHgJD34hMVUbeqi5fpw+md6x4E+AL1RVrcb/WhoBk0WtrZuAJyR5fJJHAH80QJ1r6R0kTkqy4zRlvwW8oh1wFtI7yJ3X1p0DvIkH/xF5S3ucVFVd13fw/Ci9g/Bjp6jyOHrfZN+T5HeAXafp74bsP4GXJXk8QJLN6D1/N7T1B05WMclvAVdX1XHA6fQuD/xw32v1YwZ7rcbaeu1a7cnctU2SZ7f5P6X3GVo4FkuyUZIdqzeQwe1JntvKvqpvG2cC/6N9M02SpyR5dJJtgZuq6mPAx4FntPL3jZWdxmp91qrqgb73xz8M0NYm9P4BuqOdFdtrknJzzWw/RkMvQdyfXsL4uRZ7HHBzVd2X5PnAtgPsl4Z8nG7JwheA9wFXVNXYmaGB2hAw94/TXwD2BV5JL3Fc7e1qZpksaq1U1X3AUfT+OTgL+OGA9X5I78D2uSRPmqLoF+hdJnYRvT9y/7Oqxi4z+ha9e9RWAd+nd+/FlP+ITNCPnwHfSe9G7/dMUOQr9L4du4LeYDiTXZaxwauqy4BjgG+kd7P9++jdg/K5JBcAP52i+suBS5NcSO9ym4lGxPt34KXtG8rOYBz07pH4pyQ/YPafDRqWK4FD2/t5U3rf9u8HvKu9Zhfy4IizBwEfbq9J/1mkj9O7rPD76Q0e8i/0nu/dgIva8/8KevcuARwPXJzkU9P0bV181iZtq6ouovdt9Q+BT/PgpU9z2mw/Rre+XEbvi6IbqurGFv4UsCTJJcABDLhfG7oZOE5DL7l/NQ+eBWY12tAcP05X1W3AFcC2VTX2xZL/a63Hxm42liTNYemNKHtGu0xXkrSe8Tit9ZFnFiVJkiRJHZ5ZlCRJkiR1eGZRkiRJktRhsihJkiRJ6jBZlCRJkiR1mCxKkiRJkjpMFiVJkiRJHSaLkiRJkqSO/w8mkV7bNMujlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Load dataset\"\"\"\n",
    "\n",
    "data = []\n",
    "class_label = []\n",
    "heading_label = []\n",
    "\n",
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    class_label = f['class'][:]\n",
    "    heading_label = f['heading'][:]\n",
    "    return (data, class_label, heading_label)\n",
    "\n",
    "data_train, class_label_train, heading_label_train = load_h5(data_train_path)\n",
    "data_vali, class_label_vali, heading_label_vali = load_h5(data_vali_path)\n",
    "\n",
    "data.append(data_train)\n",
    "data.append(data_vali)\n",
    "class_label.append(class_label_train)\n",
    "class_label.append(class_label_vali)\n",
    "heading_label.append(heading_label_train)\n",
    "heading_label.append(heading_label_vali)\n",
    "\n",
    "\"\"\" Data statistics \"\"\"\n",
    "\n",
    "label_list = [0,1,2]\n",
    "\n",
    "y_val = []\n",
    "for i in range( len ( data) ):\n",
    "    for j in range ( len ( label_list ) ):\n",
    "        y_val.append(np.sum(class_label[i] == label_list[j]))\n",
    "\n",
    "x_name=('unknown-train', 'cars-train','pedestrian-train',\n",
    "        'unknown-vali', 'cars-vali', 'pedestrian-vali')\n",
    "\n",
    "index = range( len(x_name) )\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(index, y_val, tick_label=x_name, align='center')\n",
    "plt.ylabel('Number of dataset')\n",
    "plt.title('Label distribution')\n",
    "plt.xlim( -1, len(x_name))\n",
    "plt.ylim( 0, np.max(y_val) * 1.1 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "INFO:tensorflow:Summary name classify loss is illegal; using classify_loss instead.\n",
      "INFO:tensorflow:Summary name mat loss is illegal; using mat_loss instead.\n",
      "2018-12-04 09:02:56.869336  \n",
      "\n",
      " Train one epoch   1 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:05:58.182419  [Epoch 0] mean loss: 0.092675\n",
      "2018-12-04 09:05:58.184429  [Epoch 0] heading rmse[deg]: 192.540236\n",
      "2018-12-04 09:05:58.186204  [Epoch 0] class accuracy: 0.495440\n",
      "2018-12-04 09:05:58.188131  [Epoch 0] avg class acc: 0.420862\n",
      "2018-12-04 09:05:58.189847  [Epoch 0] indivisual [0] class recall: 0.463424\n",
      "2018-12-04 09:05:58.191440  [Epoch 0] indivisual [0] class precision: 0.479092\n",
      "2018-12-04 09:05:58.193069  [Epoch 0] indivisual [1] class recall: 0.598068\n",
      "2018-12-04 09:05:58.194546  [Epoch 0] indivisual [1] class precision: 0.503996\n",
      "2018-12-04 09:05:58.196095  [Epoch 0] indivisual [2] class recall: 0.201095\n",
      "2018-12-04 09:05:58.197573  [Epoch 0] indivisual [2] class precision: 0.554884\n",
      "2018-12-04 09:05:58.199030   Evaluation one (validation set) epoch   1 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:46<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:06:44.648326  [Epoch 0] Validation mean loss: 0.295129\n",
      "2018-12-04 09:06:44.650324  [Epoch 0] Validation heading rmse[deg]: 394.824084\n",
      "2018-12-04 09:06:44.652140  [Epoch 0] Validation class accuracy: 0.555204\n",
      "2018-12-04 09:06:44.654084  [Epoch 0] Validation avg class acc: 0.325274\n",
      "2018-12-04 09:06:44.655950  [Epoch 0] Validation indivisual [0] class recall: 0.140805\n",
      "2018-12-04 09:06:44.657724  [Epoch 0] Validation indivisual [0] class precision: 0.507761\n",
      "2018-12-04 09:06:44.659402  [Epoch 0] Validation indivisual [1] class recall: 0.392955\n",
      "2018-12-04 09:06:44.660990  [Epoch 0] Validation indivisual [1] class precision: 0.515738\n",
      "2018-12-04 09:06:44.662694  [Epoch 0] Validation indivisual [2] class recall: 0.442063\n",
      "2018-12-04 09:06:44.664406  [Epoch 0] Validation indivisual [2] class precision: 0.918205\n",
      "2018-12-04 09:06:44.666128  \n",
      "\n",
      " Train one epoch   2 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:59<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:09:44.902631  [Epoch 1] mean loss: 0.037502\n",
      "2018-12-04 09:09:44.904399  [Epoch 1] heading rmse[deg]: 122.461812\n",
      "2018-12-04 09:09:44.905919  [Epoch 1] class accuracy: 0.677240\n",
      "2018-12-04 09:09:44.907539  [Epoch 1] avg class acc: 0.702831\n",
      "2018-12-04 09:09:44.909062  [Epoch 1] indivisual [0] class recall: 0.574299\n",
      "2018-12-04 09:09:44.910597  [Epoch 1] indivisual [0] class precision: 0.653706\n",
      "2018-12-04 09:09:44.912067  [Epoch 1] indivisual [1] class recall: 0.751088\n",
      "2018-12-04 09:09:44.913449  [Epoch 1] indivisual [1] class precision: 0.670446\n",
      "2018-12-04 09:09:44.914907  [Epoch 1] indivisual [2] class recall: 0.783107\n",
      "2018-12-04 09:09:44.916725  [Epoch 1] indivisual [2] class precision: 0.789892\n",
      "2018-12-04 09:09:44.918395   Evaluation one (validation set) epoch   2 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:10:31.113402  [Epoch 1] Validation mean loss: 0.028002\n",
      "2018-12-04 09:10:31.115371  [Epoch 1] Validation heading rmse[deg]: 103.859673\n",
      "2018-12-04 09:10:31.117126  [Epoch 1] Validation class accuracy: 0.776357\n",
      "2018-12-04 09:10:31.118879  [Epoch 1] Validation avg class acc: 0.412746\n",
      "2018-12-04 09:10:31.120503  [Epoch 1] Validation indivisual [0] class recall: 0.308676\n",
      "2018-12-04 09:10:31.122055  [Epoch 1] Validation indivisual [0] class precision: 0.857404\n",
      "2018-12-04 09:10:31.129110  [Epoch 1] Validation indivisual [1] class recall: 0.482621\n",
      "2018-12-04 09:10:31.131089  [Epoch 1] Validation indivisual [1] class precision: 0.711491\n",
      "2018-12-04 09:10:31.132684  [Epoch 1] Validation indivisual [2] class recall: 0.446941\n",
      "2018-12-04 09:10:31.134237  [Epoch 1] Validation indivisual [2] class precision: 0.903564\n",
      "2018-12-04 09:10:31.135857  \n",
      "\n",
      " Train one epoch   3 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:59<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:13:31.384183  [Epoch 2] mean loss: 0.029769\n",
      "2018-12-04 09:13:31.386473  [Epoch 2] heading rmse[deg]: 110.086543\n",
      "2018-12-04 09:13:31.388371  [Epoch 2] class accuracy: 0.767240\n",
      "2018-12-04 09:13:31.390302  [Epoch 2] avg class acc: 0.793099\n",
      "2018-12-04 09:13:31.392104  [Epoch 2] indivisual [0] class recall: 0.686645\n",
      "2018-12-04 09:13:31.393869  [Epoch 2] indivisual [0] class precision: 0.758261\n",
      "2018-12-04 09:13:31.395466  [Epoch 2] indivisual [1] class recall: 0.818044\n",
      "2018-12-04 09:13:31.397094  [Epoch 2] indivisual [1] class precision: 0.756080\n",
      "2018-12-04 09:13:31.398669  [Epoch 2] indivisual [2] class recall: 0.874606\n",
      "2018-12-04 09:13:31.400273  [Epoch 2] indivisual [2] class precision: 0.843011\n",
      "2018-12-04 09:13:31.401812   Evaluation one (validation set) epoch   3 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:14:17.413955  [Epoch 2] Validation mean loss: 0.025186\n",
      "2018-12-04 09:14:17.415786  [Epoch 2] Validation heading rmse[deg]: 103.955251\n",
      "2018-12-04 09:14:17.417366  [Epoch 2] Validation class accuracy: 0.833606\n",
      "2018-12-04 09:14:17.418996  [Epoch 2] Validation avg class acc: 0.439971\n",
      "2018-12-04 09:14:17.420961  [Epoch 2] Validation indivisual [0] class recall: 0.460430\n",
      "2018-12-04 09:14:17.422713  [Epoch 2] Validation indivisual [0] class precision: 0.770746\n",
      "2018-12-04 09:14:17.424561  [Epoch 2] Validation indivisual [1] class recall: 0.396840\n",
      "2018-12-04 09:14:17.426291  [Epoch 2] Validation indivisual [1] class precision: 0.923483\n",
      "2018-12-04 09:14:17.428028  [Epoch 2] Validation indivisual [2] class recall: 0.462643\n",
      "2018-12-04 09:14:17.429725  [Epoch 2] Validation indivisual [2] class precision: 0.818512\n",
      "2018-12-04 09:14:17.431329  \n",
      "\n",
      " Train one epoch   4 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:59<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:17:17.606938  [Epoch 3] mean loss: 0.027275\n",
      "2018-12-04 09:17:17.608924  [Epoch 3] heading rmse[deg]: 106.615013\n",
      "2018-12-04 09:17:17.610674  [Epoch 3] class accuracy: 0.797880\n",
      "2018-12-04 09:17:17.612547  [Epoch 3] avg class acc: 0.820172\n",
      "2018-12-04 09:17:17.615297  [Epoch 3] indivisual [0] class recall: 0.740585\n",
      "2018-12-04 09:17:17.616919  [Epoch 3] indivisual [0] class precision: 0.787016\n",
      "2018-12-04 09:17:17.618504  [Epoch 3] indivisual [1] class recall: 0.831121\n",
      "2018-12-04 09:17:17.620079  [Epoch 3] indivisual [1] class precision: 0.794398\n",
      "2018-12-04 09:17:17.621631  [Epoch 3] indivisual [2] class recall: 0.888810\n",
      "2018-12-04 09:17:17.623214  [Epoch 3] indivisual [2] class precision: 0.850034\n",
      "2018-12-04 09:17:17.624741   Evaluation one (validation set) epoch   4 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:18:03.218226  [Epoch 3] Validation mean loss: 0.025630\n",
      "2018-12-04 09:18:03.220170  [Epoch 3] Validation heading rmse[deg]: 104.040689\n",
      "2018-12-04 09:18:03.222011  [Epoch 3] Validation class accuracy: 0.829182\n",
      "2018-12-04 09:18:03.224045  [Epoch 3] Validation avg class acc: 0.427882\n",
      "2018-12-04 09:18:03.225875  [Epoch 3] Validation indivisual [0] class recall: 0.351658\n",
      "2018-12-04 09:18:03.227567  [Epoch 3] Validation indivisual [0] class precision: 0.917937\n",
      "2018-12-04 09:18:03.229239  [Epoch 3] Validation indivisual [1] class recall: 0.507287\n",
      "2018-12-04 09:18:03.230749  [Epoch 3] Validation indivisual [1] class precision: 0.761960\n",
      "2018-12-04 09:18:03.232429  [Epoch 3] Validation indivisual [2] class recall: 0.424702\n",
      "2018-12-04 09:18:03.234040  [Epoch 3] Validation indivisual [2] class precision: 0.931165\n",
      "2018-12-04 09:18:03.235699  \n",
      "\n",
      " Train one epoch   5 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:59<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:21:03.405708  [Epoch 4] mean loss: 0.025829\n",
      "2018-12-04 09:21:03.407781  [Epoch 4] heading rmse[deg]: 105.311423\n",
      "2018-12-04 09:21:03.409625  [Epoch 4] class accuracy: 0.828360\n",
      "2018-12-04 09:21:03.411453  [Epoch 4] avg class acc: 0.846510\n",
      "2018-12-04 09:21:03.413096  [Epoch 4] indivisual [0] class recall: 0.785760\n",
      "2018-12-04 09:21:03.414710  [Epoch 4] indivisual [0] class precision: 0.815114\n",
      "2018-12-04 09:21:03.416449  [Epoch 4] indivisual [1] class recall: 0.851312\n",
      "2018-12-04 09:21:03.418162  [Epoch 4] indivisual [1] class precision: 0.835371\n",
      "2018-12-04 09:21:03.419910  [Epoch 4] indivisual [2] class recall: 0.902457\n",
      "2018-12-04 09:21:03.421941  [Epoch 4] indivisual [2] class precision: 0.848217\n",
      "2018-12-04 09:21:03.424116   Evaluation one (validation set) epoch   5 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:21:48.875913  [Epoch 4] Validation mean loss: 0.023338\n",
      "2018-12-04 09:21:48.877476  [Epoch 4] Validation heading rmse[deg]: 104.210912\n",
      "2018-12-04 09:21:48.878785  [Epoch 4] Validation class accuracy: 0.892007\n",
      "2018-12-04 09:21:48.880221  [Epoch 4] Validation avg class acc: 0.465336\n",
      "2018-12-04 09:21:48.881612  [Epoch 4] Validation indivisual [0] class recall: 0.481359\n",
      "2018-12-04 09:21:48.882877  [Epoch 4] Validation indivisual [0] class precision: 0.844088\n",
      "2018-12-04 09:21:48.884201  [Epoch 4] Validation indivisual [1] class recall: 0.441119\n",
      "2018-12-04 09:21:48.885431  [Epoch 4] Validation indivisual [1] class precision: 0.980171\n",
      "2018-12-04 09:21:48.886634  [Epoch 4] Validation indivisual [2] class recall: 0.473529\n",
      "2018-12-04 09:21:48.887870  [Epoch 4] Validation indivisual [2] class precision: 0.801410\n",
      "2018-12-04 09:21:48.889154  \n",
      "\n",
      " Train one epoch   6 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:59<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:24:48.964175  [Epoch 5] mean loss: 0.024561\n",
      "2018-12-04 09:24:48.966052  [Epoch 5] heading rmse[deg]: 104.861060\n",
      "2018-12-04 09:24:48.967938  [Epoch 5] class accuracy: 0.851160\n",
      "2018-12-04 09:24:48.970090  [Epoch 5] avg class acc: 0.866782\n",
      "2018-12-04 09:24:48.972175  [Epoch 5] indivisual [0] class recall: 0.819166\n",
      "2018-12-04 09:24:48.973966  [Epoch 5] indivisual [0] class precision: 0.838941\n",
      "2018-12-04 09:24:48.975836  [Epoch 5] indivisual [1] class recall: 0.866821\n",
      "2018-12-04 09:24:48.977598  [Epoch 5] indivisual [1] class precision: 0.858339\n",
      "2018-12-04 09:24:48.979324  [Epoch 5] indivisual [2] class recall: 0.914358\n",
      "2018-12-04 09:24:48.981060  [Epoch 5] indivisual [2] class precision: 0.868124\n",
      "2018-12-04 09:24:48.982701   Evaluation one (validation set) epoch   6 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:25:34.431674  [Epoch 5] Validation mean loss: 0.022224\n",
      "2018-12-04 09:25:34.433487  [Epoch 5] Validation heading rmse[deg]: 103.527116\n",
      "2018-12-04 09:25:34.446939  [Epoch 5] Validation class accuracy: 0.910892\n",
      "2018-12-04 09:25:34.449143  [Epoch 5] Validation avg class acc: 0.468793\n",
      "2018-12-04 09:25:34.451075  [Epoch 5] Validation indivisual [0] class recall: 0.439412\n",
      "2018-12-04 09:25:34.452707  [Epoch 5] Validation indivisual [0] class precision: 0.948645\n",
      "2018-12-04 09:25:34.454468  [Epoch 5] Validation indivisual [1] class recall: 0.507069\n",
      "2018-12-04 09:25:34.456263  [Epoch 5] Validation indivisual [1] class precision: 0.878889\n",
      "2018-12-04 09:25:34.457948  [Epoch 5] Validation indivisual [2] class recall: 0.459900\n",
      "2018-12-04 09:25:34.459720  [Epoch 5] Validation indivisual [2] class precision: 0.922195\n",
      "2018-12-04 09:25:34.461396  \n",
      "\n",
      " Train one epoch   7 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:28:34.295546  [Epoch 6] mean loss: 0.024655\n",
      "2018-12-04 09:28:34.297555  [Epoch 6] heading rmse[deg]: 104.933817\n",
      "2018-12-04 09:28:34.299427  [Epoch 6] class accuracy: 0.845880\n",
      "2018-12-04 09:28:34.301394  [Epoch 6] avg class acc: 0.860760\n",
      "2018-12-04 09:28:34.303403  [Epoch 6] indivisual [0] class recall: 0.812771\n",
      "2018-12-04 09:28:34.305236  [Epoch 6] indivisual [0] class precision: 0.836458\n",
      "2018-12-04 09:28:34.306938  [Epoch 6] indivisual [1] class recall: 0.864173\n",
      "2018-12-04 09:28:34.308666  [Epoch 6] indivisual [1] class precision: 0.849727\n",
      "2018-12-04 09:28:34.310589  [Epoch 6] indivisual [2] class recall: 0.905336\n",
      "2018-12-04 09:28:34.316570  [Epoch 6] indivisual [2] class precision: 0.866084\n",
      "2018-12-04 09:28:34.318390   Evaluation one (validation set) epoch   7 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:29:19.786709  [Epoch 6] Validation mean loss: 0.021407\n",
      "2018-12-04 09:29:19.788613  [Epoch 6] Validation heading rmse[deg]: 105.944795\n",
      "2018-12-04 09:29:19.790217  [Epoch 6] Validation class accuracy: 0.941747\n",
      "2018-12-04 09:29:19.791945  [Epoch 6] Validation avg class acc: 0.485778\n",
      "2018-12-04 09:29:19.793777  [Epoch 6] Validation indivisual [0] class recall: 0.469411\n",
      "2018-12-04 09:29:19.795842  [Epoch 6] Validation indivisual [0] class precision: 0.958337\n",
      "2018-12-04 09:29:19.797653  [Epoch 6] Validation indivisual [1] class recall: 0.508676\n",
      "2018-12-04 09:29:19.799397  [Epoch 6] Validation indivisual [1] class precision: 0.942614\n",
      "2018-12-04 09:29:19.801101  [Epoch 6] Validation indivisual [2] class recall: 0.479247\n",
      "2018-12-04 09:29:19.802787  [Epoch 6] Validation indivisual [2] class precision: 0.878798\n",
      "2018-12-04 09:29:19.804514  \n",
      "\n",
      " Train one epoch   8 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:32:19.801375  [Epoch 7] mean loss: 0.023578\n",
      "2018-12-04 09:32:19.803426  [Epoch 7] heading rmse[deg]: 105.015631\n",
      "2018-12-04 09:32:19.805437  [Epoch 7] class accuracy: 0.868760\n",
      "2018-12-04 09:32:19.807338  [Epoch 7] avg class acc: 0.880095\n",
      "2018-12-04 09:32:19.809085  [Epoch 7] indivisual [0] class recall: 0.844148\n",
      "2018-12-04 09:32:19.810735  [Epoch 7] indivisual [0] class precision: 0.856761\n",
      "2018-12-04 09:32:19.812419  [Epoch 7] indivisual [1] class recall: 0.881357\n",
      "2018-12-04 09:32:19.814092  [Epoch 7] indivisual [1] class precision: 0.880805\n",
      "2018-12-04 09:32:19.815744  [Epoch 7] indivisual [2] class recall: 0.914781\n",
      "2018-12-04 09:32:19.817359  [Epoch 7] indivisual [2] class precision: 0.867248\n",
      "2018-12-04 09:32:19.818955   Evaluation one (validation set) epoch   8 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:33:05.234016  [Epoch 7] Validation mean loss: 0.019845\n",
      "2018-12-04 09:33:05.235959  [Epoch 7] Validation heading rmse[deg]: 104.140277\n",
      "2018-12-04 09:33:05.237920  [Epoch 7] Validation class accuracy: 0.967100\n",
      "2018-12-04 09:33:05.240062  [Epoch 7] Validation avg class acc: 0.492360\n",
      "2018-12-04 09:33:05.241828  [Epoch 7] Validation indivisual [0] class recall: 0.499978\n",
      "2018-12-04 09:33:05.243567  [Epoch 7] Validation indivisual [0] class precision: 0.961551\n",
      "2018-12-04 09:33:05.245498  [Epoch 7] Validation indivisual [1] class recall: 0.511387\n",
      "2018-12-04 09:33:05.247228  [Epoch 7] Validation indivisual [1] class precision: 0.987225\n",
      "2018-12-04 09:33:05.248864  [Epoch 7] Validation indivisual [2] class recall: 0.465716\n",
      "2018-12-04 09:33:05.250537  [Epoch 7] Validation indivisual [2] class precision: 0.907873\n",
      "2018-12-04 09:33:05.252193  \n",
      "\n",
      " Train one epoch   9 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:59<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:36:05.481570  [Epoch 8] mean loss: 0.021677\n",
      "2018-12-04 09:36:05.483474  [Epoch 8] heading rmse[deg]: 104.235521\n",
      "2018-12-04 09:36:05.485406  [Epoch 8] class accuracy: 0.907680\n",
      "2018-12-04 09:36:05.487134  [Epoch 8] avg class acc: 0.913666\n",
      "2018-12-04 09:36:05.488770  [Epoch 8] indivisual [0] class recall: 0.885113\n",
      "2018-12-04 09:36:05.490422  [Epoch 8] indivisual [0] class precision: 0.904740\n",
      "2018-12-04 09:36:05.492108  [Epoch 8] indivisual [1] class recall: 0.923940\n",
      "2018-12-04 09:36:05.494080  [Epoch 8] indivisual [1] class precision: 0.916726\n",
      "2018-12-04 09:36:05.496193  [Epoch 8] indivisual [2] class recall: 0.931944\n",
      "2018-12-04 09:36:05.497932  [Epoch 8] indivisual [2] class precision: 0.884932\n",
      "2018-12-04 09:36:05.499637   Evaluation one (validation set) epoch   9 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:36:50.945549  [Epoch 8] Validation mean loss: 0.019568\n",
      "2018-12-04 09:36:50.947414  [Epoch 8] Validation heading rmse[deg]: 103.762068\n",
      "2018-12-04 09:36:50.949047  [Epoch 8] Validation class accuracy: 0.962454\n",
      "2018-12-04 09:36:50.950641  [Epoch 8] Validation avg class acc: 0.490936\n",
      "2018-12-04 09:36:50.952356  [Epoch 8] Validation indivisual [0] class recall: 0.497442\n",
      "2018-12-04 09:36:50.953907  [Epoch 8] Validation indivisual [0] class precision: 0.955638\n",
      "2018-12-04 09:36:50.955431  [Epoch 8] Validation indivisual [1] class recall: 0.508291\n",
      "2018-12-04 09:36:50.957022  [Epoch 8] Validation indivisual [1] class precision: 0.990325\n",
      "2018-12-04 09:36:50.958525  [Epoch 8] Validation indivisual [2] class recall: 0.467075\n",
      "2018-12-04 09:36:50.960115  [Epoch 8] Validation indivisual [2] class precision: 0.882069\n",
      "2018-12-04 09:36:50.961663  \n",
      "\n",
      " Train one epoch  10 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:39:51.036724  [Epoch 9] mean loss: 0.021449\n",
      "2018-12-04 09:39:51.038669  [Epoch 9] heading rmse[deg]: 104.365021\n",
      "2018-12-04 09:39:51.040567  [Epoch 9] class accuracy: 0.911960\n",
      "2018-12-04 09:39:51.042454  [Epoch 9] avg class acc: 0.918824\n",
      "2018-12-04 09:39:51.044552  [Epoch 9] indivisual [0] class recall: 0.888492\n",
      "2018-12-04 09:39:51.046495  [Epoch 9] indivisual [0] class precision: 0.908214\n",
      "2018-12-04 09:39:51.048207  [Epoch 9] indivisual [1] class recall: 0.927576\n",
      "2018-12-04 09:39:51.049953  [Epoch 9] indivisual [1] class precision: 0.923478\n",
      "2018-12-04 09:39:51.051682  [Epoch 9] indivisual [2] class recall: 0.940404\n",
      "2018-12-04 09:39:51.053408  [Epoch 9] indivisual [2] class precision: 0.881903\n",
      "2018-12-04 09:39:51.055015   Evaluation one (validation set) epoch  10 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:40:36.503877  [Epoch 9] Validation mean loss: 0.019644\n",
      "2018-12-04 09:40:36.505944  [Epoch 9] Validation heading rmse[deg]: 103.869775\n",
      "2018-12-04 09:40:36.507929  [Epoch 9] Validation class accuracy: 0.957398\n",
      "2018-12-04 09:40:36.510149  [Epoch 9] Validation avg class acc: 0.490596\n",
      "2018-12-04 09:40:36.512002  [Epoch 9] Validation indivisual [0] class recall: 0.500792\n",
      "2018-12-04 09:40:36.513929  [Epoch 9] Validation indivisual [0] class precision: 0.942287\n",
      "2018-12-04 09:40:36.515870  [Epoch 9] Validation indivisual [1] class recall: 0.497411\n",
      "2018-12-04 09:40:36.517666  [Epoch 9] Validation indivisual [1] class precision: 0.997854\n",
      "2018-12-04 09:40:36.519503  [Epoch 9] Validation indivisual [2] class recall: 0.473585\n",
      "2018-12-04 09:40:36.521359  [Epoch 9] Validation indivisual [2] class precision: 0.866499\n",
      "2018-12-04 09:40:37.367995  Model saved in file: /home/gozilla/kyungpyo/git/MasterThesisProject/Network/notebook/train_log_20181204/model_out5_4/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Import model \"\"\"\n",
    "sys.path.append( os.path.abspath('../../model') )\n",
    "\n",
    "from train import *\n",
    "import model_out_5_heading as MODEL\n",
    "\n",
    "def run_training(out_path):\n",
    "    \n",
    "    \"\"\" Path \"\"\"\n",
    "    model_save_path = os.path.abspath(out_path)\n",
    "    if not os.path.isdir(model_save_path) : os.mkdir(model_save_path)\n",
    "    log_path = os.path.abspath(os.path.join(model_save_path, 'train_log.txt') )\n",
    "        \n",
    "    \"\"\" Parameters \"\"\"\n",
    "    GPU_INDEX = 0\n",
    "    NUM_POINT = 1024\n",
    "    NUM_CLASSES = 3\n",
    "\n",
    "    BN_INIT_DECAY = 0.5\n",
    "    BN_DECAY_DECAY_RATE = 0.5\n",
    "    BN_DECAY_DECAY_STEP = float(200000)\n",
    "    BN_DECAY_CLIP = 0.99\n",
    "    DECAY_STEP = BN_DECAY_DECAY_STEP\n",
    "    DECAY_RATE = BN_DECAY_DECAY_RATE\n",
    "\n",
    "    BATCH_SIZE = 50\n",
    "\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    BASE_LEARNING_RATE = 0.001\n",
    "\n",
    "    OPTIMIZER = 'adam'\n",
    "\n",
    "    MAX_EPOCH = 10\n",
    "\n",
    "    \"\"\" log file \"\"\"\n",
    "    LOG_FOUT = open(log_path, 'w')\n",
    "\n",
    "    def log_string(out_str):\n",
    "        out_str = str( datetime.datetime.fromtimestamp( time.time() ) ) + \"  \" + out_str\n",
    "        LOG_FOUT.write(out_str+'\\n')\n",
    "        LOG_FOUT.flush()\n",
    "        print(out_str)\n",
    "\n",
    "\n",
    "    def get_learning_rate(batch):\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "                            BASE_LEARNING_RATE,  # Base learning rate.\n",
    "                            batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                            DECAY_STEP,          # Decay step.\n",
    "                            DECAY_RATE,          # Decay rate.\n",
    "                            staircase=True)\n",
    "        learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n",
    "        return learning_rate        \n",
    "\n",
    "    def get_bn_decay(batch):\n",
    "        bn_momentum = tf.train.exponential_decay(\n",
    "                          BN_INIT_DECAY,\n",
    "                          batch * BATCH_SIZE,\n",
    "                          BN_DECAY_DECAY_STEP,\n",
    "                          BN_DECAY_DECAY_RATE,\n",
    "                          staircase=True)\n",
    "        bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "        return bn_decay\n",
    "\n",
    "    \"\"\" load traing model \"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Placeholder\n",
    "            \"\"\"\n",
    "            pointclouds_pl, class_labels_pl, heading_labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "            is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "            print(is_training_pl)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            decay\n",
    "            \"\"\"\n",
    "            # Note the global_step=batch parameter to minimize. \n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.summary.scalar('bn_decay', bn_decay)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Get model and loss \n",
    "            \"\"\"\n",
    "            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n",
    "            loss = MODEL.get_loss(pred, class_labels_pl, heading_labels_pl, end_points, h_reg_weight=10)\n",
    "            tf.summary.scalar('loss', loss)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Get accuracy \n",
    "            \"\"\"\n",
    "            correct = tf.equal(tf.argmax(tf.slice(pred, [0,0], [BATCH_SIZE,3]), 1), tf.to_int64(class_labels_pl))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Get training operator\n",
    "            \"\"\"\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            if OPTIMIZER == 'momentum':\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n",
    "            elif OPTIMIZER == 'adam':\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss, global_step=batch)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Add ops to save and restore all the variables.\n",
    "            \"\"\"\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        Create a session\n",
    "        \"\"\"\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = False\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Add summary writers\n",
    "        merged = tf.merge_all_summaries()\n",
    "        \"\"\"\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        train_writer_path = os.path.abspath( os.path.join(model_save_path, 'train') )\n",
    "        if os.path.isdir(train_writer_path): os.system('rm -r {}'.format(train_writer_path))\n",
    "        os.mkdir(train_writer_path)\n",
    "\n",
    "        test_writer_path = os.path.abspath( os.path.join(model_save_path, 'test') )\n",
    "        if os.path.isdir(test_writer_path): os.system('rm -r {}'.format(test_writer_path))\n",
    "        os.mkdir(test_writer_path)\n",
    "\n",
    "\n",
    "        train_writer = tf.summary.FileWriter(train_writer_path, sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(test_writer_path)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Init variables\n",
    "        \"\"\"\n",
    "        init = tf.global_variables_initializer()\n",
    "        # To fix the bug introduced in TF 0.12.1 as in\n",
    "        # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n",
    "        #sess.run(init)\n",
    "        sess.run(init, {is_training_pl: True})\n",
    "\n",
    "        ops = {'pointclouds_pl': pointclouds_pl,\n",
    "               'class_labels_pl': class_labels_pl,\n",
    "               'heading_labels_pl': heading_labels_pl,\n",
    "               'is_training_pl': is_training_pl,\n",
    "               'pred': pred,\n",
    "               'loss': loss,\n",
    "               'train_op': train_op,\n",
    "               'merged': merged,\n",
    "               'step': batch}\n",
    "\n",
    "\n",
    "        for epoch in range(MAX_EPOCH):\n",
    "\n",
    "            ## Training\n",
    "            log_string ( \"\\n\\n Train one epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = True\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle train files\n",
    "            \"\"\"\n",
    "            train_file_idxs = np.arange(0, data_train.shape[0])\n",
    "            np.random.shuffle(train_file_idxs)\n",
    "\n",
    "            current_data = data_train[train_file_idxs] \n",
    "            current_class_label = class_label_train[train_file_idxs]\n",
    "            current_heading_label = heading_label_train[train_file_idxs]\n",
    "            \n",
    "            current_class_label.reshape((data_train.shape[0],))\n",
    "            current_heading_label.reshape((data_train.shape[0],))\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            heading_rmse_sum = 0\n",
    "            \n",
    "            total_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "   \n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE          \n",
    "    \n",
    "\n",
    "            \"\"\"\n",
    "            Run batch training\n",
    "            \"\"\"\n",
    "            num_batches = 500\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE           \n",
    "\n",
    "                # Augment batched point clouds by rotation and jittering\n",
    "                rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])\n",
    "                jittered_data = provider.jitter_point_cloud(rotated_data)\n",
    "\n",
    "                # Reashape\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                feed_dict = {ops['pointclouds_pl']: jittered_data,\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training,}\n",
    "\n",
    "                summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                    ops['train_op'], ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                train_writer.add_summary(summary, step)\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                \n",
    "                ## classification\n",
    "                class_pred = pred_val[:,:3]\n",
    "                heading_pred = pred_val[:,3]\n",
    "                \n",
    "                class_pred = np.argmax(class_pred, 1)\n",
    "                correct = np.sum(class_pred == current_class_label_reshape)\n",
    "                                \n",
    "                total_correct += correct\n",
    "                total_seen += BATCH_SIZE\n",
    "                loss_sum += loss_val\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    total_class[i] += np.sum( np.ones(BATCH_SIZE) * i == current_class_label_reshape )\n",
    "                    total_detect_class[i] += np.sum( np.ones(BATCH_SIZE) * i == class_pred )\n",
    "                    total_correct_class[i] += np.sum( (np.ones(BATCH_SIZE) * i == current_class_label_reshape) * \\\n",
    "                                                        (np.ones(BATCH_SIZE) * i == class_pred) )\n",
    "                ## Heading regression\n",
    "                heading_rmse_sum += np.mean( np.square(heading_pred - current_heading_label_reshape) )\n",
    "\n",
    "            log_string(  '[Epoch %d] mean loss: %f' % \\\n",
    "                       (  epoch, loss_sum / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] heading rmse[deg]: %f' % \\\n",
    "                       (  epoch, 360. * np.sqrt(heading_rmse_sum / float(num_batches) )  )   )\n",
    "            log_string(  '[Epoch %d] class accuracy: %f'% \\\n",
    "                       (  epoch, total_correct / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] avg class acc: %f' % \\\n",
    "                       (  epoch, np.mean( np.array(total_correct_class) / np.array(total_class,dtype=np.float) )  )   )\n",
    "\n",
    "            for i_cls in range(NUM_CLASSES):\n",
    "                if not float(total_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] indivisual [%d] class recall: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "                if not float(total_detect_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] indivisual [%d] class precision: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation using validation set    \n",
    "            \"\"\"\n",
    "            \n",
    "            log_string ( \" Evaluation one (validation set) epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = False\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            heading_rmse_sum = 0\n",
    "            \n",
    "            total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_true_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle validation files\n",
    "            \"\"\"\n",
    "            file_idxs = np.arange(0, data_vali.shape[0])\n",
    "            np.random.shuffle(file_idxs)\n",
    "\n",
    "            current_data = data_vali[file_idxs]\n",
    "            current_class_label = class_label_vali[file_idxs]\n",
    "            current_heading_label = heading_label_vali[file_idxs]\n",
    "\n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Run batch validation\n",
    "            \"\"\"\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Reashape\n",
    "                \"\"\"\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Feed dict\n",
    "                \"\"\"\n",
    "                feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training}\n",
    "                \n",
    "                \"\"\"\n",
    "                Summary\n",
    "                \"\"\"\n",
    "                summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                    ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                \n",
    "                ## classification\n",
    "                class_pred = pred_val[:,:3]\n",
    "                heading_pred = pred_val[:,3]\n",
    "                \n",
    "                class_pred = np.argmax(class_pred, 1)\n",
    "                correct = np.sum(class_pred == current_class_label_reshape)\n",
    "                                \n",
    "                total_correct += correct\n",
    "                total_seen += BATCH_SIZE\n",
    "                loss_sum += loss_val\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    total_class[i] += np.sum( np.ones(BATCH_SIZE) * i == current_class_label_reshape )\n",
    "                    total_detect_class[i] += np.sum( np.ones(BATCH_SIZE) * i == class_pred )\n",
    "                    total_correct_class[i] += np.sum( (np.ones(BATCH_SIZE) * i == current_class_label_reshape) * \\\n",
    "                                                        (np.ones(BATCH_SIZE) * i == class_pred) )\n",
    "                ## Heading regression\n",
    "                heading_rmse_sum += np.mean( np.square(heading_pred - current_heading_label_reshape) )\n",
    "                \n",
    "                \n",
    "                \n",
    "            log_string(  '[Epoch %d] Validation mean loss: %f' % \\\n",
    "                       (  epoch, loss_sum / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] Validation heading rmse[deg]: %f' % \\\n",
    "                       (  epoch, 360. * np.sqrt(heading_rmse_sum / float(num_batches) )  )   )\n",
    "            log_string(  '[Epoch %d] Validation class accuracy: %f'% \\\n",
    "                       (  epoch, total_correct / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] Validation avg class acc: %f' % \\\n",
    "                       (  epoch, np.mean( np.array(total_correct_class) / np.array(total_class,dtype=np.float) )  )   )\n",
    "\n",
    "            for i_cls in range(NUM_CLASSES):\n",
    "                if not float(total_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] Validation indivisual [%d] class recall: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "                if not float(total_detect_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] Validation indivisual [%d] class precision: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Save the variables to disk.\n",
    "            \"\"\"\n",
    "            if ( epoch + 1 ) % 10 == 0:\n",
    "                save_path = saver.save(sess, os.path.join(model_save_path, \"model.ckpt\"))\n",
    "                log_string(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "                \n",
    "# option 1: execute code with extra process\n",
    "p = multiprocessing.Process(target=run_training, args = ('./model_out5_4',))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "INFO:tensorflow:Summary name classify loss is illegal; using classify_loss instead.\n",
      "INFO:tensorflow:Summary name mat loss is illegal; using mat_loss instead.\n",
      "2018-12-04 09:40:46.130167  \n",
      "\n",
      " Train one epoch   1 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:43:47.691645  [Epoch 0] mean loss: 0.830394\n",
      "2018-12-04 09:43:47.693517  [Epoch 0] heading rmse[deg]: 213.269651\n",
      "2018-12-04 09:43:47.695307  [Epoch 0] class accuracy: 0.458160\n",
      "2018-12-04 09:43:47.697194  [Epoch 0] avg class acc: 0.344926\n",
      "2018-12-04 09:43:47.698813  [Epoch 0] indivisual [0] class recall: 0.458595\n",
      "2018-12-04 09:43:47.700362  [Epoch 0] indivisual [0] class precision: 0.456681\n",
      "2018-12-04 09:43:47.702343  [Epoch 0] indivisual [1] class recall: 0.566693\n",
      "2018-12-04 09:43:47.704393  [Epoch 0] indivisual [1] class precision: 0.464478\n",
      "2018-12-04 09:43:47.706132  [Epoch 0] indivisual [2] class recall: 0.009489\n",
      "2018-12-04 09:43:47.707850  [Epoch 0] indivisual [2] class precision: 0.123223\n",
      "2018-12-04 09:43:47.709544   Evaluation one (validation set) epoch   1 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:46<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:44:34.245542  [Epoch 0] Validation mean loss: 0.193921\n",
      "2018-12-04 09:44:34.247455  [Epoch 0] Validation heading rmse[deg]: 104.678023\n",
      "2018-12-04 09:44:34.249310  [Epoch 0] Validation class accuracy: 0.465836\n",
      "2018-12-04 09:44:34.251151  [Epoch 0] Validation avg class acc: 0.178769\n",
      "2018-12-04 09:44:34.252867  [Epoch 0] Validation indivisual [0] class recall: 0.022970\n",
      "2018-12-04 09:44:34.254727  [Epoch 0] Validation indivisual [0] class precision: 0.450086\n",
      "2018-12-04 09:44:34.256578  [Epoch 0] Validation indivisual [1] class recall: 0.513338\n",
      "2018-12-04 09:44:34.258214  [Epoch 0] Validation indivisual [1] class precision: 0.466548\n",
      "2018-12-04 09:44:34.259841  [Epoch 0] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 09:44:34.261413  \n",
      "\n",
      " Train one epoch   2 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:47:33.935127  [Epoch 1] mean loss: 0.281701\n",
      "2018-12-04 09:47:33.937024  [Epoch 1] heading rmse[deg]: 129.129463\n",
      "2018-12-04 09:47:33.938795  [Epoch 1] class accuracy: 0.456240\n",
      "2018-12-04 09:47:33.940624  [Epoch 1] avg class acc: 0.341886\n",
      "2018-12-04 09:47:33.942386  [Epoch 1] indivisual [0] class recall: 0.434378\n",
      "2018-12-04 09:47:33.944170  [Epoch 1] indivisual [0] class precision: 0.446992\n",
      "2018-12-04 09:47:33.945934  [Epoch 1] indivisual [1] class recall: 0.590566\n",
      "2018-12-04 09:47:33.947623  [Epoch 1] indivisual [1] class precision: 0.464019\n",
      "2018-12-04 09:47:33.949292  [Epoch 1] indivisual [2] class recall: 0.000716\n",
      "2018-12-04 09:47:33.950895  [Epoch 1] indivisual [2] class precision: 0.060606\n",
      "2018-12-04 09:47:33.952633   Evaluation one (validation set) epoch   2 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:48:20.032658  [Epoch 1] Validation mean loss: 0.186608\n",
      "2018-12-04 09:48:20.034502  [Epoch 1] Validation heading rmse[deg]: 103.813113\n",
      "2018-12-04 09:48:20.036393  [Epoch 1] Validation class accuracy: 0.508104\n",
      "2018-12-04 09:48:20.038233  [Epoch 1] Validation avg class acc: 0.198299\n",
      "2018-12-04 09:48:20.040035  [Epoch 1] Validation indivisual [0] class recall: 0.377022\n",
      "2018-12-04 09:48:20.041711  [Epoch 1] Validation indivisual [0] class precision: 0.466576\n",
      "2018-12-04 09:48:20.043308  [Epoch 1] Validation indivisual [1] class recall: 0.217875\n",
      "2018-12-04 09:48:20.044889  [Epoch 1] Validation indivisual [1] class precision: 0.597769\n",
      "2018-12-04 09:48:20.046381  [Epoch 1] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 09:48:20.048145  \n",
      "\n",
      " Train one epoch   3 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:51:20.074999  [Epoch 2] mean loss: 0.210485\n",
      "2018-12-04 09:51:20.076990  [Epoch 2] heading rmse[deg]: 111.559279\n",
      "2018-12-04 09:51:20.078794  [Epoch 2] class accuracy: 0.495520\n",
      "2018-12-04 09:51:20.080593  [Epoch 2] avg class acc: 0.428030\n",
      "2018-12-04 09:51:20.082323  [Epoch 2] indivisual [0] class recall: 0.388435\n",
      "2018-12-04 09:51:20.084064  [Epoch 2] indivisual [0] class precision: 0.450309\n",
      "2018-12-04 09:51:20.085769  [Epoch 2] indivisual [1] class recall: 0.666933\n",
      "2018-12-04 09:51:20.087461  [Epoch 2] indivisual [1] class precision: 0.512185\n",
      "2018-12-04 09:51:20.089129  [Epoch 2] indivisual [2] class recall: 0.228722\n",
      "2018-12-04 09:51:20.090700  [Epoch 2] indivisual [2] class precision: 0.685205\n",
      "2018-12-04 09:51:20.092382   Evaluation one (validation set) epoch   3 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:46<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:52:07.244219  [Epoch 2] Validation mean loss: 0.181547\n",
      "2018-12-04 09:52:07.246276  [Epoch 2] Validation heading rmse[deg]: 104.026536\n",
      "2018-12-04 09:52:07.248084  [Epoch 2] Validation class accuracy: 0.629257\n",
      "2018-12-04 09:52:07.250035  [Epoch 2] Validation avg class acc: 0.360061\n",
      "2018-12-04 09:52:07.251984  [Epoch 2] Validation indivisual [0] class recall: 0.301533\n",
      "2018-12-04 09:52:07.253818  [Epoch 2] Validation indivisual [0] class precision: 0.579179\n",
      "2018-12-04 09:52:07.255334  [Epoch 2] Validation indivisual [1] class recall: 0.315837\n",
      "2018-12-04 09:52:07.256872  [Epoch 2] Validation indivisual [1] class precision: 0.625117\n",
      "2018-12-04 09:52:07.258300  [Epoch 2] Validation indivisual [2] class recall: 0.462814\n",
      "2018-12-04 09:52:07.259813  [Epoch 2] Validation indivisual [2] class precision: 0.824300\n",
      "2018-12-04 09:52:07.261259  \n",
      "\n",
      " Train one epoch   4 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:55:07.185135  [Epoch 3] mean loss: 0.189440\n",
      "2018-12-04 09:55:07.187055  [Epoch 3] heading rmse[deg]: 106.124771\n",
      "2018-12-04 09:55:07.188835  [Epoch 3] class accuracy: 0.595600\n",
      "2018-12-04 09:55:07.191036  [Epoch 3] avg class acc: 0.629183\n",
      "2018-12-04 09:55:07.192830  [Epoch 3] indivisual [0] class recall: 0.435762\n",
      "2018-12-04 09:55:07.194573  [Epoch 3] indivisual [0] class precision: 0.556733\n",
      "2018-12-04 09:55:07.196331  [Epoch 3] indivisual [1] class recall: 0.716932\n",
      "2018-12-04 09:55:07.198250  [Epoch 3] indivisual [1] class precision: 0.584829\n",
      "2018-12-04 09:55:07.200262  [Epoch 3] indivisual [2] class recall: 0.734854\n",
      "2018-12-04 09:55:07.201934  [Epoch 3] indivisual [2] class precision: 0.777233\n",
      "2018-12-04 09:55:07.203563   Evaluation one (validation set) epoch   4 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:55:53.407326  [Epoch 3] Validation mean loss: 0.180223\n",
      "2018-12-04 09:55:53.409541  [Epoch 3] Validation heading rmse[deg]: 104.062783\n",
      "2018-12-04 09:55:53.411387  [Epoch 3] Validation class accuracy: 0.719257\n",
      "2018-12-04 09:55:53.413434  [Epoch 3] Validation avg class acc: 0.393000\n",
      "2018-12-04 09:55:53.415173  [Epoch 3] Validation indivisual [0] class recall: 0.300022\n",
      "2018-12-04 09:55:53.416963  [Epoch 3] Validation indivisual [0] class precision: 0.733155\n",
      "2018-12-04 09:55:53.418605  [Epoch 3] Validation indivisual [1] class recall: 0.423225\n",
      "2018-12-04 09:55:53.420448  [Epoch 3] Validation indivisual [1] class precision: 0.675909\n",
      "2018-12-04 09:55:53.422108  [Epoch 3] Validation indivisual [2] class recall: 0.455753\n",
      "2018-12-04 09:55:53.423908  [Epoch 3] Validation indivisual [2] class precision: 0.888665\n",
      "2018-12-04 09:55:53.425613  \n",
      "\n",
      " Train one epoch   5 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:58:53.243522  [Epoch 4] mean loss: 0.184154\n",
      "2018-12-04 09:58:53.245549  [Epoch 4] heading rmse[deg]: 104.858557\n",
      "2018-12-04 09:58:53.247362  [Epoch 4] class accuracy: 0.658600\n",
      "2018-12-04 09:58:53.249335  [Epoch 4] avg class acc: 0.691520\n",
      "2018-12-04 09:58:53.251029  [Epoch 4] indivisual [0] class recall: 0.497755\n",
      "2018-12-04 09:58:53.252784  [Epoch 4] indivisual [0] class precision: 0.643069\n",
      "2018-12-04 09:58:53.254653  [Epoch 4] indivisual [1] class recall: 0.779839\n",
      "2018-12-04 09:58:53.256643  [Epoch 4] indivisual [1] class precision: 0.639175\n",
      "2018-12-04 09:58:53.258812  [Epoch 4] indivisual [2] class recall: 0.796965\n",
      "2018-12-04 09:58:53.260698  [Epoch 4] indivisual [2] class precision: 0.804229\n",
      "2018-12-04 09:58:53.262481   Evaluation one (validation set) epoch   5 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 09:59:39.475092  [Epoch 4] Validation mean loss: 0.179274\n",
      "2018-12-04 09:59:39.477002  [Epoch 4] Validation heading rmse[deg]: 104.059421\n",
      "2018-12-04 09:59:39.478627  [Epoch 4] Validation class accuracy: 0.734721\n",
      "2018-12-04 09:59:39.480410  [Epoch 4] Validation avg class acc: 0.404013\n",
      "2018-12-04 09:59:39.482092  [Epoch 4] Validation indivisual [0] class recall: 0.388265\n",
      "2018-12-04 09:59:39.483820  [Epoch 4] Validation indivisual [0] class precision: 0.682106\n",
      "2018-12-04 09:59:39.485348  [Epoch 4] Validation indivisual [1] class recall: 0.350939\n",
      "2018-12-04 09:59:39.486908  [Epoch 4] Validation indivisual [1] class precision: 0.822229\n",
      "2018-12-04 09:59:39.488390  [Epoch 4] Validation indivisual [2] class recall: 0.472835\n",
      "2018-12-04 09:59:39.489876  [Epoch 4] Validation indivisual [2] class precision: 0.685801\n",
      "2018-12-04 09:59:39.491412  \n",
      "\n",
      " Train one epoch   6 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:59<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:02:39.526903  [Epoch 5] mean loss: 0.181166\n",
      "2018-12-04 10:02:39.528792  [Epoch 5] heading rmse[deg]: 104.500322\n",
      "2018-12-04 10:02:39.530438  [Epoch 5] class accuracy: 0.711760\n",
      "2018-12-04 10:02:39.532218  [Epoch 5] avg class acc: 0.738738\n",
      "2018-12-04 10:02:39.533831  [Epoch 5] indivisual [0] class recall: 0.585457\n",
      "2018-12-04 10:02:39.535797  [Epoch 5] indivisual [0] class precision: 0.709653\n",
      "2018-12-04 10:02:39.537849  [Epoch 5] indivisual [1] class recall: 0.807798\n",
      "2018-12-04 10:02:39.539580  [Epoch 5] indivisual [1] class precision: 0.688729\n",
      "2018-12-04 10:02:39.541342  [Epoch 5] indivisual [2] class recall: 0.822958\n",
      "2018-12-04 10:02:39.543089  [Epoch 5] indivisual [2] class precision: 0.828623\n",
      "2018-12-04 10:02:39.544795   Evaluation one (validation set) epoch   6 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:03:25.832547  [Epoch 5] Validation mean loss: 0.179282\n",
      "2018-12-04 10:03:25.834846  [Epoch 5] Validation heading rmse[deg]: 104.501317\n",
      "2018-12-04 10:03:25.836721  [Epoch 5] Validation class accuracy: 0.795428\n",
      "2018-12-04 10:03:25.838576  [Epoch 5] Validation avg class acc: 0.427705\n",
      "2018-12-04 10:03:25.840432  [Epoch 5] Validation indivisual [0] class recall: 0.374764\n",
      "2018-12-04 10:03:25.842314  [Epoch 5] Validation indivisual [0] class precision: 0.799607\n",
      "2018-12-04 10:03:25.844293  [Epoch 5] Validation indivisual [1] class recall: 0.433382\n",
      "2018-12-04 10:03:25.846128  [Epoch 5] Validation indivisual [1] class precision: 0.785526\n",
      "2018-12-04 10:03:25.847990  [Epoch 5] Validation indivisual [2] class recall: 0.474970\n",
      "2018-12-04 10:03:25.849752  [Epoch 5] Validation indivisual [2] class precision: 0.820221\n",
      "2018-12-04 10:03:25.851515  \n",
      "\n",
      " Train one epoch   7 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:06:25.976463  [Epoch 6] mean loss: 0.180519\n",
      "2018-12-04 10:06:25.978494  [Epoch 6] heading rmse[deg]: 104.588499\n",
      "2018-12-04 10:06:25.980343  [Epoch 6] class accuracy: 0.737600\n",
      "2018-12-04 10:06:25.982300  [Epoch 6] avg class acc: 0.763365\n",
      "2018-12-04 10:06:25.984190  [Epoch 6] indivisual [0] class recall: 0.636364\n",
      "2018-12-04 10:06:25.985988  [Epoch 6] indivisual [0] class precision: 0.737150\n",
      "2018-12-04 10:06:25.987777  [Epoch 6] indivisual [1] class recall: 0.812724\n",
      "2018-12-04 10:06:25.989473  [Epoch 6] indivisual [1] class precision: 0.716155\n",
      "2018-12-04 10:06:25.991112  [Epoch 6] indivisual [2] class recall: 0.841009\n",
      "2018-12-04 10:06:25.992766  [Epoch 6] indivisual [2] class precision: 0.838251\n",
      "2018-12-04 10:06:25.994389   Evaluation one (validation set) epoch   7 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:07:11.553851  [Epoch 6] Validation mean loss: 0.177018\n",
      "2018-12-04 10:07:11.555716  [Epoch 6] Validation heading rmse[deg]: 104.090076\n",
      "2018-12-04 10:07:11.557624  [Epoch 6] Validation class accuracy: 0.818401\n",
      "2018-12-04 10:07:11.559475  [Epoch 6] Validation avg class acc: 0.438305\n",
      "2018-12-04 10:07:11.561207  [Epoch 6] Validation indivisual [0] class recall: 0.421168\n",
      "2018-12-04 10:07:11.562924  [Epoch 6] Validation indivisual [0] class precision: 0.783896\n",
      "2018-12-04 10:07:11.564622  [Epoch 6] Validation indivisual [1] class recall: 0.413281\n",
      "2018-12-04 10:07:11.566231  [Epoch 6] Validation indivisual [1] class precision: 0.877039\n",
      "2018-12-04 10:07:11.567873  [Epoch 6] Validation indivisual [2] class recall: 0.480467\n",
      "2018-12-04 10:07:11.569402  [Epoch 6] Validation indivisual [2] class precision: 0.758118\n",
      "2018-12-04 10:07:11.570867  \n",
      "\n",
      " Train one epoch   8 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:10:12.268177  [Epoch 7] mean loss: 0.180466\n",
      "2018-12-04 10:10:12.270221  [Epoch 7] heading rmse[deg]: 104.755750\n",
      "2018-12-04 10:10:12.272091  [Epoch 7] class accuracy: 0.757440\n",
      "2018-12-04 10:10:12.273887  [Epoch 7] avg class acc: 0.777729\n",
      "2018-12-04 10:10:12.275758  [Epoch 7] indivisual [0] class recall: 0.677208\n",
      "2018-12-04 10:10:12.277579  [Epoch 7] indivisual [0] class precision: 0.749020\n",
      "2018-12-04 10:10:12.279674  [Epoch 7] indivisual [1] class recall: 0.815455\n",
      "2018-12-04 10:10:12.281443  [Epoch 7] indivisual [1] class precision: 0.744644\n",
      "2018-12-04 10:10:12.283102  [Epoch 7] indivisual [2] class recall: 0.840523\n",
      "2018-12-04 10:10:12.284835  [Epoch 7] indivisual [2] class precision: 0.842609\n",
      "2018-12-04 10:10:12.286533   Evaluation one (validation set) epoch   8 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:10:58.135169  [Epoch 7] Validation mean loss: 0.178211\n",
      "2018-12-04 10:10:58.137123  [Epoch 7] Validation heading rmse[deg]: 104.417041\n",
      "2018-12-04 10:10:58.138916  [Epoch 7] Validation class accuracy: 0.824275\n",
      "2018-12-04 10:10:58.140806  [Epoch 7] Validation avg class acc: 0.438402\n",
      "2018-12-04 10:10:58.142491  [Epoch 7] Validation indivisual [0] class recall: 0.376650\n",
      "2018-12-04 10:10:58.144352  [Epoch 7] Validation indivisual [0] class precision: 0.855848\n",
      "2018-12-04 10:10:58.146107  [Epoch 7] Validation indivisual [1] class recall: 0.465280\n",
      "2018-12-04 10:10:58.147986  [Epoch 7] Validation indivisual [1] class precision: 0.845739\n",
      "2018-12-04 10:10:58.150020  [Epoch 7] Validation indivisual [2] class recall: 0.473277\n",
      "2018-12-04 10:10:58.151813  [Epoch 7] Validation indivisual [2] class precision: 0.678492\n",
      "2018-12-04 10:10:58.153512  \n",
      "\n",
      " Train one epoch   9 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:13:57.797785  [Epoch 8] mean loss: 0.176454\n",
      "2018-12-04 10:13:57.799779  [Epoch 8] heading rmse[deg]: 103.993265\n",
      "2018-12-04 10:13:57.801620  [Epoch 8] class accuracy: 0.809640\n",
      "2018-12-04 10:13:57.803629  [Epoch 8] avg class acc: 0.825848\n",
      "2018-12-04 10:13:57.805667  [Epoch 8] indivisual [0] class recall: 0.749887\n",
      "2018-12-04 10:13:57.807492  [Epoch 8] indivisual [0] class precision: 0.807239\n",
      "2018-12-04 10:13:57.809268  [Epoch 8] indivisual [1] class recall: 0.852311\n",
      "2018-12-04 10:13:57.810870  [Epoch 8] indivisual [1] class precision: 0.798779\n",
      "2018-12-04 10:13:57.812510  [Epoch 8] indivisual [2] class recall: 0.875347\n",
      "2018-12-04 10:13:57.814142  [Epoch 8] indivisual [2] class precision: 0.861880\n",
      "2018-12-04 10:13:57.815855   Evaluation one (validation set) epoch   9 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:14:43.352056  [Epoch 8] Validation mean loss: 0.174725\n",
      "2018-12-04 10:14:43.354266  [Epoch 8] Validation heading rmse[deg]: 104.235055\n",
      "2018-12-04 10:14:43.356225  [Epoch 8] Validation class accuracy: 0.883680\n",
      "2018-12-04 10:14:43.358234  [Epoch 8] Validation avg class acc: 0.456630\n",
      "2018-12-04 10:14:43.360125  [Epoch 8] Validation indivisual [0] class recall: 0.498447\n",
      "2018-12-04 10:14:43.361872  [Epoch 8] Validation indivisual [0] class precision: 0.808642\n",
      "2018-12-04 10:14:43.363804  [Epoch 8] Validation indivisual [1] class recall: 0.419682\n",
      "2018-12-04 10:14:43.365483  [Epoch 8] Validation indivisual [1] class precision: 0.987603\n",
      "2018-12-04 10:14:43.367009  [Epoch 8] Validation indivisual [2] class recall: 0.451761\n",
      "2018-12-04 10:14:43.368652  [Epoch 8] Validation indivisual [2] class precision: 0.895447\n",
      "2018-12-04 10:14:43.370282  \n",
      "\n",
      " Train one epoch  10 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:17:43.149155  [Epoch 9] mean loss: 0.176553\n",
      "2018-12-04 10:17:43.151009  [Epoch 9] heading rmse[deg]: 104.372679\n",
      "2018-12-04 10:17:43.152730  [Epoch 9] class accuracy: 0.820960\n",
      "2018-12-04 10:17:43.154706  [Epoch 9] avg class acc: 0.838056\n",
      "2018-12-04 10:17:43.156577  [Epoch 9] indivisual [0] class recall: 0.770936\n",
      "2018-12-04 10:17:43.158802  [Epoch 9] indivisual [0] class precision: 0.810597\n",
      "2018-12-04 10:17:43.160594  [Epoch 9] indivisual [1] class recall: 0.851780\n",
      "2018-12-04 10:17:43.162323  [Epoch 9] indivisual [1] class precision: 0.819696\n",
      "2018-12-04 10:17:43.164121  [Epoch 9] indivisual [2] class recall: 0.891451\n",
      "2018-12-04 10:17:43.165835  [Epoch 9] indivisual [2] class precision: 0.862981\n",
      "2018-12-04 10:17:43.167542   Evaluation one (validation set) epoch  10 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:18:28.710541  [Epoch 9] Validation mean loss: 0.171453\n",
      "2018-12-04 10:18:28.712326  [Epoch 9] Validation heading rmse[deg]: 103.868578\n",
      "2018-12-04 10:18:28.714140  [Epoch 9] Validation class accuracy: 0.943866\n",
      "2018-12-04 10:18:28.715927  [Epoch 9] Validation avg class acc: 0.479286\n",
      "2018-12-04 10:18:28.717538  [Epoch 9] Validation indivisual [0] class recall: 0.496391\n",
      "2018-12-04 10:18:28.719021  [Epoch 9] Validation indivisual [0] class precision: 0.926413\n",
      "2018-12-04 10:18:28.720627  [Epoch 9] Validation indivisual [1] class recall: 0.492146\n",
      "2018-12-04 10:18:28.722122  [Epoch 9] Validation indivisual [1] class precision: 0.964762\n",
      "2018-12-04 10:18:28.723739  [Epoch 9] Validation indivisual [2] class recall: 0.449320\n",
      "2018-12-04 10:18:28.725233  [Epoch 9] Validation indivisual [2] class precision: 0.930838\n",
      "2018-12-04 10:18:29.612065  Model saved in file: /home/gozilla/kyungpyo/git/MasterThesisProject/Network/notebook/train_log_20181204/model_out5_5/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Import model \"\"\"\n",
    "sys.path.append( os.path.abspath('../../model') )\n",
    "\n",
    "from train import *\n",
    "import model_out_5_heading as MODEL\n",
    "\n",
    "def run_training(out_path):\n",
    "    \n",
    "    \"\"\" Path \"\"\"\n",
    "    model_save_path = os.path.abspath(out_path)\n",
    "    if not os.path.isdir(model_save_path) : os.mkdir(model_save_path)\n",
    "    log_path = os.path.abspath(os.path.join(model_save_path, 'train_log.txt') )\n",
    "        \n",
    "    \"\"\" Parameters \"\"\"\n",
    "    GPU_INDEX = 0\n",
    "    NUM_POINT = 1024\n",
    "    NUM_CLASSES = 3\n",
    "\n",
    "    BN_INIT_DECAY = 0.5\n",
    "    BN_DECAY_DECAY_RATE = 0.5\n",
    "    BN_DECAY_DECAY_STEP = float(200000)\n",
    "    BN_DECAY_CLIP = 0.99\n",
    "    DECAY_STEP = BN_DECAY_DECAY_STEP\n",
    "    DECAY_RATE = BN_DECAY_DECAY_RATE\n",
    "\n",
    "    BATCH_SIZE = 50\n",
    "\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    BASE_LEARNING_RATE = 0.001\n",
    "\n",
    "    OPTIMIZER = 'adam'\n",
    "\n",
    "    MAX_EPOCH = 10\n",
    "\n",
    "    \"\"\" log file \"\"\"\n",
    "    LOG_FOUT = open(log_path, 'w')\n",
    "\n",
    "    def log_string(out_str):\n",
    "        out_str = str( datetime.datetime.fromtimestamp( time.time() ) ) + \"  \" + out_str\n",
    "        LOG_FOUT.write(out_str+'\\n')\n",
    "        LOG_FOUT.flush()\n",
    "        print(out_str)\n",
    "\n",
    "\n",
    "    def get_learning_rate(batch):\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "                            BASE_LEARNING_RATE,  # Base learning rate.\n",
    "                            batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                            DECAY_STEP,          # Decay step.\n",
    "                            DECAY_RATE,          # Decay rate.\n",
    "                            staircase=True)\n",
    "        learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n",
    "        return learning_rate        \n",
    "\n",
    "    def get_bn_decay(batch):\n",
    "        bn_momentum = tf.train.exponential_decay(\n",
    "                          BN_INIT_DECAY,\n",
    "                          batch * BATCH_SIZE,\n",
    "                          BN_DECAY_DECAY_STEP,\n",
    "                          BN_DECAY_DECAY_RATE,\n",
    "                          staircase=True)\n",
    "        bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "        return bn_decay\n",
    "\n",
    "    \"\"\" load traing model \"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Placeholder\n",
    "            \"\"\"\n",
    "            pointclouds_pl, class_labels_pl, heading_labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "            is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "            print(is_training_pl)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            decay\n",
    "            \"\"\"\n",
    "            # Note the global_step=batch parameter to minimize. \n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.summary.scalar('bn_decay', bn_decay)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Get model and loss \n",
    "            \"\"\"\n",
    "            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n",
    "            loss = MODEL.get_loss(pred, class_labels_pl, heading_labels_pl, end_points, h_reg_weight=100)\n",
    "            tf.summary.scalar('loss', loss)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Get accuracy \n",
    "            \"\"\"\n",
    "            correct = tf.equal(tf.argmax(tf.slice(pred, [0,0], [BATCH_SIZE,3]), 1), tf.to_int64(class_labels_pl))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Get training operator\n",
    "            \"\"\"\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            if OPTIMIZER == 'momentum':\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n",
    "            elif OPTIMIZER == 'adam':\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss, global_step=batch)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Add ops to save and restore all the variables.\n",
    "            \"\"\"\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        Create a session\n",
    "        \"\"\"\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = False\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Add summary writers\n",
    "        merged = tf.merge_all_summaries()\n",
    "        \"\"\"\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        train_writer_path = os.path.abspath( os.path.join(model_save_path, 'train') )\n",
    "        if os.path.isdir(train_writer_path): os.system('rm -r {}'.format(train_writer_path))\n",
    "        os.mkdir(train_writer_path)\n",
    "\n",
    "        test_writer_path = os.path.abspath( os.path.join(model_save_path, 'test') )\n",
    "        if os.path.isdir(test_writer_path): os.system('rm -r {}'.format(test_writer_path))\n",
    "        os.mkdir(test_writer_path)\n",
    "\n",
    "\n",
    "        train_writer = tf.summary.FileWriter(train_writer_path, sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(test_writer_path)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Init variables\n",
    "        \"\"\"\n",
    "        init = tf.global_variables_initializer()\n",
    "        # To fix the bug introduced in TF 0.12.1 as in\n",
    "        # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n",
    "        #sess.run(init)\n",
    "        sess.run(init, {is_training_pl: True})\n",
    "\n",
    "        ops = {'pointclouds_pl': pointclouds_pl,\n",
    "               'class_labels_pl': class_labels_pl,\n",
    "               'heading_labels_pl': heading_labels_pl,\n",
    "               'is_training_pl': is_training_pl,\n",
    "               'pred': pred,\n",
    "               'loss': loss,\n",
    "               'train_op': train_op,\n",
    "               'merged': merged,\n",
    "               'step': batch}\n",
    "\n",
    "\n",
    "        for epoch in range(MAX_EPOCH):\n",
    "\n",
    "            ## Training\n",
    "            log_string ( \"\\n\\n Train one epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = True\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle train files\n",
    "            \"\"\"\n",
    "            train_file_idxs = np.arange(0, data_train.shape[0])\n",
    "            np.random.shuffle(train_file_idxs)\n",
    "\n",
    "            current_data = data_train[train_file_idxs] \n",
    "            current_class_label = class_label_train[train_file_idxs]\n",
    "            current_heading_label = heading_label_train[train_file_idxs]\n",
    "            \n",
    "            current_class_label.reshape((data_train.shape[0],))\n",
    "            current_heading_label.reshape((data_train.shape[0],))\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            heading_rmse_sum = 0\n",
    "            \n",
    "            total_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "   \n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE          \n",
    "    \n",
    "\n",
    "            \"\"\"\n",
    "            Run batch training\n",
    "            \"\"\"\n",
    "            num_batches = 500\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE           \n",
    "\n",
    "                # Augment batched point clouds by rotation and jittering\n",
    "                rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])\n",
    "                jittered_data = provider.jitter_point_cloud(rotated_data)\n",
    "\n",
    "                # Reashape\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                feed_dict = {ops['pointclouds_pl']: jittered_data,\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training,}\n",
    "\n",
    "                summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                    ops['train_op'], ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                train_writer.add_summary(summary, step)\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                \n",
    "                ## classification\n",
    "                class_pred = pred_val[:,:3]\n",
    "                heading_pred = pred_val[:,3]\n",
    "                \n",
    "                class_pred = np.argmax(class_pred, 1)\n",
    "                correct = np.sum(class_pred == current_class_label_reshape)\n",
    "                                \n",
    "                total_correct += correct\n",
    "                total_seen += BATCH_SIZE\n",
    "                loss_sum += loss_val\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    total_class[i] += np.sum( np.ones(BATCH_SIZE) * i == current_class_label_reshape )\n",
    "                    total_detect_class[i] += np.sum( np.ones(BATCH_SIZE) * i == class_pred )\n",
    "                    total_correct_class[i] += np.sum( (np.ones(BATCH_SIZE) * i == current_class_label_reshape) * \\\n",
    "                                                        (np.ones(BATCH_SIZE) * i == class_pred) )\n",
    "                ## Heading regression\n",
    "                heading_rmse_sum += np.mean( np.square(heading_pred - current_heading_label_reshape) )\n",
    "\n",
    "            log_string(  '[Epoch %d] mean loss: %f' % \\\n",
    "                       (  epoch, loss_sum / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] heading rmse[deg]: %f' % \\\n",
    "                       (  epoch, 360. * np.sqrt(heading_rmse_sum / float(num_batches) )  )   )\n",
    "            log_string(  '[Epoch %d] class accuracy: %f'% \\\n",
    "                       (  epoch, total_correct / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] avg class acc: %f' % \\\n",
    "                       (  epoch, np.mean( np.array(total_correct_class) / np.array(total_class,dtype=np.float) )  )   )\n",
    "\n",
    "            for i_cls in range(NUM_CLASSES):\n",
    "                if not float(total_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] indivisual [%d] class recall: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "                if not float(total_detect_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] indivisual [%d] class precision: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation using validation set    \n",
    "            \"\"\"\n",
    "            \n",
    "            log_string ( \" Evaluation one (validation set) epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = False\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            heading_rmse_sum = 0\n",
    "            \n",
    "            total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_true_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle validation files\n",
    "            \"\"\"\n",
    "            file_idxs = np.arange(0, data_vali.shape[0])\n",
    "            np.random.shuffle(file_idxs)\n",
    "\n",
    "            current_data = data_vali[file_idxs]\n",
    "            current_class_label = class_label_vali[file_idxs]\n",
    "            current_heading_label = heading_label_vali[file_idxs]\n",
    "\n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Run batch validation\n",
    "            \"\"\"\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Reashape\n",
    "                \"\"\"\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Feed dict\n",
    "                \"\"\"\n",
    "                feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training}\n",
    "                \n",
    "                \"\"\"\n",
    "                Summary\n",
    "                \"\"\"\n",
    "                summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                    ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                \n",
    "                ## classification\n",
    "                class_pred = pred_val[:,:3]\n",
    "                heading_pred = pred_val[:,3]\n",
    "                \n",
    "                class_pred = np.argmax(class_pred, 1)\n",
    "                correct = np.sum(class_pred == current_class_label_reshape)\n",
    "                                \n",
    "                total_correct += correct\n",
    "                total_seen += BATCH_SIZE\n",
    "                loss_sum += loss_val\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    total_class[i] += np.sum( np.ones(BATCH_SIZE) * i == current_class_label_reshape )\n",
    "                    total_detect_class[i] += np.sum( np.ones(BATCH_SIZE) * i == class_pred )\n",
    "                    total_correct_class[i] += np.sum( (np.ones(BATCH_SIZE) * i == current_class_label_reshape) * \\\n",
    "                                                        (np.ones(BATCH_SIZE) * i == class_pred) )\n",
    "                ## Heading regression\n",
    "                heading_rmse_sum += np.mean( np.square(heading_pred - current_heading_label_reshape) )\n",
    "                \n",
    "                \n",
    "                \n",
    "            log_string(  '[Epoch %d] Validation mean loss: %f' % \\\n",
    "                       (  epoch, loss_sum / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] Validation heading rmse[deg]: %f' % \\\n",
    "                       (  epoch, 360. * np.sqrt(heading_rmse_sum / float(num_batches) )  )   )\n",
    "            log_string(  '[Epoch %d] Validation class accuracy: %f'% \\\n",
    "                       (  epoch, total_correct / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] Validation avg class acc: %f' % \\\n",
    "                       (  epoch, np.mean( np.array(total_correct_class) / np.array(total_class,dtype=np.float) )  )   )\n",
    "\n",
    "            for i_cls in range(NUM_CLASSES):\n",
    "                if not float(total_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] Validation indivisual [%d] class recall: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "                if not float(total_detect_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] Validation indivisual [%d] class precision: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Save the variables to disk.\n",
    "            \"\"\"\n",
    "            if ( epoch + 1 ) % 10 == 0:\n",
    "                save_path = saver.save(sess, os.path.join(model_save_path, \"model.ckpt\"))\n",
    "                log_string(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "                \n",
    "# option 1: execute code with extra process\n",
    "p = multiprocessing.Process(target=run_training, args = ('./model_out5_5',))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "INFO:tensorflow:Summary name classify loss is illegal; using classify_loss instead.\n",
      "INFO:tensorflow:Summary name mat loss is illegal; using mat_loss instead.\n",
      "2018-12-04 10:18:38.955098  \n",
      "\n",
      " Train one epoch   1 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:21:40.234480  [Epoch 0] mean loss: 6.850015\n",
      "2018-12-04 10:21:40.238612  [Epoch 0] heading rmse[deg]: 199.225012\n",
      "2018-12-04 10:21:40.240438  [Epoch 0] class accuracy: 0.450360\n",
      "2018-12-04 10:21:40.242376  [Epoch 0] avg class acc: 0.339413\n",
      "2018-12-04 10:21:40.244103  [Epoch 0] indivisual [0] class recall: 0.435092\n",
      "2018-12-04 10:21:40.245793  [Epoch 0] indivisual [0] class precision: 0.444610\n",
      "2018-12-04 10:21:40.247450  [Epoch 0] indivisual [1] class recall: 0.571834\n",
      "2018-12-04 10:21:40.249171  [Epoch 0] indivisual [1] class precision: 0.458108\n",
      "2018-12-04 10:21:40.250748  [Epoch 0] indivisual [2] class recall: 0.011314\n",
      "2018-12-04 10:21:40.252344  [Epoch 0] indivisual [2] class precision: 0.178161\n",
      "2018-12-04 10:21:40.253914   Evaluation one (validation set) epoch   1 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:46<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:22:26.761508  [Epoch 0] Validation mean loss: 1.699160\n",
      "2018-12-04 10:22:26.763563  [Epoch 0] Validation heading rmse[deg]: 103.643718\n",
      "2018-12-04 10:22:26.765385  [Epoch 0] Validation class accuracy: 0.439219\n",
      "2018-12-04 10:22:26.767150  [Epoch 0] Validation avg class acc: 0.168806\n",
      "2018-12-04 10:22:26.768802  [Epoch 0] Validation indivisual [0] class recall: 0.049936\n",
      "2018-12-04 10:22:26.770426  [Epoch 0] Validation indivisual [0] class precision: 0.401058\n",
      "2018-12-04 10:22:26.772108  [Epoch 0] Validation indivisual [1] class recall: 0.456481\n",
      "2018-12-04 10:22:26.773704  [Epoch 0] Validation indivisual [1] class precision: 0.443715\n",
      "2018-12-04 10:22:26.775374  [Epoch 0] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 10:22:26.776970  \n",
      "\n",
      " Train one epoch   2 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:25:26.288190  [Epoch 1] mean loss: 2.304988\n",
      "2018-12-04 10:25:26.290151  [Epoch 1] heading rmse[deg]: 120.888409\n",
      "2018-12-04 10:25:26.291872  [Epoch 1] class accuracy: 0.465200\n",
      "2018-12-04 10:25:26.293750  [Epoch 1] avg class acc: 0.349056\n",
      "2018-12-04 10:25:26.295431  [Epoch 1] indivisual [0] class recall: 0.444059\n",
      "2018-12-04 10:25:26.297085  [Epoch 1] indivisual [0] class precision: 0.461378\n",
      "2018-12-04 10:25:26.298679  [Epoch 1] indivisual [1] class recall: 0.600604\n",
      "2018-12-04 10:25:26.300280  [Epoch 1] indivisual [1] class precision: 0.469253\n",
      "2018-12-04 10:25:26.301848  [Epoch 1] indivisual [2] class recall: 0.002505\n",
      "2018-12-04 10:25:26.303416  [Epoch 1] indivisual [2] class precision: 0.129630\n",
      "2018-12-04 10:25:26.304991   Evaluation one (validation set) epoch   2 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:26:12.647532  [Epoch 1] Validation mean loss: 1.686992\n",
      "2018-12-04 10:26:12.649382  [Epoch 1] Validation heading rmse[deg]: 103.876550\n",
      "2018-12-04 10:26:12.651062  [Epoch 1] Validation class accuracy: 0.432639\n",
      "2018-12-04 10:26:12.652942  [Epoch 1] Validation avg class acc: 0.170483\n",
      "2018-12-04 10:26:12.654628  [Epoch 1] Validation indivisual [0] class recall: 0.509010\n",
      "2018-12-04 10:26:12.656459  [Epoch 1] Validation indivisual [0] class precision: 0.437795\n",
      "2018-12-04 10:26:12.658163  [Epoch 1] Validation indivisual [1] class recall: 0.002440\n",
      "2018-12-04 10:26:12.659891  [Epoch 1] Validation indivisual [1] class precision: 0.127517\n",
      "2018-12-04 10:26:12.661555  [Epoch 1] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 10:26:12.663233  \n",
      "\n",
      " Train one epoch   3 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:29:12.053098  [Epoch 2] mean loss: 1.857132\n",
      "2018-12-04 10:29:12.054925  [Epoch 2] heading rmse[deg]: 108.611548\n",
      "2018-12-04 10:29:12.056644  [Epoch 2] class accuracy: 0.461360\n",
      "2018-12-04 10:29:12.058719  [Epoch 2] avg class acc: 0.346270\n",
      "2018-12-04 10:29:12.060393  [Epoch 2] indivisual [0] class recall: 0.396788\n",
      "2018-12-04 10:29:12.062018  [Epoch 2] indivisual [0] class precision: 0.457170\n",
      "2018-12-04 10:29:12.063737  [Epoch 2] indivisual [1] class recall: 0.640622\n",
      "2018-12-04 10:29:12.065431  [Epoch 2] indivisual [1] class precision: 0.465268\n",
      "2018-12-04 10:29:12.067321  [Epoch 2] indivisual [2] class recall: 0.001401\n",
      "2018-12-04 10:29:12.069441  [Epoch 2] indivisual [2] class precision: 0.074074\n",
      "2018-12-04 10:29:12.071166   Evaluation one (validation set) epoch   3 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:29:58.317010  [Epoch 2] Validation mean loss: 1.684919\n",
      "2018-12-04 10:29:58.318860  [Epoch 2] Validation heading rmse[deg]: 103.772797\n",
      "2018-12-04 10:29:58.320614  [Epoch 2] Validation class accuracy: 0.496468\n",
      "2018-12-04 10:29:58.322483  [Epoch 2] Validation avg class acc: 0.194218\n",
      "2018-12-04 10:29:58.324329  [Epoch 2] Validation indivisual [0] class recall: 0.383141\n",
      "2018-12-04 10:29:58.326072  [Epoch 2] Validation indivisual [0] class precision: 0.523795\n",
      "2018-12-04 10:29:58.327887  [Epoch 2] Validation indivisual [1] class recall: 0.199512\n",
      "2018-12-04 10:29:58.329604  [Epoch 2] Validation indivisual [1] class precision: 0.452427\n",
      "2018-12-04 10:29:58.331173  [Epoch 2] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 10:29:58.332720  \n",
      "\n",
      " Train one epoch   4 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:32:57.702241  [Epoch 3] mean loss: 1.756427\n",
      "2018-12-04 10:32:57.704470  [Epoch 3] heading rmse[deg]: 105.714875\n",
      "2018-12-04 10:32:57.706531  [Epoch 3] class accuracy: 0.459000\n",
      "2018-12-04 10:32:57.708888  [Epoch 3] avg class acc: 0.344228\n",
      "2018-12-04 10:32:57.710942  [Epoch 3] indivisual [0] class recall: 0.399745\n",
      "2018-12-04 10:32:57.712941  [Epoch 3] indivisual [0] class precision: 0.455197\n",
      "2018-12-04 10:32:57.714644  [Epoch 3] indivisual [1] class recall: 0.631157\n",
      "2018-12-04 10:32:57.716367  [Epoch 3] indivisual [1] class precision: 0.462714\n",
      "2018-12-04 10:32:57.718063  [Epoch 3] indivisual [2] class recall: 0.001782\n",
      "2018-12-04 10:32:57.719749  [Epoch 3] indivisual [2] class precision: 0.090909\n",
      "2018-12-04 10:32:57.721398   Evaluation one (validation set) epoch   4 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:33:43.959335  [Epoch 3] Validation mean loss: 1.686275\n",
      "2018-12-04 10:33:43.961346  [Epoch 3] Validation heading rmse[deg]: 103.876642\n",
      "2018-12-04 10:33:43.963317  [Epoch 3] Validation class accuracy: 0.568141\n",
      "2018-12-04 10:33:43.965246  [Epoch 3] Validation avg class acc: 0.220396\n",
      "2018-12-04 10:33:43.966948  [Epoch 3] Validation indivisual [0] class recall: 0.255324\n",
      "2018-12-04 10:33:43.968633  [Epoch 3] Validation indivisual [0] class precision: 0.609731\n",
      "2018-12-04 10:33:43.970349  [Epoch 3] Validation indivisual [1] class recall: 0.405864\n",
      "2018-12-04 10:33:43.972222  [Epoch 3] Validation indivisual [1] class precision: 0.545455\n",
      "2018-12-04 10:33:43.973892  [Epoch 3] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 10:33:43.975704  [Epoch 3] Validation indivisual [2] class precision: 0.000000\n",
      "2018-12-04 10:33:43.977595  \n",
      "\n",
      " Train one epoch   5 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:36:43.535801  [Epoch 4] mean loss: 1.740770\n",
      "2018-12-04 10:36:43.537853  [Epoch 4] heading rmse[deg]: 105.295562\n",
      "2018-12-04 10:36:43.539793  [Epoch 4] class accuracy: 0.468280\n",
      "2018-12-04 10:36:43.541871  [Epoch 4] avg class acc: 0.349951\n",
      "2018-12-04 10:36:43.543741  [Epoch 4] indivisual [0] class recall: 0.380922\n",
      "2018-12-04 10:36:43.545668  [Epoch 4] indivisual [0] class precision: 0.464417\n",
      "2018-12-04 10:36:43.547380  [Epoch 4] indivisual [1] class recall: 0.666402\n",
      "2018-12-04 10:36:43.549030  [Epoch 4] indivisual [1] class precision: 0.470937\n",
      "2018-12-04 10:36:43.550698  [Epoch 4] indivisual [2] class recall: 0.002529\n",
      "2018-12-04 10:36:43.552385  [Epoch 4] indivisual [2] class precision: 0.218750\n",
      "2018-12-04 10:36:43.554008   Evaluation one (validation set) epoch   5 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:37:29.518402  [Epoch 4] Validation mean loss: 1.685755\n",
      "2018-12-04 10:37:29.520385  [Epoch 4] Validation heading rmse[deg]: 103.813298\n",
      "2018-12-04 10:37:29.522170  [Epoch 4] Validation class accuracy: 0.450483\n",
      "2018-12-04 10:37:29.524245  [Epoch 4] Validation avg class acc: 0.174848\n",
      "2018-12-04 10:37:29.526207  [Epoch 4] Validation indivisual [0] class recall: 0.237995\n",
      "2018-12-04 10:37:29.527987  [Epoch 4] Validation indivisual [0] class precision: 0.486416\n",
      "2018-12-04 10:37:29.529770  [Epoch 4] Validation indivisual [1] class recall: 0.286550\n",
      "2018-12-04 10:37:29.531422  [Epoch 4] Validation indivisual [1] class precision: 0.425177\n",
      "2018-12-04 10:37:29.533158  [Epoch 4] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 10:37:29.534793  \n",
      "\n",
      " Train one epoch   6 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:40:29.686380  [Epoch 5] mean loss: 1.719204\n",
      "2018-12-04 10:40:29.688636  [Epoch 5] heading rmse[deg]: 104.894600\n",
      "2018-12-04 10:40:29.690483  [Epoch 5] class accuracy: 0.463800\n",
      "2018-12-04 10:40:29.692668  [Epoch 5] avg class acc: 0.348189\n",
      "2018-12-04 10:40:29.694712  [Epoch 5] indivisual [0] class recall: 0.379596\n",
      "2018-12-04 10:40:29.696405  [Epoch 5] indivisual [0] class precision: 0.452141\n",
      "2018-12-04 10:40:29.698098  [Epoch 5] indivisual [1] class recall: 0.659574\n",
      "2018-12-04 10:40:29.699833  [Epoch 5] indivisual [1] class precision: 0.471011\n",
      "2018-12-04 10:40:29.701555  [Epoch 5] indivisual [2] class recall: 0.005398\n",
      "2018-12-04 10:40:29.709044  [Epoch 5] indivisual [2] class precision: 0.333333\n",
      "2018-12-04 10:40:29.710637   Evaluation one (validation set) epoch   6 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:41:15.482313  [Epoch 5] Validation mean loss: 1.924292\n",
      "2018-12-04 10:41:15.484292  [Epoch 5] Validation heading rmse[deg]: 111.194445\n",
      "2018-12-04 10:41:15.486166  [Epoch 5] Validation class accuracy: 0.502416\n",
      "2018-12-04 10:41:15.488110  [Epoch 5] Validation avg class acc: 0.195557\n",
      "2018-12-04 10:41:15.489888  [Epoch 5] Validation indivisual [0] class recall: 0.321527\n",
      "2018-12-04 10:41:15.491834  [Epoch 5] Validation indivisual [0] class precision: 0.455286\n",
      "2018-12-04 10:41:15.493768  [Epoch 5] Validation indivisual [1] class recall: 0.265144\n",
      "2018-12-04 10:41:15.495657  [Epoch 5] Validation indivisual [1] class precision: 0.572578\n",
      "2018-12-04 10:41:15.497574  [Epoch 5] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 10:41:15.499304  \n",
      "\n",
      " Train one epoch   7 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:44:14.945114  [Epoch 6] mean loss: 1.711618\n",
      "2018-12-04 10:44:14.947352  [Epoch 6] heading rmse[deg]: 104.782922\n",
      "2018-12-04 10:44:14.949202  [Epoch 6] class accuracy: 0.470240\n",
      "2018-12-04 10:44:14.950934  [Epoch 6] avg class acc: 0.356162\n",
      "2018-12-04 10:44:14.952721  [Epoch 6] indivisual [0] class recall: 0.389250\n",
      "2018-12-04 10:44:14.954510  [Epoch 6] indivisual [0] class precision: 0.452696\n",
      "2018-12-04 10:44:14.956437  [Epoch 6] indivisual [1] class recall: 0.661328\n",
      "2018-12-04 10:44:14.958325  [Epoch 6] indivisual [1] class precision: 0.480247\n",
      "2018-12-04 10:44:14.960288  [Epoch 6] indivisual [2] class recall: 0.017909\n",
      "2018-12-04 10:44:14.962045  [Epoch 6] indivisual [2] class precision: 0.644737\n",
      "2018-12-04 10:44:14.963711   Evaluation one (validation set) epoch   7 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:45:00.394108  [Epoch 6] Validation mean loss: 1.842134\n",
      "2018-12-04 10:45:00.395999  [Epoch 6] Validation heading rmse[deg]: 108.930740\n",
      "2018-12-04 10:45:00.397813  [Epoch 6] Validation class accuracy: 0.489145\n",
      "2018-12-04 10:45:00.399743  [Epoch 6] Validation avg class acc: 0.191129\n",
      "2018-12-04 10:45:00.401399  [Epoch 6] Validation indivisual [0] class recall: 0.481341\n",
      "2018-12-04 10:45:00.403287  [Epoch 6] Validation indivisual [0] class precision: 0.459609\n",
      "2018-12-04 10:45:00.405134  [Epoch 6] Validation indivisual [1] class recall: 0.092045\n",
      "2018-12-04 10:45:00.406840  [Epoch 6] Validation indivisual [1] class precision: 0.730402\n",
      "2018-12-04 10:45:00.408559  [Epoch 6] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 10:45:00.410250  \n",
      "\n",
      " Train one epoch   8 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:57<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:47:59.756114  [Epoch 7] mean loss: 1.716441\n",
      "2018-12-04 10:47:59.758212  [Epoch 7] heading rmse[deg]: 104.797849\n",
      "2018-12-04 10:47:59.760130  [Epoch 7] class accuracy: 0.476560\n",
      "2018-12-04 10:47:59.762231  [Epoch 7] avg class acc: 0.373196\n",
      "2018-12-04 10:47:59.764233  [Epoch 7] indivisual [0] class recall: 0.393948\n",
      "2018-12-04 10:47:59.765922  [Epoch 7] indivisual [0] class precision: 0.445988\n",
      "2018-12-04 10:47:59.767505  [Epoch 7] indivisual [1] class recall: 0.662697\n",
      "2018-12-04 10:47:59.769317  [Epoch 7] indivisual [1] class precision: 0.494984\n",
      "2018-12-04 10:47:59.771237  [Epoch 7] indivisual [2] class recall: 0.062942\n",
      "2018-12-04 10:47:59.772962  [Epoch 7] indivisual [2] class precision: 0.542683\n",
      "2018-12-04 10:47:59.774659   Evaluation one (validation set) epoch   8 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:48:45.539815  [Epoch 7] Validation mean loss: 2.229820\n",
      "2018-12-04 10:48:45.541815  [Epoch 7] Validation heading rmse[deg]: 120.278610\n",
      "2018-12-04 10:48:45.543709  [Epoch 7] Validation class accuracy: 0.548030\n",
      "2018-12-04 10:48:45.545650  [Epoch 7] Validation avg class acc: 0.308474\n",
      "2018-12-04 10:48:45.547342  [Epoch 7] Validation indivisual [0] class recall: 0.436100\n",
      "2018-12-04 10:48:45.549157  [Epoch 7] Validation indivisual [0] class precision: 0.494064\n",
      "2018-12-04 10:48:45.551057  [Epoch 7] Validation indivisual [1] class recall: 0.111593\n",
      "2018-12-04 10:48:45.552867  [Epoch 7] Validation indivisual [1] class precision: 0.619513\n",
      "2018-12-04 10:48:45.554373  [Epoch 7] Validation indivisual [2] class recall: 0.377728\n",
      "2018-12-04 10:48:45.556033  [Epoch 7] Validation indivisual [2] class precision: 0.853592\n",
      "2018-12-04 10:48:45.557651  \n",
      "\n",
      " Train one epoch   9 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:51:44.779178  [Epoch 8] mean loss: 1.687665\n",
      "2018-12-04 10:51:44.780873  [Epoch 8] heading rmse[deg]: 104.037397\n",
      "2018-12-04 10:51:44.782417  [Epoch 8] class accuracy: 0.509360\n",
      "2018-12-04 10:51:44.784069  [Epoch 8] avg class acc: 0.447316\n",
      "2018-12-04 10:51:44.785582  [Epoch 8] indivisual [0] class recall: 0.462985\n",
      "2018-12-04 10:51:44.787054  [Epoch 8] indivisual [0] class precision: 0.463907\n",
      "2018-12-04 10:51:44.788432  [Epoch 8] indivisual [1] class recall: 0.621326\n",
      "2018-12-04 10:51:44.790208  [Epoch 8] indivisual [1] class precision: 0.536467\n",
      "2018-12-04 10:51:44.792263  [Epoch 8] indivisual [2] class recall: 0.257639\n",
      "2018-12-04 10:51:44.794024  [Epoch 8] indivisual [2] class precision: 0.643539\n",
      "2018-12-04 10:51:44.795768   Evaluation one (validation set) epoch   9 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:52:30.382857  [Epoch 8] Validation mean loss: 5.007278\n",
      "2018-12-04 10:52:30.384831  [Epoch 8] Validation heading rmse[deg]: 172.423310\n",
      "2018-12-04 10:52:30.386548  [Epoch 8] Validation class accuracy: 0.519703\n",
      "2018-12-04 10:52:30.388501  [Epoch 8] Validation avg class acc: 0.256389\n",
      "2018-12-04 10:52:30.390283  [Epoch 8] Validation indivisual [0] class recall: 0.464903\n",
      "2018-12-04 10:52:30.392222  [Epoch 8] Validation indivisual [0] class precision: 0.475105\n",
      "2018-12-04 10:52:30.394167  [Epoch 8] Validation indivisual [1] class recall: 0.090379\n",
      "2018-12-04 10:52:30.395978  [Epoch 8] Validation indivisual [1] class precision: 0.666773\n",
      "2018-12-04 10:52:30.397657  [Epoch 8] Validation indivisual [2] class recall: 0.213885\n",
      "2018-12-04 10:52:30.399295  [Epoch 8] Validation indivisual [2] class precision: 0.906273\n",
      "2018-12-04 10:52:30.400955  \n",
      "\n",
      " Train one epoch  10 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:55:29.693547  [Epoch 9] mean loss: 1.694527\n",
      "2018-12-04 10:55:29.695530  [Epoch 9] heading rmse[deg]: 104.234295\n",
      "2018-12-04 10:55:29.697331  [Epoch 9] class accuracy: 0.534480\n",
      "2018-12-04 10:55:29.699201  [Epoch 9] avg class acc: 0.517093\n",
      "2018-12-04 10:55:29.700966  [Epoch 9] indivisual [0] class recall: 0.420652\n",
      "2018-12-04 10:55:29.702719  [Epoch 9] indivisual [0] class precision: 0.474718\n",
      "2018-12-04 10:55:29.704632  [Epoch 9] indivisual [1] class recall: 0.660957\n",
      "2018-12-04 10:55:29.706477  [Epoch 9] indivisual [1] class precision: 0.554629\n",
      "2018-12-04 10:55:29.708263  [Epoch 9] indivisual [2] class recall: 0.469670\n",
      "2018-12-04 10:55:29.710005  [Epoch 9] indivisual [2] class precision: 0.696109\n",
      "2018-12-04 10:55:29.711737   Evaluation one (validation set) epoch  10 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:56:15.237725  [Epoch 9] Validation mean loss: 3.361261\n",
      "2018-12-04 10:56:15.258277  [Epoch 9] Validation heading rmse[deg]: 143.956301\n",
      "2018-12-04 10:56:15.260991  [Epoch 9] Validation class accuracy: 0.502825\n",
      "2018-12-04 10:56:15.263058  [Epoch 9] Validation avg class acc: 0.261176\n",
      "2018-12-04 10:56:15.264796  [Epoch 9] Validation indivisual [0] class recall: 0.295635\n",
      "2018-12-04 10:56:15.266501  [Epoch 9] Validation indivisual [0] class precision: 0.452634\n",
      "2018-12-04 10:56:15.268214  [Epoch 9] Validation indivisual [1] class recall: 0.226321\n",
      "2018-12-04 10:56:15.269908  [Epoch 9] Validation indivisual [1] class precision: 0.505642\n",
      "2018-12-04 10:56:15.271619  [Epoch 9] Validation indivisual [2] class recall: 0.261573\n",
      "2018-12-04 10:56:15.273219  [Epoch 9] Validation indivisual [2] class precision: 0.950000\n",
      "2018-12-04 10:56:16.264631  Model saved in file: /home/gozilla/kyungpyo/git/MasterThesisProject/Network/notebook/train_log_20181204/model_out5_6/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Import model \"\"\"\n",
    "sys.path.append( os.path.abspath('../../model') )\n",
    "\n",
    "from train import *\n",
    "import model_out_5_heading as MODEL\n",
    "\n",
    "def run_training(out_path):\n",
    "    \n",
    "    \"\"\" Path \"\"\"\n",
    "    model_save_path = os.path.abspath(out_path)\n",
    "    if not os.path.isdir(model_save_path) : os.mkdir(model_save_path)\n",
    "    log_path = os.path.abspath(os.path.join(model_save_path, 'train_log.txt') )\n",
    "        \n",
    "    \"\"\" Parameters \"\"\"\n",
    "    GPU_INDEX = 0\n",
    "    NUM_POINT = 1024\n",
    "    NUM_CLASSES = 3\n",
    "\n",
    "    BN_INIT_DECAY = 0.5\n",
    "    BN_DECAY_DECAY_RATE = 0.5\n",
    "    BN_DECAY_DECAY_STEP = float(200000)\n",
    "    BN_DECAY_CLIP = 0.99\n",
    "    DECAY_STEP = BN_DECAY_DECAY_STEP\n",
    "    DECAY_RATE = BN_DECAY_DECAY_RATE\n",
    "\n",
    "    BATCH_SIZE = 50\n",
    "\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    BASE_LEARNING_RATE = 0.001\n",
    "\n",
    "    OPTIMIZER = 'adam'\n",
    "\n",
    "    MAX_EPOCH = 10\n",
    "\n",
    "    \"\"\" log file \"\"\"\n",
    "    LOG_FOUT = open(log_path, 'w')\n",
    "\n",
    "    def log_string(out_str):\n",
    "        out_str = str( datetime.datetime.fromtimestamp( time.time() ) ) + \"  \" + out_str\n",
    "        LOG_FOUT.write(out_str+'\\n')\n",
    "        LOG_FOUT.flush()\n",
    "        print(out_str)\n",
    "\n",
    "\n",
    "    def get_learning_rate(batch):\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "                            BASE_LEARNING_RATE,  # Base learning rate.\n",
    "                            batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                            DECAY_STEP,          # Decay step.\n",
    "                            DECAY_RATE,          # Decay rate.\n",
    "                            staircase=True)\n",
    "        learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n",
    "        return learning_rate        \n",
    "\n",
    "    def get_bn_decay(batch):\n",
    "        bn_momentum = tf.train.exponential_decay(\n",
    "                          BN_INIT_DECAY,\n",
    "                          batch * BATCH_SIZE,\n",
    "                          BN_DECAY_DECAY_STEP,\n",
    "                          BN_DECAY_DECAY_RATE,\n",
    "                          staircase=True)\n",
    "        bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "        return bn_decay\n",
    "\n",
    "    \"\"\" load traing model \"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Placeholder\n",
    "            \"\"\"\n",
    "            pointclouds_pl, class_labels_pl, heading_labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "            is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "            print(is_training_pl)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            decay\n",
    "            \"\"\"\n",
    "            # Note the global_step=batch parameter to minimize. \n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.summary.scalar('bn_decay', bn_decay)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Get model and loss \n",
    "            \"\"\"\n",
    "            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n",
    "            loss = MODEL.get_loss(pred, class_labels_pl, heading_labels_pl, end_points, h_reg_weight=1000)\n",
    "            tf.summary.scalar('loss', loss)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Get accuracy \n",
    "            \"\"\"\n",
    "            correct = tf.equal(tf.argmax(tf.slice(pred, [0,0], [BATCH_SIZE,3]), 1), tf.to_int64(class_labels_pl))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Get training operator\n",
    "            \"\"\"\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            if OPTIMIZER == 'momentum':\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n",
    "            elif OPTIMIZER == 'adam':\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss, global_step=batch)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Add ops to save and restore all the variables.\n",
    "            \"\"\"\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        Create a session\n",
    "        \"\"\"\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = False\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Add summary writers\n",
    "        merged = tf.merge_all_summaries()\n",
    "        \"\"\"\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        train_writer_path = os.path.abspath( os.path.join(model_save_path, 'train') )\n",
    "        if os.path.isdir(train_writer_path): os.system('rm -r {}'.format(train_writer_path))\n",
    "        os.mkdir(train_writer_path)\n",
    "\n",
    "        test_writer_path = os.path.abspath( os.path.join(model_save_path, 'test') )\n",
    "        if os.path.isdir(test_writer_path): os.system('rm -r {}'.format(test_writer_path))\n",
    "        os.mkdir(test_writer_path)\n",
    "\n",
    "\n",
    "        train_writer = tf.summary.FileWriter(train_writer_path, sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(test_writer_path)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Init variables\n",
    "        \"\"\"\n",
    "        init = tf.global_variables_initializer()\n",
    "        # To fix the bug introduced in TF 0.12.1 as in\n",
    "        # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n",
    "        #sess.run(init)\n",
    "        sess.run(init, {is_training_pl: True})\n",
    "\n",
    "        ops = {'pointclouds_pl': pointclouds_pl,\n",
    "               'class_labels_pl': class_labels_pl,\n",
    "               'heading_labels_pl': heading_labels_pl,\n",
    "               'is_training_pl': is_training_pl,\n",
    "               'pred': pred,\n",
    "               'loss': loss,\n",
    "               'train_op': train_op,\n",
    "               'merged': merged,\n",
    "               'step': batch}\n",
    "\n",
    "\n",
    "        for epoch in range(MAX_EPOCH):\n",
    "\n",
    "            ## Training\n",
    "            log_string ( \"\\n\\n Train one epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = True\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle train files\n",
    "            \"\"\"\n",
    "            train_file_idxs = np.arange(0, data_train.shape[0])\n",
    "            np.random.shuffle(train_file_idxs)\n",
    "\n",
    "            current_data = data_train[train_file_idxs] \n",
    "            current_class_label = class_label_train[train_file_idxs]\n",
    "            current_heading_label = heading_label_train[train_file_idxs]\n",
    "            \n",
    "            current_class_label.reshape((data_train.shape[0],))\n",
    "            current_heading_label.reshape((data_train.shape[0],))\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            heading_rmse_sum = 0\n",
    "            \n",
    "            total_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "   \n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE          \n",
    "    \n",
    "\n",
    "            \"\"\"\n",
    "            Run batch training\n",
    "            \"\"\"\n",
    "            num_batches = 500\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE           \n",
    "\n",
    "                # Augment batched point clouds by rotation and jittering\n",
    "                rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])\n",
    "                jittered_data = provider.jitter_point_cloud(rotated_data)\n",
    "\n",
    "                # Reashape\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                feed_dict = {ops['pointclouds_pl']: jittered_data,\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training,}\n",
    "\n",
    "                summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                    ops['train_op'], ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                train_writer.add_summary(summary, step)\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                \n",
    "                ## classification\n",
    "                class_pred = pred_val[:,:3]\n",
    "                heading_pred = pred_val[:,3]\n",
    "                \n",
    "                class_pred = np.argmax(class_pred, 1)\n",
    "                correct = np.sum(class_pred == current_class_label_reshape)\n",
    "                                \n",
    "                total_correct += correct\n",
    "                total_seen += BATCH_SIZE\n",
    "                loss_sum += loss_val\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    total_class[i] += np.sum( np.ones(BATCH_SIZE) * i == current_class_label_reshape )\n",
    "                    total_detect_class[i] += np.sum( np.ones(BATCH_SIZE) * i == class_pred )\n",
    "                    total_correct_class[i] += np.sum( (np.ones(BATCH_SIZE) * i == current_class_label_reshape) * \\\n",
    "                                                        (np.ones(BATCH_SIZE) * i == class_pred) )\n",
    "                ## Heading regression\n",
    "                heading_rmse_sum += np.mean( np.square(heading_pred - current_heading_label_reshape) )\n",
    "\n",
    "            log_string(  '[Epoch %d] mean loss: %f' % \\\n",
    "                       (  epoch, loss_sum / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] heading rmse[deg]: %f' % \\\n",
    "                       (  epoch, 360. * np.sqrt(heading_rmse_sum / float(num_batches) )  )   )\n",
    "            log_string(  '[Epoch %d] class accuracy: %f'% \\\n",
    "                       (  epoch, total_correct / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] avg class acc: %f' % \\\n",
    "                       (  epoch, np.mean( np.array(total_correct_class) / np.array(total_class,dtype=np.float) )  )   )\n",
    "\n",
    "            for i_cls in range(NUM_CLASSES):\n",
    "                if not float(total_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] indivisual [%d] class recall: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "                if not float(total_detect_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] indivisual [%d] class precision: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation using validation set    \n",
    "            \"\"\"\n",
    "            \n",
    "            log_string ( \" Evaluation one (validation set) epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = False\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            heading_rmse_sum = 0\n",
    "            \n",
    "            total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_true_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle validation files\n",
    "            \"\"\"\n",
    "            file_idxs = np.arange(0, data_vali.shape[0])\n",
    "            np.random.shuffle(file_idxs)\n",
    "\n",
    "            current_data = data_vali[file_idxs]\n",
    "            current_class_label = class_label_vali[file_idxs]\n",
    "            current_heading_label = heading_label_vali[file_idxs]\n",
    "\n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Run batch validation\n",
    "            \"\"\"\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Reashape\n",
    "                \"\"\"\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Feed dict\n",
    "                \"\"\"\n",
    "                feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training}\n",
    "                \n",
    "                \"\"\"\n",
    "                Summary\n",
    "                \"\"\"\n",
    "                summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                    ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                \n",
    "                ## classification\n",
    "                class_pred = pred_val[:,:3]\n",
    "                heading_pred = pred_val[:,3]\n",
    "                \n",
    "                class_pred = np.argmax(class_pred, 1)\n",
    "                correct = np.sum(class_pred == current_class_label_reshape)\n",
    "                                \n",
    "                total_correct += correct\n",
    "                total_seen += BATCH_SIZE\n",
    "                loss_sum += loss_val\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    total_class[i] += np.sum( np.ones(BATCH_SIZE) * i == current_class_label_reshape )\n",
    "                    total_detect_class[i] += np.sum( np.ones(BATCH_SIZE) * i == class_pred )\n",
    "                    total_correct_class[i] += np.sum( (np.ones(BATCH_SIZE) * i == current_class_label_reshape) * \\\n",
    "                                                        (np.ones(BATCH_SIZE) * i == class_pred) )\n",
    "                ## Heading regression\n",
    "                heading_rmse_sum += np.mean( np.square(heading_pred - current_heading_label_reshape) )\n",
    "                \n",
    "                \n",
    "                \n",
    "            log_string(  '[Epoch %d] Validation mean loss: %f' % \\\n",
    "                       (  epoch, loss_sum / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] Validation heading rmse[deg]: %f' % \\\n",
    "                       (  epoch, 360. * np.sqrt(heading_rmse_sum / float(num_batches) )  )   )\n",
    "            log_string(  '[Epoch %d] Validation class accuracy: %f'% \\\n",
    "                       (  epoch, total_correct / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] Validation avg class acc: %f' % \\\n",
    "                       (  epoch, np.mean( np.array(total_correct_class) / np.array(total_class,dtype=np.float) )  )   )\n",
    "\n",
    "            for i_cls in range(NUM_CLASSES):\n",
    "                if not float(total_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] Validation indivisual [%d] class recall: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "                if not float(total_detect_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] Validation indivisual [%d] class precision: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Save the variables to disk.\n",
    "            \"\"\"\n",
    "            if ( epoch + 1 ) % 10 == 0:\n",
    "                save_path = saver.save(sess, os.path.join(model_save_path, \"model.ckpt\"))\n",
    "                log_string(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "                \n",
    "# option 1: execute code with extra process\n",
    "p = multiprocessing.Process(target=run_training, args = ('./model_out5_6',))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "INFO:tensorflow:Summary name classify loss is illegal; using classify_loss instead.\n",
      "INFO:tensorflow:Summary name mat loss is illegal; using mat_loss instead.\n",
      "2018-12-04 10:56:25.322662  \n",
      "\n",
      " Train one epoch   1 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 10:59:26.817247  [Epoch 0] mean loss: 57.466227\n",
      "2018-12-04 10:59:26.819349  [Epoch 0] heading rmse[deg]: 187.971483\n",
      "2018-12-04 10:59:26.821300  [Epoch 0] class accuracy: 0.449400\n",
      "2018-12-04 10:59:26.823455  [Epoch 0] avg class acc: 0.338912\n",
      "2018-12-04 10:59:26.825329  [Epoch 0] indivisual [0] class recall: 0.437733\n",
      "2018-12-04 10:59:26.827222  [Epoch 0] indivisual [0] class precision: 0.452023\n",
      "2018-12-04 10:59:26.828996  [Epoch 0] indivisual [1] class recall: 0.566959\n",
      "2018-12-04 10:59:26.830624  [Epoch 0] indivisual [1] class precision: 0.454688\n",
      "2018-12-04 10:59:26.832385  [Epoch 0] indivisual [2] class recall: 0.012044\n",
      "2018-12-04 10:59:26.834106  [Epoch 0] indivisual [2] class precision: 0.109635\n",
      "2018-12-04 10:59:26.835859   Evaluation one (validation set) epoch   1 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:00:12.545288  [Epoch 0] Validation mean loss: 16.995526\n",
      "2018-12-04 11:00:12.547014  [Epoch 0] Validation heading rmse[deg]: 104.531295\n",
      "2018-12-04 11:00:12.548889  [Epoch 0] Validation class accuracy: 0.438662\n",
      "2018-12-04 11:00:12.550832  [Epoch 0] Validation avg class acc: 0.172746\n",
      "2018-12-04 11:00:12.552720  [Epoch 0] Validation indivisual [0] class recall: 0.517897\n",
      "2018-12-04 11:00:12.554591  [Epoch 0] Validation indivisual [0] class precision: 0.438495\n",
      "2018-12-04 11:00:12.556386  [Epoch 0] Validation indivisual [1] class recall: 0.000342\n",
      "2018-12-04 11:00:12.558139  [Epoch 0] Validation indivisual [1] class precision: 1.000000\n",
      "2018-12-04 11:00:12.559840  [Epoch 0] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:00:12.561539  \n",
      "\n",
      " Train one epoch   2 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:57<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:03:11.759889  [Epoch 1] mean loss: 20.721865\n",
      "2018-12-04 11:03:11.762163  [Epoch 1] heading rmse[deg]: 115.411687\n",
      "2018-12-04 11:03:11.764083  [Epoch 1] class accuracy: 0.450400\n",
      "2018-12-04 11:03:11.766050  [Epoch 1] avg class acc: 0.337866\n",
      "2018-12-04 11:03:11.767886  [Epoch 1] indivisual [0] class recall: 0.438122\n",
      "2018-12-04 11:03:11.769729  [Epoch 1] indivisual [0] class precision: 0.443141\n",
      "2018-12-04 11:03:11.771549  [Epoch 1] indivisual [1] class recall: 0.573687\n",
      "2018-12-04 11:03:11.773218  [Epoch 1] indivisual [1] class precision: 0.456493\n",
      "2018-12-04 11:03:11.774734  [Epoch 1] indivisual [2] class recall: 0.001790\n",
      "2018-12-04 11:03:11.776420  [Epoch 1] indivisual [2] class precision: 0.178571\n",
      "2018-12-04 11:03:11.778018   Evaluation one (validation set) epoch   2 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:03:57.224511  [Epoch 1] Validation mean loss: 16.722846\n",
      "2018-12-04 11:03:57.226494  [Epoch 1] Validation heading rmse[deg]: 103.805919\n",
      "2018-12-04 11:03:57.228329  [Epoch 1] Validation class accuracy: 0.438625\n",
      "2018-12-04 11:03:57.230220  [Epoch 1] Validation avg class acc: 0.172864\n",
      "2018-12-04 11:03:57.232173  [Epoch 1] Validation indivisual [0] class recall: 0.518592\n",
      "2018-12-04 11:03:57.234028  [Epoch 1] Validation indivisual [0] class precision: 0.438690\n",
      "2018-12-04 11:03:57.235958  [Epoch 1] Validation indivisual [1] class recall: 0.000000\n",
      "2018-12-04 11:03:57.237668  [Epoch 1] Validation indivisual [1] class precision: 0.000000\n",
      "2018-12-04 11:03:57.239379  [Epoch 1] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:03:57.241058  \n",
      "\n",
      " Train one epoch   3 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:57<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:06:56.275527  [Epoch 2] mean loss: 17.828412\n",
      "2018-12-04 11:06:56.277535  [Epoch 2] heading rmse[deg]: 107.333484\n",
      "2018-12-04 11:06:56.279375  [Epoch 2] class accuracy: 0.458880\n",
      "2018-12-04 11:06:56.281246  [Epoch 2] avg class acc: 0.343865\n",
      "2018-12-04 11:06:56.282909  [Epoch 2] indivisual [0] class recall: 0.375860\n",
      "2018-12-04 11:06:56.284580  [Epoch 2] indivisual [0] class precision: 0.460993\n",
      "2018-12-04 11:06:56.286178  [Epoch 2] indivisual [1] class recall: 0.655733\n",
      "2018-12-04 11:06:56.288525  [Epoch 2] indivisual [1] class precision: 0.457715\n",
      "2018-12-04 11:06:56.290464  [Epoch 2] indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:06:56.292339   Evaluation one (validation set) epoch   3 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:07:41.695135  [Epoch 2] Validation mean loss: 16.670247\n",
      "2018-12-04 11:07:41.696977  [Epoch 2] Validation heading rmse[deg]: 103.727472\n",
      "2018-12-04 11:07:41.698623  [Epoch 2] Validation class accuracy: 0.479517\n",
      "2018-12-04 11:07:41.700492  [Epoch 2] Validation avg class acc: 0.185127\n",
      "2018-12-04 11:07:41.702158  [Epoch 2] Validation indivisual [0] class recall: 0.110117\n",
      "2018-12-04 11:07:41.703872  [Epoch 2] Validation indivisual [0] class precision: 0.538346\n",
      "2018-12-04 11:07:41.705523  [Epoch 2] Validation indivisual [1] class recall: 0.445263\n",
      "2018-12-04 11:07:41.707129  [Epoch 2] Validation indivisual [1] class precision: 0.467248\n",
      "2018-12-04 11:07:41.708676  [Epoch 2] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:07:41.710216  \n",
      "\n",
      " Train one epoch   4 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:10:40.979458  [Epoch 3] mean loss: 17.183917\n",
      "2018-12-04 11:10:40.981756  [Epoch 3] heading rmse[deg]: 105.167671\n",
      "2018-12-04 11:10:40.983638  [Epoch 3] class accuracy: 0.451480\n",
      "2018-12-04 11:10:40.985555  [Epoch 3] avg class acc: 0.338070\n",
      "2018-12-04 11:10:40.987339  [Epoch 3] indivisual [0] class recall: 0.382876\n",
      "2018-12-04 11:10:40.989090  [Epoch 3] indivisual [0] class precision: 0.449091\n",
      "2018-12-04 11:10:40.990745  [Epoch 3] indivisual [1] class recall: 0.631335\n",
      "2018-12-04 11:10:40.992381  [Epoch 3] indivisual [1] class precision: 0.452994\n",
      "2018-12-04 11:10:40.994022  [Epoch 3] indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:10:40.995700  [Epoch 3] indivisual [2] class precision: 0.000000\n",
      "2018-12-04 11:10:40.997353   Evaluation one (validation set) epoch   4 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:11:26.480292  [Epoch 3] Validation mean loss: 16.696503\n",
      "2018-12-04 11:11:26.482276  [Epoch 3] Validation heading rmse[deg]: 104.049649\n",
      "2018-12-04 11:11:26.484115  [Epoch 3] Validation class accuracy: 0.453829\n",
      "2018-12-04 11:11:26.486041  [Epoch 3] Validation avg class acc: 0.174477\n",
      "2018-12-04 11:11:26.487965  [Epoch 3] Validation indivisual [0] class recall: 0.004698\n",
      "2018-12-04 11:11:26.489875  [Epoch 3] Validation indivisual [0] class precision: 1.000000\n",
      "2018-12-04 11:11:26.491581  [Epoch 3] Validation indivisual [1] class recall: 0.518733\n",
      "2018-12-04 11:11:26.493332  [Epoch 3] Validation indivisual [1] class precision: 0.451648\n",
      "2018-12-04 11:11:26.495016  [Epoch 3] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:11:26.496789  \n",
      "\n",
      " Train one epoch   5 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:14:25.680275  [Epoch 4] mean loss: 17.034676\n",
      "2018-12-04 11:14:25.682259  [Epoch 4] heading rmse[deg]: 104.926518\n",
      "2018-12-04 11:14:25.684250  [Epoch 4] class accuracy: 0.462720\n",
      "2018-12-04 11:14:25.686410  [Epoch 4] avg class acc: 0.344872\n",
      "2018-12-04 11:14:25.688299  [Epoch 4] indivisual [0] class recall: 0.351782\n",
      "2018-12-04 11:14:25.690245  [Epoch 4] indivisual [0] class precision: 0.465728\n",
      "2018-12-04 11:14:25.692218  [Epoch 4] indivisual [1] class recall: 0.682834\n",
      "2018-12-04 11:14:25.693999  [Epoch 4] indivisual [1] class precision: 0.461295\n",
      "2018-12-04 11:14:25.695904  [Epoch 4] indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:14:25.697727  [Epoch 4] indivisual [2] class precision: 0.000000\n",
      "2018-12-04 11:14:25.699336   Evaluation one (validation set) epoch   5 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:15:11.146686  [Epoch 4] Validation mean loss: 16.696837\n",
      "2018-12-04 11:15:11.148713  [Epoch 4] Validation heading rmse[deg]: 104.004661\n",
      "2018-12-04 11:15:11.150570  [Epoch 4] Validation class accuracy: 0.450223\n",
      "2018-12-04 11:15:11.152652  [Epoch 4] Validation avg class acc: 0.172378\n",
      "2018-12-04 11:15:11.154505  [Epoch 4] Validation indivisual [0] class recall: 0.000440\n",
      "2018-12-04 11:15:11.156259  [Epoch 4] Validation indivisual [0] class precision: 1.000000\n",
      "2018-12-04 11:15:11.157936  [Epoch 4] Validation indivisual [1] class recall: 0.516695\n",
      "2018-12-04 11:15:11.159557  [Epoch 4] Validation indivisual [1] class precision: 0.450019\n",
      "2018-12-04 11:15:11.161167  [Epoch 4] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:15:11.162728  \n",
      "\n",
      " Train one epoch   6 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:57<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:18:09.999755  [Epoch 5] mean loss: 16.901673\n",
      "2018-12-04 11:18:10.001719  [Epoch 5] heading rmse[deg]: 104.628230\n",
      "2018-12-04 11:18:10.003499  [Epoch 5] class accuracy: 0.452960\n",
      "2018-12-04 11:18:10.005414  [Epoch 5] avg class acc: 0.338277\n",
      "2018-12-04 11:18:10.007059  [Epoch 5] indivisual [0] class recall: 0.308518\n",
      "2018-12-04 11:18:10.009014  [Epoch 5] indivisual [0] class precision: 0.458914\n",
      "2018-12-04 11:18:10.010655  [Epoch 5] indivisual [1] class recall: 0.706312\n",
      "2018-12-04 11:18:10.012519  [Epoch 5] indivisual [1] class precision: 0.450693\n",
      "2018-12-04 11:18:10.014302  [Epoch 5] indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:18:10.015973  [Epoch 5] indivisual [2] class precision: 0.000000\n",
      "2018-12-04 11:18:10.017667   Evaluation one (validation set) epoch   6 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:18:55.420546  [Epoch 5] Validation mean loss: 16.844349\n",
      "2018-12-04 11:18:55.422482  [Epoch 5] Validation heading rmse[deg]: 104.424261\n",
      "2018-12-04 11:18:55.424245  [Epoch 5] Validation class accuracy: 0.450149\n",
      "2018-12-04 11:18:55.426091  [Epoch 5] Validation avg class acc: 0.172921\n",
      "2018-12-04 11:18:55.428063  [Epoch 5] Validation indivisual [0] class recall: 0.000000\n",
      "2018-12-04 11:18:55.430009  [Epoch 5] Validation indivisual [1] class recall: 0.518764\n",
      "2018-12-04 11:18:55.431792  [Epoch 5] Validation indivisual [1] class precision: 0.450149\n",
      "2018-12-04 11:18:55.433604  [Epoch 5] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:18:55.435338  \n",
      "\n",
      " Train one epoch   7 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:57<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:21:54.351432  [Epoch 6] mean loss: 17.010183\n",
      "2018-12-04 11:21:54.353589  [Epoch 6] heading rmse[deg]: 104.657513\n",
      "2018-12-04 11:21:54.355444  [Epoch 6] class accuracy: 0.451720\n",
      "2018-12-04 11:21:54.357208  [Epoch 6] avg class acc: 0.337991\n",
      "2018-12-04 11:21:54.358853  [Epoch 6] indivisual [0] class recall: 0.445076\n",
      "2018-12-04 11:21:54.360557  [Epoch 6] indivisual [0] class precision: 0.452835\n",
      "2018-12-04 11:21:54.362220  [Epoch 6] indivisual [1] class recall: 0.568898\n",
      "2018-12-04 11:21:54.363878  [Epoch 6] indivisual [1] class precision: 0.450890\n",
      "2018-12-04 11:21:54.365466  [Epoch 6] indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:21:54.366965  [Epoch 6] indivisual [2] class precision: 0.000000\n",
      "2018-12-04 11:21:54.368554   Evaluation one (validation set) epoch   7 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:22:39.805643  [Epoch 6] Validation mean loss: 16.975971\n",
      "2018-12-04 11:22:39.807577  [Epoch 6] Validation heading rmse[deg]: 104.789708\n",
      "2018-12-04 11:22:39.809484  [Epoch 6] Validation class accuracy: 0.438513\n",
      "2018-12-04 11:22:39.811364  [Epoch 6] Validation avg class acc: 0.171823\n",
      "2018-12-04 11:22:39.813097  [Epoch 6] Validation indivisual [0] class recall: 0.515469\n",
      "2018-12-04 11:22:39.814737  [Epoch 6] Validation indivisual [0] class precision: 0.438513\n",
      "2018-12-04 11:22:39.816578  [Epoch 6] Validation indivisual [1] class recall: 0.000000\n",
      "2018-12-04 11:22:39.818335  [Epoch 6] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:22:39.820060  \n",
      "\n",
      " Train one epoch   8 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:25:38.847498  [Epoch 7] mean loss: 17.068993\n",
      "2018-12-04 11:25:38.849786  [Epoch 7] heading rmse[deg]: 104.977210\n",
      "2018-12-04 11:25:38.851621  [Epoch 7] class accuracy: 0.451440\n",
      "2018-12-04 11:25:38.853639  [Epoch 7] avg class acc: 0.338744\n",
      "2018-12-04 11:25:38.855411  [Epoch 7] indivisual [0] class recall: 0.367957\n",
      "2018-12-04 11:25:38.857344  [Epoch 7] indivisual [0] class precision: 0.456174\n",
      "2018-12-04 11:25:38.859271  [Epoch 7] indivisual [1] class recall: 0.647923\n",
      "2018-12-04 11:25:38.861024  [Epoch 7] indivisual [1] class precision: 0.449051\n",
      "2018-12-04 11:25:38.862720  [Epoch 7] indivisual [2] class recall: 0.000354\n",
      "2018-12-04 11:25:38.864382  [Epoch 7] indivisual [2] class precision: 0.100000\n",
      "2018-12-04 11:25:38.866125   Evaluation one (validation set) epoch   8 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:44<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:26:24.254336  [Epoch 7] Validation mean loss: 16.696358\n",
      "2018-12-04 11:26:24.256323  [Epoch 7] Validation heading rmse[deg]: 103.906927\n",
      "2018-12-04 11:26:24.258146  [Epoch 7] Validation class accuracy: 0.485762\n",
      "2018-12-04 11:26:24.260068  [Epoch 7] Validation avg class acc: 0.190190\n",
      "2018-12-04 11:26:24.261771  [Epoch 7] Validation indivisual [0] class recall: 0.456443\n",
      "2018-12-04 11:26:24.263732  [Epoch 7] Validation indivisual [0] class precision: 0.456563\n",
      "2018-12-04 11:26:24.265633  [Epoch 7] Validation indivisual [1] class recall: 0.114129\n",
      "2018-12-04 11:26:24.267444  [Epoch 7] Validation indivisual [1] class precision: 0.648279\n",
      "2018-12-04 11:26:24.269218  [Epoch 7] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:26:24.270907  \n",
      "\n",
      " Train one epoch   9 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:57<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:29:23.260586  [Epoch 8] mean loss: 16.742176\n",
      "2018-12-04 11:29:23.262584  [Epoch 8] heading rmse[deg]: 104.067964\n",
      "2018-12-04 11:29:23.264385  [Epoch 8] class accuracy: 0.454680\n",
      "2018-12-04 11:29:23.266320  [Epoch 8] avg class acc: 0.342595\n",
      "2018-12-04 11:29:23.268183  [Epoch 8] indivisual [0] class recall: 0.460906\n",
      "2018-12-04 11:29:23.270150  [Epoch 8] indivisual [0] class precision: 0.454173\n",
      "2018-12-04 11:29:23.271901  [Epoch 8] indivisual [1] class recall: 0.566881\n",
      "2018-12-04 11:29:23.273605  [Epoch 8] indivisual [1] class precision: 0.455325\n",
      "2018-12-04 11:29:23.275251  [Epoch 8] indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:29:23.276869  [Epoch 8] indivisual [2] class precision: 0.000000\n",
      "2018-12-04 11:29:23.278450   Evaluation one (validation set) epoch   9 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:30:08.876060  [Epoch 8] Validation mean loss: 16.766067\n",
      "2018-12-04 11:30:08.878023  [Epoch 8] Validation heading rmse[deg]: 104.163289\n",
      "2018-12-04 11:30:08.879845  [Epoch 8] Validation class accuracy: 0.438736\n",
      "2018-12-04 11:30:08.881725  [Epoch 8] Validation avg class acc: 0.172053\n",
      "2018-12-04 11:30:08.883507  [Epoch 8] Validation indivisual [0] class recall: 0.516160\n",
      "2018-12-04 11:30:08.885198  [Epoch 8] Validation indivisual [0] class precision: 0.438736\n",
      "2018-12-04 11:30:08.886826  [Epoch 8] Validation indivisual [1] class recall: 0.000000\n",
      "2018-12-04 11:30:08.888396  [Epoch 8] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:30:08.889968  \n",
      "\n",
      " Train one epoch  10 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:33:08.207402  [Epoch 9] mean loss: 16.781692\n",
      "2018-12-04 11:33:08.209335  [Epoch 9] heading rmse[deg]: 104.189951\n",
      "2018-12-04 11:33:08.211159  [Epoch 9] class accuracy: 0.456240\n",
      "2018-12-04 11:33:08.213166  [Epoch 9] avg class acc: 0.340542\n",
      "2018-12-04 11:33:08.215142  [Epoch 9] indivisual [0] class recall: 0.296500\n",
      "2018-12-04 11:33:08.217259  [Epoch 9] indivisual [0] class precision: 0.455198\n",
      "2018-12-04 11:33:08.218998  [Epoch 9] indivisual [1] class recall: 0.725126\n",
      "2018-12-04 11:33:08.220668  [Epoch 9] indivisual [1] class precision: 0.456705\n",
      "2018-12-04 11:33:08.222325  [Epoch 9] indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:33:08.224023  [Epoch 9] indivisual [2] class precision: 0.000000\n",
      "2018-12-04 11:33:08.225656   Evaluation one (validation set) epoch  10 /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:45<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-04 11:33:53.730559  [Epoch 9] Validation mean loss: 16.666522\n",
      "2018-12-04 11:33:53.732629  [Epoch 9] Validation heading rmse[deg]: 103.806222\n",
      "2018-12-04 11:33:53.734484  [Epoch 9] Validation class accuracy: 0.449740\n",
      "2018-12-04 11:33:53.736522  [Epoch 9] Validation avg class acc: 0.172594\n",
      "2018-12-04 11:33:53.738369  [Epoch 9] Validation indivisual [0] class recall: 0.000000\n",
      "2018-12-04 11:33:53.740267  [Epoch 9] Validation indivisual [1] class recall: 0.517783\n",
      "2018-12-04 11:33:53.742060  [Epoch 9] Validation indivisual [1] class precision: 0.449740\n",
      "2018-12-04 11:33:53.744111  [Epoch 9] Validation indivisual [2] class recall: 0.000000\n",
      "2018-12-04 11:33:54.660059  Model saved in file: /home/gozilla/kyungpyo/git/MasterThesisProject/Network/notebook/train_log_20181204/model_out5_7/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Import model \"\"\"\n",
    "sys.path.append( os.path.abspath('../../model') )\n",
    "\n",
    "from train import *\n",
    "import model_out_5_heading as MODEL\n",
    "\n",
    "def run_training(out_path):\n",
    "    \n",
    "    \"\"\" Path \"\"\"\n",
    "    model_save_path = os.path.abspath(out_path)\n",
    "    if not os.path.isdir(model_save_path) : os.mkdir(model_save_path)\n",
    "    log_path = os.path.abspath(os.path.join(model_save_path, 'train_log.txt') )\n",
    "        \n",
    "    \"\"\" Parameters \"\"\"\n",
    "    GPU_INDEX = 0\n",
    "    NUM_POINT = 1024\n",
    "    NUM_CLASSES = 3\n",
    "\n",
    "    BN_INIT_DECAY = 0.5\n",
    "    BN_DECAY_DECAY_RATE = 0.5\n",
    "    BN_DECAY_DECAY_STEP = float(200000)\n",
    "    BN_DECAY_CLIP = 0.99\n",
    "    DECAY_STEP = BN_DECAY_DECAY_STEP\n",
    "    DECAY_RATE = BN_DECAY_DECAY_RATE\n",
    "\n",
    "    BATCH_SIZE = 50\n",
    "\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    BASE_LEARNING_RATE = 0.001\n",
    "\n",
    "    OPTIMIZER = 'adam'\n",
    "\n",
    "    MAX_EPOCH = 10\n",
    "\n",
    "    \"\"\" log file \"\"\"\n",
    "    LOG_FOUT = open(log_path, 'w')\n",
    "\n",
    "    def log_string(out_str):\n",
    "        out_str = str( datetime.datetime.fromtimestamp( time.time() ) ) + \"  \" + out_str\n",
    "        LOG_FOUT.write(out_str+'\\n')\n",
    "        LOG_FOUT.flush()\n",
    "        print(out_str)\n",
    "\n",
    "\n",
    "    def get_learning_rate(batch):\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "                            BASE_LEARNING_RATE,  # Base learning rate.\n",
    "                            batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                            DECAY_STEP,          # Decay step.\n",
    "                            DECAY_RATE,          # Decay rate.\n",
    "                            staircase=True)\n",
    "        learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n",
    "        return learning_rate        \n",
    "\n",
    "    def get_bn_decay(batch):\n",
    "        bn_momentum = tf.train.exponential_decay(\n",
    "                          BN_INIT_DECAY,\n",
    "                          batch * BATCH_SIZE,\n",
    "                          BN_DECAY_DECAY_STEP,\n",
    "                          BN_DECAY_DECAY_RATE,\n",
    "                          staircase=True)\n",
    "        bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "        return bn_decay\n",
    "\n",
    "    \"\"\" load traing model \"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Placeholder\n",
    "            \"\"\"\n",
    "            pointclouds_pl, class_labels_pl, heading_labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "            is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "            print(is_training_pl)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            decay\n",
    "            \"\"\"\n",
    "            # Note the global_step=batch parameter to minimize. \n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.summary.scalar('bn_decay', bn_decay)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Get model and loss \n",
    "            \"\"\"\n",
    "            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n",
    "            loss = MODEL.get_loss(pred, class_labels_pl, heading_labels_pl, end_points, h_reg_weight=10000)\n",
    "            tf.summary.scalar('loss', loss)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Get accuracy \n",
    "            \"\"\"\n",
    "            correct = tf.equal(tf.argmax(tf.slice(pred, [0,0], [BATCH_SIZE,3]), 1), tf.to_int64(class_labels_pl))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Get training operator\n",
    "            \"\"\"\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            if OPTIMIZER == 'momentum':\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n",
    "            elif OPTIMIZER == 'adam':\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss, global_step=batch)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Add ops to save and restore all the variables.\n",
    "            \"\"\"\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        Create a session\n",
    "        \"\"\"\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = False\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Add summary writers\n",
    "        merged = tf.merge_all_summaries()\n",
    "        \"\"\"\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        train_writer_path = os.path.abspath( os.path.join(model_save_path, 'train') )\n",
    "        if os.path.isdir(train_writer_path): os.system('rm -r {}'.format(train_writer_path))\n",
    "        os.mkdir(train_writer_path)\n",
    "\n",
    "        test_writer_path = os.path.abspath( os.path.join(model_save_path, 'test') )\n",
    "        if os.path.isdir(test_writer_path): os.system('rm -r {}'.format(test_writer_path))\n",
    "        os.mkdir(test_writer_path)\n",
    "\n",
    "\n",
    "        train_writer = tf.summary.FileWriter(train_writer_path, sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(test_writer_path)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Init variables\n",
    "        \"\"\"\n",
    "        init = tf.global_variables_initializer()\n",
    "        # To fix the bug introduced in TF 0.12.1 as in\n",
    "        # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n",
    "        #sess.run(init)\n",
    "        sess.run(init, {is_training_pl: True})\n",
    "\n",
    "        ops = {'pointclouds_pl': pointclouds_pl,\n",
    "               'class_labels_pl': class_labels_pl,\n",
    "               'heading_labels_pl': heading_labels_pl,\n",
    "               'is_training_pl': is_training_pl,\n",
    "               'pred': pred,\n",
    "               'loss': loss,\n",
    "               'train_op': train_op,\n",
    "               'merged': merged,\n",
    "               'step': batch}\n",
    "\n",
    "\n",
    "        for epoch in range(MAX_EPOCH):\n",
    "\n",
    "            ## Training\n",
    "            log_string ( \"\\n\\n Train one epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = True\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle train files\n",
    "            \"\"\"\n",
    "            train_file_idxs = np.arange(0, data_train.shape[0])\n",
    "            np.random.shuffle(train_file_idxs)\n",
    "\n",
    "            current_data = data_train[train_file_idxs] \n",
    "            current_class_label = class_label_train[train_file_idxs]\n",
    "            current_heading_label = heading_label_train[train_file_idxs]\n",
    "            \n",
    "            current_class_label.reshape((data_train.shape[0],))\n",
    "            current_heading_label.reshape((data_train.shape[0],))\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            heading_rmse_sum = 0\n",
    "            \n",
    "            total_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "   \n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE          \n",
    "    \n",
    "\n",
    "            \"\"\"\n",
    "            Run batch training\n",
    "            \"\"\"\n",
    "            num_batches = 500\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE           \n",
    "\n",
    "                # Augment batched point clouds by rotation and jittering\n",
    "                rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])\n",
    "                jittered_data = provider.jitter_point_cloud(rotated_data)\n",
    "\n",
    "                # Reashape\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                feed_dict = {ops['pointclouds_pl']: jittered_data,\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training,}\n",
    "\n",
    "                summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                    ops['train_op'], ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                train_writer.add_summary(summary, step)\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                \n",
    "                ## classification\n",
    "                class_pred = pred_val[:,:3]\n",
    "                heading_pred = pred_val[:,3]\n",
    "                \n",
    "                class_pred = np.argmax(class_pred, 1)\n",
    "                correct = np.sum(class_pred == current_class_label_reshape)\n",
    "                                \n",
    "                total_correct += correct\n",
    "                total_seen += BATCH_SIZE\n",
    "                loss_sum += loss_val\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    total_class[i] += np.sum( np.ones(BATCH_SIZE) * i == current_class_label_reshape )\n",
    "                    total_detect_class[i] += np.sum( np.ones(BATCH_SIZE) * i == class_pred )\n",
    "                    total_correct_class[i] += np.sum( (np.ones(BATCH_SIZE) * i == current_class_label_reshape) * \\\n",
    "                                                        (np.ones(BATCH_SIZE) * i == class_pred) )\n",
    "                ## Heading regression\n",
    "                heading_rmse_sum += np.mean( np.square(heading_pred - current_heading_label_reshape) )\n",
    "\n",
    "            log_string(  '[Epoch %d] mean loss: %f' % \\\n",
    "                       (  epoch, loss_sum / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] heading rmse[deg]: %f' % \\\n",
    "                       (  epoch, 360. * np.sqrt(heading_rmse_sum / float(num_batches) )  )   )\n",
    "            log_string(  '[Epoch %d] class accuracy: %f'% \\\n",
    "                       (  epoch, total_correct / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] avg class acc: %f' % \\\n",
    "                       (  epoch, np.mean( np.array(total_correct_class) / np.array(total_class,dtype=np.float) )  )   )\n",
    "\n",
    "            for i_cls in range(NUM_CLASSES):\n",
    "                if not float(total_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] indivisual [%d] class recall: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "                if not float(total_detect_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] indivisual [%d] class precision: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Evaluation using validation set    \n",
    "            \"\"\"\n",
    "            \n",
    "            log_string ( \" Evaluation one (validation set) epoch %3d / %3d\" % (epoch+1, MAX_EPOCH) )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            is_training = False\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Evaluation metric\n",
    "            \"\"\"\n",
    "            total_correct = 0\n",
    "            total_seen = 0\n",
    "            loss_sum = 0\n",
    "            heading_rmse_sum = 0\n",
    "            \n",
    "            total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            total_detect_true_class = [0 for _ in range(NUM_CLASSES)]\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Shuffle validation files\n",
    "            \"\"\"\n",
    "            file_idxs = np.arange(0, data_vali.shape[0])\n",
    "            np.random.shuffle(file_idxs)\n",
    "\n",
    "            current_data = data_vali[file_idxs]\n",
    "            current_class_label = class_label_vali[file_idxs]\n",
    "            current_heading_label = heading_label_vali[file_idxs]\n",
    "\n",
    "            num_batches = current_data.shape[0] // BATCH_SIZE\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            Run batch validation\n",
    "            \"\"\"\n",
    "            for batch_idx in trange(num_batches):\n",
    "\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Reashape\n",
    "                \"\"\"\n",
    "                current_class_label_reshape = current_class_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "                current_heading_label_reshape = current_heading_label[start_idx:end_idx].reshape((BATCH_SIZE,))\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Feed dict\n",
    "                \"\"\"\n",
    "                feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                             ops['class_labels_pl']: current_class_label_reshape,\n",
    "                             ops['heading_labels_pl']: current_heading_label_reshape,\n",
    "                             ops['is_training_pl']: is_training}\n",
    "                \n",
    "                \"\"\"\n",
    "                Summary\n",
    "                \"\"\"\n",
    "                summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n",
    "                    ops['loss'], ops['pred']], feed_dict=feed_dict)\n",
    "\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                Evaluation\n",
    "                \"\"\"\n",
    "                \n",
    "                ## classification\n",
    "                class_pred = pred_val[:,:3]\n",
    "                heading_pred = pred_val[:,3]\n",
    "                \n",
    "                class_pred = np.argmax(class_pred, 1)\n",
    "                correct = np.sum(class_pred == current_class_label_reshape)\n",
    "                                \n",
    "                total_correct += correct\n",
    "                total_seen += BATCH_SIZE\n",
    "                loss_sum += loss_val\n",
    "\n",
    "                for i in range(NUM_CLASSES):\n",
    "                    total_class[i] += np.sum( np.ones(BATCH_SIZE) * i == current_class_label_reshape )\n",
    "                    total_detect_class[i] += np.sum( np.ones(BATCH_SIZE) * i == class_pred )\n",
    "                    total_correct_class[i] += np.sum( (np.ones(BATCH_SIZE) * i == current_class_label_reshape) * \\\n",
    "                                                        (np.ones(BATCH_SIZE) * i == class_pred) )\n",
    "                ## Heading regression\n",
    "                heading_rmse_sum += np.mean( np.square(heading_pred - current_heading_label_reshape) )\n",
    "                \n",
    "                \n",
    "                \n",
    "            log_string(  '[Epoch %d] Validation mean loss: %f' % \\\n",
    "                       (  epoch, loss_sum / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] Validation heading rmse[deg]: %f' % \\\n",
    "                       (  epoch, 360. * np.sqrt(heading_rmse_sum / float(num_batches) )  )   )\n",
    "            log_string(  '[Epoch %d] Validation class accuracy: %f'% \\\n",
    "                       (  epoch, total_correct / float(total_seen)  )   )\n",
    "            log_string(  '[Epoch %d] Validation avg class acc: %f' % \\\n",
    "                       (  epoch, np.mean( np.array(total_correct_class) / np.array(total_class,dtype=np.float) )  )   )\n",
    "\n",
    "            for i_cls in range(NUM_CLASSES):\n",
    "                if not float(total_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] Validation indivisual [%d] class recall: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_class[i_cls])))    \n",
    "                if not float(total_detect_class[i_cls]) == 0:\n",
    "                    log_string(  '[Epoch %d] Validation indivisual [%d] class precision: %f' % \\\n",
    "                           (  epoch, i_cls, float(total_correct_class[i_cls])/float(total_detect_class[i_cls])))    \n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Save the variables to disk.\n",
    "            \"\"\"\n",
    "            if ( epoch + 1 ) % 10 == 0:\n",
    "                save_path = saver.save(sess, os.path.join(model_save_path, \"model.ckpt\"))\n",
    "                log_string(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "                \n",
    "# option 1: execute code with extra process\n",
    "p = multiprocessing.Process(target=run_training, args = ('./model_out5_7',))\n",
    "p.start()\n",
    "p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
